# 5. 構文解析アルゴリズム古今東西

第2章で算術式を例にしてBNFや抽象構文木といった基礎概念を説明しました。第3章ではJSONの構文解析器の実装を通してPEGによる構文解析と単純な字句解析を用いた構文解析のやり方を学びました。第4章では文脈自由文法と形式言語の階層の話をしました。これでようやく準備が整ったので、本書の本丸である構文解析アルゴリズムの話ができます。

といっても、戸惑う読者の方が多いかもしれません。これまで「構文解析アルゴリズム」について具体的な話はまったくなかったのですから。しかし、皆さんは、第3章で二つの構文解析アルゴリズムを使ってJSONの構文解析器を**すでに**書いているのです。

第3章で最初に実装したのはPEGと呼ばれる手法の素朴な実装です。次に実装したのは*LL(1)*っぽい再帰下降構文解析器です。**再帰下降**という言葉は見慣れないものなので、疑問に思われる読者の方も多いと思います。その疑問は脇において、第3章での実装が理解できたのなら、皆さんはすでに直感的に構文解析アルゴリズムを理解していることになります。

この章では、2024年までに発表された主要な構文解析アルゴリズムについて、筆者の独断と偏見を交えて解説します。この章で紹介する構文解析アルゴリズムのほとんどについて、その構文解析アルゴリズムを使った構文解析器を生成してくれる構文解析器生成系が存在します。構文解析機生成系については第6章で説明しますが、ここではさわりだけを紹介しておきます。

たとえば、構文解析アルゴリズムとして有名な*LALR(1)*は、もっともメジャーな構文解析器生成系でCコードを生成するyacc（GNUによる再実装であるbisonが主流）で採用されています。*LL(1)*はJava向けの構文解析器生成系としてメジャーなJavaCCで採用されている方式です。*ALL(\*)*は、Javaをはじめとした多言語向け構文解析器生成系として有名なANTLRで採用されています。PEGを採用した構文解析器生成系も多数存在します。

このように、なにかの構文解析アルゴリズムがあれば、構文解析アルゴリズムに基づいた構文解析機生成系を作ることができます。余談ですが、筆者は大学院生時代にPEGおよびPackrat Parsingの研究をしており、その過程でPEGによる構文解析器生成系を作ったものです。

小難しいことばかり言うのは趣味ではないので、さっそく、構文解析アルゴリズムの世界を覗いてみましょう！　

## 5.1 下向き構文解析と上向き構文解析

具体的な構文解析アルゴリズムの説明に入る前に、構文解析アルゴリズムは大別して、

- 上から下へ（下向き）
- 下から上へ（上向き）

の二つのアプローチがあることを理解しておきましょう。下向き構文解析法と上向き構文解析法では真逆の発想で構文解析を行うからです。

## 5.2 下向き構文解析の概要

まずは下向き構文解析法です。下向き構文解析では予測型とバックトラック型で若干異なる方法で構文解析をしますが、ここでは予測型の下向き構文解析法を説明します。予測型の下向き構文解析法ではCFGの開始記号から構文解析を開始し、規則に従って再帰的に構文解析を行っていきます。

第4章で例に出てきたDyck言語を例にして、具体的な方法を説明します。Dyck言語の文法は以下のようなものでした。（`$`は入力の開始と終了を表す特別な記号、`ε`は空文字列を表します）

```
D -> $ P $
P -> ( P ) P
P -> ε
```

このCFGはカッコがネストした文字列の繰り返し（空文字列を含む）を過不足無く表現しているわけですが、`(())`という文字列がマッチするかを判定する問題を考えてみましょう。

まず最初に、開始記号が`D`で規則`D -> $ P $`があるので、解析を開始します。スタックを使って解析の進行状況を管理します。ドット `・` は現在注目している位置を示します。

```
入力: $ ( ( ) ) $
スタック: [ D -> ・$ P $ ]
```

次に最初の記号 `$` を入力文字列から読み込みます。

```
入力: ( ( ) ) $
スタック: [ D -> $・P $ ]
```

次に非終端記号 `P` を解析しようとします。次の入力は `(` なので、規則 `P -> ( P ) P` を適用することになります。スタックにこの規則を追加します。

```
入力: ( ( ) ) $
スタック: [ D -> $・P $, P -> ・( P ) P ]
```

次の入力 `(` とスタックトップの規則の期待する記号 `(` がマッチするので、入力を消費し、ドットを進めます。

```
入力: ( ) ) $
スタック: [ D -> $・P $, P -> (・P ) P ]
```

再び非終端記号 `P` を解析します。次の入力は `(` なので、規則 `P -> ( P ) P` を適用します。

```
入力: ( ) ) $
スタック: [ D -> $・P $, P -> (・P ) P, P -> ・( P ) P ]
```

次の入力 `(` とスタックトップの規則の期待する記号 `(` がマッチするので、入力を消費し、ドットを進めます。

```
入力: ) ) $
スタック: [ D -> $・P $, P -> (・P ) P, P -> (・P ) P ]
```

再び非終端記号 `P` を解析します。次の入力は `)` です。規則 `P -> ( P ) P` は `(` で始まるため適用できません。もう一つの規則 `P -> ε` を適用します。これは空文字列にマッチするので、入力は消費せず、ドットだけが進みます（εの解析が完了したとみなします）。

```
入力: ) ) $
スタック: [ D -> $・P $, P -> (・P ) P, P -> ( P・) P ]
```

次の入力 `)` とスタックトップの規則の期待する記号 `)` がマッチするので、入力を消費し、ドットを進めます。

```
入力: ) $
スタック: [ D -> $・P $, P -> (・P ) P, P -> ( P )・P ]
```

再び非終端記号 `P` を解析します。次の入力は `)` なので、規則 `P -> ε` を適用します。

```
入力: ) $
スタック: [ D -> $・P $, P -> (・P ) P, P -> ( P ) P・]
```

スタックトップの規則 `P -> ( P ) P` の解析が完了したので、スタックからこの規則を取り除きます。解析が完了した `P` が一つ上の規則 `P -> (・P ) P` の `P` に対応します。

```
入力: ) $
スタック: [ D -> $・P $, P -> ( P・) P ]
```

次の入力 `)` とスタックトップの規則の期待する記号 `)` がマッチするので、入力を消費し、ドットを進めます。

```
入力: $
スタック: [ D -> $・P $, P -> ( P )・P ]
```

再び非終端記号 `P` を解析します。次の入力は `$` なので、規則 `P -> ε` を適用します。

```
入力: $
スタック: [ D -> $・P $, P -> ( P ) P・]
```

スタックトップの規則 `P -> ( P ) P` の解析が完了したので、スタックから取り除きます。解析が完了した `P` が一番下の規則 `D -> $・P $` の `P` に対応します。

```
入力: $
スタック: [ D -> $ P・$ ]
```

次の入力 `$` とスタックトップの規則の期待する記号 `$` がマッチするので、入力を消費し、ドットを進めます。

```
入力: (空)
スタック: [ D -> $ P $・]
```

スタックトップの規則 `D -> $ P $` の解析が完了し、入力も終端に達したので、スタックから規則を取り除きます。

```
入力: (空)
スタック: [ ]
```

入力文字列の終端に到達し、スタックが空になったので、入力文字列 `(())` はDyck言語の文法に従っていることがわかりました。

予測型の下向き構文解析では以下の動作を繰り返します。

1. 残りの文字列から、1文字とってきて先読み文字列に追加する
2. 次が非終端記号で、先読み文字列から適用すべき規則が決定できる場合スタックにその規則を積む。規則が決定できない場合はエラー。次が終端記号であれば、先読み文字列の先頭とマッチするかを確認し、マッチすれば文字列を消費し、マッチしない場合はエラーを返す
3. 規則の最後に到達した場合は、スタックから要素を取り除く

## 5.3 下向き構文解析法のJavaによる実装

このような動作をJavaコードで表現することを考えてみます。

```java
// D -> P
// P -> ( P ) P
// P -> ε
public class Dyck {
    private final String input;
    private int position;

    public Dyck(String input) { // コンストラクタ名を修正
        this.input = input;
        this.position = 0;
    }

    public boolean parse() {
        boolean result = D();
        return result && position == input.length();
    }

    private boolean D() {
        return P();
    }

    private boolean P() {
        // P -> ( P ) P
        if (position < input.length() && input.charAt(position) == '(') {
            position++; // '(' を読み進める
            if (!P()) return false;
            if (position < input.length() && input.charAt(position) == ')') {
                position++; // ')' を読み進める
                return P();
            } else {
                return false;
            }
        // P -> ε
        } else {
            // 空文字列にマッチ
            return true;
        }
    }
}
```

クラス`Dyck`は、Dyck言語を構文解析して、成功したら`true`、そうでなければ`false`を返すものです。BNFと比較すると、

- 規則の名前と一対一になるメソッドが存在する
- 非終端記号の参照は規則の名前に対応するメソッドの再帰呼び出しとして実現されている

のが特徴です。

呼び出す規則を上、呼び出される規則を下とした時、上から下に再帰呼び出しが続いていくため、再帰下降構文解析と呼ばれます。このように「上から下に」構文解析を行っていくのが下向き構文解析法の特徴です。

注意しなければいけないのは、下向き構文解析の方法は多数あり、その1つに再帰下降構文解析があるということです。

実際、後述するLL(1)の実装のときは構文解析のための表を作り、関数の再帰呼び出しは行わないこともあります。

## 5.4 上向き構文解析の概要

上向き構文解析は下向き構文解析とは真逆の発想で構文解析を行います。こちらの方法は下向き型より直感的に理解しづらいかもしれません。

上向き構文解析ー正確にはシフト還元構文解析として知られているものーでは、文字列を左から右に読み込んでいき、順番にスタックにプッシュしていきます。これをシフト（shift）と呼びます。

シフト動作を続けていくうちに、規則の右辺の記号列とスタックトップにある記号列がマッチすれば、規則の左辺にマッチしたとして、スタックトップにある記号列を規則の左辺で置き換えます。これを還元（reduce）と呼びます。

具体例を挙げてみます。以下のCFGがあったとしましょう。ただし、入力の先頭と末尾を表すために`$`を使うものとします。

```
D -> $ P $
P -> ( P ) P
P -> ε
```

これは下向き構文解析で扱ったDyck言語の文法です。上向き構文解析の説明の都合上、上記と等価な以下の文法を考えます。

```
D -> $ P $
D -> $ ε $
P -> P X
P -> X
X -> ( X )
X -> ()
```

このCFGに対して`(())`という文字列がマッチするかを判定する問題を考えてみましょう。上向き構文解析では、まず最初の「1文字」を左から右にシフトします。以下のようなイメージです。スタックに要素をプッシュすると右に要素が追加されていくものとします。

```
スタック: [ $, ( ]
```

このスタックは`P`にも`D`にもマッチしません。そこで、もう1文字をシフトしてみます。

```
スタック: [ $, (, ( ]
```

まだマッチしませんね。さらにもう1文字シフトしてみます。

```
スタック: [ $, (, (, ) ]
```

規則`X -> ()`を使って還元を行います。

```
スタック: [ $, (, X ]
```

この状態でもう1文字シフトしてみます。

```
スタック: [ $, (, X, ) ]
```

規則`X -> (X)`を使って還元を行います。

```
スタック: [ $, X ]
```

さらに規則`P -> X`を使って還元を行います。

```
スタック: [ $, P ]
```

文字列の末尾にきたので、`$`をシフトします。

```
スタック: [ $, P, $ ]
```

このスタックは規則`D -> $ P $`にマッチします。還元が行われ、最終的にスタックの状態は次のようになります。

```
スタック: [ D ]
```

めでたく`(())`が`D`とマッチすることがわかりました。上向き構文解析では以下の手順を繰り返していきます。

1. 残りの文字があれば、入力文字をシフトしてスタックにプッシュする（シフト）
2. スタックの記号列が規則の右辺にマッチすれば、左辺の非終端記号で置き換える（還元）

4章の最後で少しだけ述べましたが、還元はちょうど、最右導出における導出の逆向きの操作になります。

## 5.5 上向き構文解析のJavaによる実装

このような動作をJavaコードで表現することを考えてみます。まず必要なのは、規則を表すクラス`Rule`です。問題を単純化するために、

1. 規則の名前（左辺）は1文字
2. 規則の右辺は終端記号または非終端記号のリストである

とします。このようなクラス`Rule`は以下のように表現できます。

```java
import java.util.List;
import java.util.ArrayList;

// ElementインターフェースとTerminal, NonTerminalレコードは5.4節で定義済みとする

public record Rule(char lhs, List<Element> rhs) {
    public Rule(char lhs, Element... rhs) {
        this(lhs, List.of(rhs));
    }
    public boolean matches(List<Element> stack) {
        if (stack.size() < rhs.size()) return false;
        for (int i = 0; i < rhs.size(); i++) {
            Element elementInRule = rhs.get(rhs.size() - i - 1);
            Element elementInStack = stack.get(stack.size() - i - 1);
            if (!elementInRule.equals(elementInStack)) {
                return false;
            }
        }
        return true;
    }
}
```

可変長引数を受け取るコンストラクタは規則を簡単に記述するためのものです。`matches`メソッドはスタックの状態と規則がマッチするかを判定します。

`Element`は終端記号や非終端記号を表すクラスで、以下のように定義されます。

```java
public sealed interface Element
    permits Element.Terminal, Element.NonTerminal {
    public record Terminal(char symbol) implements Element {}
    public record NonTerminal(char name) implements Element {}
}
```

これらのクラスを使ってシフトと還元を行うクラス`DyckShiftReduce`は次のように定義できます。（クラス名を`Dyck`から変更）

```java
import java.util.List;
import java.util.ArrayList;

public class DyckShiftReduce { // クラス名を変更
    private final String input;
    private int position;
    private final List<Rule> rules;

    private final List<Element> stack = new ArrayList<>();

    public DyckShiftReduce(String input) { // コンストラクタ名を変更
        this.input = input;
        this.position = 0;
        this.rules = List.of(
            // D -> $ P $
            new Rule('D', new Element.Terminal('$'), new Element.NonTerminal('P'), new Element.Terminal('$')),
            // D -> $ $ (εの代わりに空の右辺を表現)
            new Rule('D', new Element.Terminal('$'), new Element.Terminal('$')),
            // P -> P X
            new Rule('P', new Element.NonTerminal('P'), new Element.NonTerminal('X')),
            // P -> X
            new Rule('P', new Element.NonTerminal('X')),
            // X -> ( X )
            new Rule('X', new Element.Terminal('('), new Element.NonTerminal('X'), new Element.Terminal(')')),
            // X -> ()
            new Rule('X', new Element.Terminal('('), new Element.Terminal(')'))
        );
    }

    public boolean parse() {
        stack.add(new Element.Terminal('$')); // 開始記号を追加
        while (true) {
            if (!tryReduce()) { // まず還元を試みる
                if (position < input.length()) { // 還元できなければシフト
                    stack.add(new Element.Terminal(input.charAt(position)));
                    position++;
                } else { // シフトもできなければループ終了
                    break;
                }
            }
        }
        // 入力の終端記号を追加
        stack.add(new Element.Terminal('$'));
        // 可能な限り還元を試みる
        while (tryReduce()) {
            // 還元を試みる (ループ条件で実行)
        }
        // 最終的にスタックが [D] になれば成功
        return stack.size() == 1 && stack.get(0).equals(new Element.NonTerminal('D'));
    }

    private boolean tryReduce() {
        for (Rule rule : rules) {
            if (rule.matches(stack)) {
                // マッチしたら右辺の長さ分スタックから削除
                for (int i = 0; i < rule.rhs().size(); i++) {
                    stack.remove(stack.size() - 1);
                }
                // 左辺の非終端記号をスタックに追加
                stack.add(new Element.NonTerminal(rule.lhs()));
                return true; // 還元成功
            }
        }
        return false; // 還元できる規則がなかった
    }
}
```

このプログラムでは、入力文字列を1文字ずつシフトしながら、還元を行っています。規則にマッチする場合はスタックから右辺の要素を取り除き、左辺の非終端記号をプッシュします。最終的にスタックに`NonTerminal('D')`だけが残れば、入力文字列が文法に従っていることが確認できます。

## 5.6 下向き構文解析と上向き構文解析の比較

下向き構文解析法と上向き構文解析法は得手不得手があります。

下向き型は規則と関数を対応付けるのが容易なので手書きの構文解析器を書くのに向いています。実際、驚くほど多くのプログラミング処理系の構文解析器は手書きの再帰下降構文解析で実装されています。

下向き型は、関数の引数として現在の情報を渡して、引数に応じて構文解析の結果を変化させることが比較的容易です。これは文脈に依存した文法を持った言語を解析するときに有利な性質です。しかし、下向き型は左再帰という形の文法をそのまま処理できないという欠点があります。

たとえば、以下のBNFは上向き型だと普通に解析できますが、工夫なしに下向き型で実装すると無限再帰に陥ってスタックオーバーフローします。

```
A = A "a"
A = "";
```

このような問題を下向き型で解決する方法も存在します。

たとえば、上の文法を以下のように書き換えれば下向き型でも問題なく解析できるようになります。このような処理を左再帰の除去と呼びます。

通常のプログラミング言語でも直線的な再帰は常にループに変換可能ですが、原理的にはそれと似たようなものです。

```
A = "a" A
  | "";
```

さて、上向き型は左再帰を問題なく処理できるので、このような文法をそのまま解析できるわけです、では上向き型はすべての文法に対して有利なのでしょうか？ことはそう単純ではありません。

たとえば、それまでの文脈に応じて構文解析のルールを切り替えたくなることがあります。最近の言語によく搭載されている文字列補間などはその最たる例です。

`"`の中は文字列リテラルとして特別扱いされますが、その中で`#{`が出てきたら（Rubyの場合）、通常の式を構文解析するときのルールに戻る必要があります。

このように、文脈に応じて適用するルールを切り替えるのは下向き型が得意です。もちろん、上向き型でも実現できないわけではありません。実際、Rubyの構文解析機はYaccの定義ファイルから生成されるようになっていますが、Yaccが採用しているのは代表的な上向き構文解析法である`LALR(1)`です。

ともあれ、下向きと上向きには異なる利点と欠点があります。

次からは具体的なアルゴリズムの説明に移ります。

## 5.7 LL(1) - 代表的な下向き構文解析アルゴリズム

下向き型構文解析法の中でおそらくもっとも古典的で、よく知られているのは`LL(1)`法です。`LL`は**L**eft-to-right, **L**eftmost derivationの略で、左から右へ文字列をスキャンしながら**最左導出**を行うことを意味しています。最左導出は第4章で説明しましたね。

`LL(1)`の`1`は「1トークン先読み」を意味しています。つまり、`LL(1)`法は、次の1トークンを見て、最左導出を行うような構文解析手法です。この手法は手書きの**再帰下降構文解析**によって簡単に実装できるため、構文解析手法の中でも単純なものと言えるでしょう。字面が一見小難しく見えますが、`LL(1)`のアイデアは意外に簡単なものです。

たとえば、以下のようなJava言語のif文があったとします。

```java
if(age < 18) {
    System.out.println("18歳未満です");
} else {
    System.out.println("18歳以上です");
}
```

我々はどのようにしてこれを見て「if文がある」と認識するのでしょうか。もちろん「人それぞれ」なのですが、最初にキーワード`if`が現れたからif文だと考える人も多いのではないかと思います。

`LL(1)`構文解析アルゴリズムはまさにこのイメージを元にした手法です。プログラムをトークン列に区切った後に、「最初の1トークン」を見て、「これはif文だ」とか「これはwhile文だ」とか認識するようなものですね。

イメージとしては簡単なのですが、アルゴリズムとして実行可能なようにするためには考えなければいけない論点がいくつかあります。以下では、`LL(1)`を実装するに当たって考えなければいけない課題について論じます。

### 課題1 - ある構文の最初のトークンが複数種類ある場合

先程の例ではある構文、たとえばif文が始まるには`if`というキーワードが必須で、それ以外の方法でif文が始まることはありえませんでした。

つまり、`if`というトークンが先頭に来たら、それはif文であると確定できるわけです。

しかし、問題はそう単純ではありません。if文の他に符号付き整数および加減乗除のみからなる算術式を構文解析をすることを考えてみましょう。

算術式は以下のいずれかで始まります。

- `(`
- `-`
- `+`
- 整数リテラル（`<int_literal>`）

つまり、算術式の始まりは複数のトークンで表されます。このような場合、最初のトークンとの一致比較だけでは「これは算術式だ」と確定できません。

あるトークンが算術式の始まりである事を確定するためには、トークンの集合という概念が必要になります。

たとえば、算術式の始まりは以下のようなトークンの集合で表されます。

```text
{"(", "-", "+", <int_literal>}
```

このように、ある構文が始まるかを決定するために必要なトークンの集合のことを**FIRST集合**と呼びます。

**FIRST集合**は非終端記号ごとに定義されます。以降では、非終端記号`N`に対して定義されるFIRST集合を`FIRST(N)`と表します。

たとえば、規則 `A` の右辺が複数あって以下のようになっているとします。

```
A -> B
A -> C
```

このとき、

```
FIRST(B) intersection FIRST(C) = empty set
```

が成り立てば、先頭１トークンだけを「先に見て」`B` を選ぶか `C` を選ぶかを安全に決定することができます。

この「先を見る」（Lookahead）という動作がLL(1)のキモです。

バックトラックしない下向き型の場合「あ。間違ってたので別の選択肢をためそう」ということができませんから、必然的に一つ先を読んで分岐する必要があるのです。

一つ先を読んで安全に分岐を選べるためには、分岐の先頭にあるトークンがお互いに重なっていないことが必要条件になります。この「お互いに重なっていない」というのが、「`FIRST(B)` と `FIRST(C)` の積集合が空集合である」という条件です。

### 課題2 - 省略可能な要素の扱い

if文であるかどうかは、先頭の1トークンを見ればわかります。しかし、if文であるとして、if-else文なのかelseがない単純なif文であるかどうかを判定するのはどうすればいいでしょうか。たとえば、以下の文は正当です。

```java
if (age < 18) {
    System.out.println("18歳未満です");
}
```

以下の文も正当です。

```java
if (age < 18) {
    System.out.println("18歳未満です");
} else {
    System.out.println("18歳以上です");
}
```

最初のif文の後に、

- 前者はelseが出現しない
- 後者はelseが出現する

という違いがあります。

つまり、elseが出現するかどうかで、どの規則を適用するかを決定する必要があります。このような場合、次のトークンを見て、elseならif-else文、そうでなければ単純なif文と解釈します。

この判断を行うためには**FIRST集合**だけでは不十分です。elseが省略される可能性があるためです。elseが省略可能かどうかを示す情報が必要です。

ある要素が省略可能かどうかを示す情報を**nullable**と呼びます。**nullable**は非終端記号が空文字列を生成可能かどうかを示す情報です。たとえば、以下の規則があるとします。

```
A -> a
A -> b
A -> ε
```

`A` は空文字列 `ε` を生成可能です。このような場合、`A` は nullable であると言います。

さて、この言い方に従うと

```java
else {
    System.out.println("18歳以上です");
}
```

この部分は**nullable**であると言えます。

このような**nullable**な要素の次に出現し得るトークンの集合を**FOLLOW集合**と呼びます。**FOLLOW集合**は非終端記号ごとに定義されます。以降では、非終端記号`N`に対して定義される**FOLLOW集合**を`FOLLOW(N)`と表します。

次の項では、**FIRST集合**と**FOLLOW集合**の概念についてより厳密に説明します。

### FIRST集合とFOLLOW集合の計算

LL(1)をアルゴリズムとしてきちんと定義しようとするなら、この二つの概念が必要であることはわかってもらえたのではないかと思います。しかし、この二つですが、プログラム上でどう計算すれば良いのでしょうか？この問いに答えることがLL(1)アルゴリズムをきちんと理解することであり、逆にきちんと理解できれば、自力でLL(1)アルゴリズムによるパーサを記述できるようになるでしょう。

まずはFIRST集合について考えてみます。単純化のために以下のような規則を仮定します。

```
A -> α1
A -> α2
...
A -> αn
```

`α_i` は終端記号や非終端記号の並びです。`FIRST(A)` を求めるには以下の手順を用います。

1. FIRST集合を空集合に初期化する。
2. 各生成規則 `A -> α_i` について、次を行う：
 - `α_i` の最初の記号 `X_1` が終端記号ならば、`FIRST(A)` に `X_1` を追加する。
 - `X_1` が非終端記号の場合、`FIRST(X1)` を計算し、`FIRST(A)` に `FIRST(X1)` (εを除く) を追加する。
 - `X_1` が nullable である場合、次の記号 `X_2` について同様の処理を行う。`α_i` のすべての記号が nullable ならば、ε を `FIRST(A)` に追加する。

`nullable`については先程軽く述べましたが、ある非終端記号が空文字列を生成可能かどうかを示すものです。`nullable`の計算は以下の手順で行います。

1. 全ての非終端記号 `N` について `nullable(N)` を false に初期化する。
2. 生成規則 `A -> ε` があれば `nullable(A)` を true に設定する。
3. 生成規則 `A -> X1 X2 ... Xk` について、すべての `Xi` (1 <= i <= k) が nullable ならば `nullable(A)` を true に設定する。
4. 値が変化しなくなるまで2と3を繰り返す。

次に**FOLLOW集合**の計算です。`FOLLOW(A)`は、非終端記号`A`の後に現れる可能性のある終端記号の集合です。計算手順は以下の通りです。

1. すべての非終端記号 `N` について `FOLLOW(N)` を空集合で初期化する。
2. 開始記号 `S'` の `FOLLOW(S')` に入力終了記号 `$` を追加する。
3. 文法中の各規則 `B -> αAβ` について、
    *   `FIRST(β)` に含まれる `ε` 以外のすべての終端記号を `FOLLOW(A)` に追加する。
    *   もし `β` が `ε` を導出可能（`nullable(β)` が真）ならば、`FOLLOW(B)` のすべての記号を `FOLLOW(A)` に追加する。
4. 新しい記号が追加されなくなるまで、ステップ3を繰り返す。

この`FIRST`と`FOLLOW`を用いて、LL(1)構文解析表を作成します。

### LL(1)構文解析表の作成

構文解析表は、非終端記号と入力の次のトークン（終端記号）の組み合わせで、次にどの生成規則を適用すべきかを示すものです。構文解析表の作成手順は以下の通りです。

1. 各生成規則 `A -> α` について、次を行う：
  - `FIRST(α)` に含まれる各終端記号 `a` (εを除く) に対して、表の項目 `Table[A, a]` に規則 `A -> α` を入れる。
  - もし `ε` が `FIRST(α)` に含まれるなら（つまり `α` が nullable なら）、`FOLLOW(A)` に含まれる各終端記号 `b` ( `$ `も含む) に対して、表の項目 `Table[A, b]` に規則 `A -> α` を入れる。
2. 構文解析表のいずれかの項目 `Table[A, a]` に複数の規則が入る場合、その文法はLL(1)ではない。

つまり、LL(1)構文解析表が作成できるかどうかは、その文法がLL(1)であるかどうかの判定に等しいと言えます。

### LL(1)の問題点と限界

`LL(1)`は古典的でありかつ実用的でもありますが、アルゴリズムがシンプルである故の問題点や限界も存在します。この節では`LL(1)`の抱える問題点について述べます。

### 問題点1 - 最初の1トークンで構文要素を決められないことがある

例えば、以下の文法を考えてみましょう。

```
S -> a B
S -> a C
B -> b
C -> c
```

`S` から始まる場合、最初のトークンは常に `a` です。`a` の後に `b` が来れば `S -> a B` を、`c` が来れば `S -> a C` を選択すべきですが、最初の `a` だけではどちらの規則を適用すべきか決められません。これは `FIRST(a B)` と `FIRST(a C)` がともに `{a}` であり、積集合が空でないためです。

この問題は**左因子化**（left factoring）によって解決できます。左因子化では共通部分をくくり出すことで、LL(1)で解析可能な文法に変換します。

```
S  -> a S'
S' -> B
S' -> C
B  -> b
C  -> c
```

しかし、左因子化は常に適用できるわけではありません。

### 問題点2 - 左再帰の問題

$LL(1)$では左再帰を含む文法を扱うことができません。例えば、以下の文法は左再帰を含んでいます。

```
E -> E + T
E -> T
```

この文法は `E` の定義の最初に `E` 自身が出現しています（直接左再帰）。LL(1)パーサでこれをそのまま実装しようとすると、`E` を解析するために `E` を呼び出す…という無限再帰に陥ってしまいます。

左再帰は、以下のように文法を書き換えることで除去できます。

```
E  -> T E'
E' -> + T E'
E' -> ε
```

左再帰の除去は多くの場合に可能ですが、変換作業が煩雑になることも少なくありません。

## 5.8 LL(k) - LL(1)の拡張

LL(1)の限界を克服するために、LL(k)という概念が導入されました。kは先読みするトークン数を示します。kを増やすことで、より複雑な文法を扱えるようになりますが、解析表のサイズや計算量が増加します。

しかし、LL(k)でもすべての文脈自由言語を扱えるわけではありません。たとえば、文脈自由言語の例として以下のようなものがあります。

`a^i b^j (i >= j >= 1)`

これは `a` が `i` 回、その後に `b` が `j` 回現れる文字列で、`a` の数 `i` が `b` の数 `j` 以上であるような言語です。この言語はLL(k)文法では表現できませんが、後述するLR(1)文法では表現可能です。これは、LL(k)が解析できる言語のクラスがLR(1)よりも狭いことを示唆しています。

## 5.9 LR(0) - 最も単純な上向き構文解析

LR法は、**L**eft-to-right（左から右へ入力をスキャン）と**R**ightmost derivation（最右導出の逆をたどる）の略であり、上向き構文解析の代表的な手法群です。その中でも**LR(0)**は最も基本的なアルゴリズムであり、他のLR系の手法（SLR(1), LR(1), LALR(1)）の基礎となります。

LR法の基本的な考え方は、5.4節で説明した**シフト還元構文解析**です。入力を左から読み込み（シフト）、スタック上の記号列が文法規則の右辺と一致したら、それを左辺の非終端記号に置き換える（還元）という操作を繰り返します。

LR(0)を含むLR系の構文解析器は、このシフトと還元の判断を**構文解析表（Parsing Table）**に基づいて効率的に行います。構文解析表は、現在の**状態**と次に入力される**記号**（終端記号）に応じて、次に取るべき**アクション**（シフト、還元、受理、エラー）を決定します。

構文解析表を作成するためには、まず文法から**LR(0)項目（LR(0) item）**の集合を構築し、それらを**状態**として管理する必要があります。

### LR(0)項目と項目集合（状態）

**LR(0)項目**とは、文法規則の右辺の任意の位置にドット（・）を挿入したものです。ドットは、その規則の右辺のどこまでを認識したかを示すマーカーの役割を果たします。

例えば、`E -> E + T` という規則からは、以下の4つのLR(0)項目が生成されます。

- `E -> ・E + T` : まだ何も認識していない状態
- `E -> E・+ T` : `E` を認識し、次に `+` を期待する状態
- `E -> E +・T` : `E +` を認識し、次に `T` を期待する状態
- `E -> E + T・` : `E + T` をすべて認識し、還元可能な状態

LR(0)構文解析では、これらのLR(0)項目の**集合**を**状態**として扱います。構文解析器は、入力を読み進めながら、これらの状態間を遷移していきます。

### 閉包（Closure）とGOTO関数

状態（LR(0)項目集合）を構築するためには、**閉包（Closure）**と**GOTO関数**という二つの操作が必要です。

#### 閉包（Closure）

ある状態（項目集合）`I` の閉包 `closure(I)` は、その状態から遷移せずに認識できる可能性のあるすべての項目を含む集合です。具体的には、以下の手順で計算します。

1.  `closure(I)` を `I` で初期化する。
2.  `closure(I)` 内の項目 `[A -> α・Bβ]` （`B`は非終端記号）について、`B` から始まるすべての規則 `B -> γ` に対して、項目 `[B -> ・γ]` を `closure(I)` に追加する。
3.  新しい項目が追加されなくなるまで、ステップ2を繰り返す。

閉包操作により、ある状態において次に非終端記号 `B` が期待される場合、`B` を導出するために必要なすべての規則の初期状態（ドットが左端にある項目）がその状態に含まれることになります。

#### GOTO関数

GOTO関数 `goto(I, X)` は、状態 `I` において記号 `X` （終端記号または非終端記号）を読み込んだときに遷移する先の状態を計算します。

1.  状態 `I` 内のすべての項目 `[A -> α・Xβ]` について、ドットを一つ右に移動させた項目 `[A -> αX・β]` を集める。
2.  これらの新しい項目の集合に対して閉包操作を行い、結果を `goto(I, X)` とする。

### LR(0)状態機械の構築

文法からLR(0)構文解析器の状態機械（オートマトン）を構築する手順は以下の通りです。

1.  **文法の拡張**: 元の文法の開始記号を `S` とすると、新しい開始記号 `S'` と規則 `S' -> S` を追加します。これは、解析の終了（受理）を明確にするためです。
2.  **初期状態の作成**: 拡張された文法の初期項目 `[S' -> ・S]` を含む閉包 `closure({[S' -> ・S]})` を計算し、これを初期状態 `I0` とします。
3.  **状態の構築**:
    *   既に構築された状態 `I` と、文法中の各記号 `X` について `goto(I, X)` を計算します。
    *   `goto(I, X)` が空でなく、まだ状態として登録されていない新しい項目集合であれば、それを新しい状態として登録します。
    *   すべての状態からすべての記号に対するGOTO関数を計算し尽くすまで、このプロセスを繰り返します。

これにより、LR(0)項目の集合をノードとし、GOTO関数をエッジとする状態遷移図（LR(0)オートマトン）が構築されます。

### LR(0)構文解析表の作成

構築した状態機械（各状態 `Ii` と GOTO関数）から、構文解析表（ACTION表とGOTO表）を作成します。

1.  **ACTION表**:
    *   **シフト**: `goto(Ii, a) = Ij` （`a` は終端記号）の場合、`ACTION[i, a] = "shift j"` とします。これは、状態 `i` で終端記号 `a` を読み込んだら、スタックに `a` と状態 `j` をプッシュ（シフト）することを示します。
    *   **還元**: 状態 `Ii` に項目 `[A -> α・]` （`A ≠ S'`）が含まれる場合、**すべての**終端記号 `a` に対して `ACTION[i, a] = "reduce A -> α"` とします。これは、状態 `i` に到達し、規則 `A -> α` の右辺をすべて認識したので、スタックから `α` に対応する要素を取り除き、`A` をプッシュ（還元）することを示します。
    *   **受理**: 状態 `Ii` に項目 `[S' -> S・]` が含まれる場合、`ACTION[i, $]` （`$` は入力終了記号）に `"accept"` を設定します。
2.  **GOTO表**:
    *   `goto(Ii, A) = Ij` （`A` は非終端記号）の場合、`GOTO[i, A] = j` とします。これは、還元によって非終端記号 `A` がスタックにプッシュされた後、次に遷移すべき状態が `j` であることを示します。

### LR(0)の限界：コンフリクト

LR(0)構文解析表を作成する際、ACTION表の同じマスに複数のアクションが書き込まれることがあります。これを**コンフリクト**と呼び、LR(0)法では解析できない文法であることを示します。

-   **シフト/還元コンフリクト (Shift/Reduce Conflict)**: 同じマスに `shift` アクションと `reduce` アクションが入る場合。入力記号をシフトして解析を続けるべきか、規則を還元すべきか決定できません。
-   **還元/還元コンフリクト (Reduce/Reduce Conflict)**: 同じマスに複数の `reduce` アクションが入る場合。どの規則で還元すべきか決定できません。

LR(0)法は、還元を決定する際に次に入力される記号（先読み記号）を全く考慮しないため、多くの実用的な文法でコンフリクトが発生します。

### 具体例：LR(0)状態機械と解析表の構築

簡単な文法を使って、LR(0)の状態機械と解析表を構築してみましょう。

**文法 G1:**

```
(0) S' -> E
(1) E -> E + T
(2) E -> T
(3) T -> id
```

**LR(0)項目集合（状態）:**

-   **I0**: `closure({[S' -> ・E]})` = `{ [S' -> ・E], [E -> ・E + T], [E -> ・T], [T -> ・id] }`
-   **I1**: `goto(I0, E)` = `closure({[S' -> E・], [E -> E・+ T]})` = `{ [S' -> E・], [E -> E・+ T] }`
-   **I2**: `goto(I0, T)` = `closure({[E -> T・]})` = `{ [E -> T・] }`
-   **I3**: `goto(I0, id)` = `closure({[T -> id・]})` = `{ [T -> id・] }`
-   **I4**: `goto(I1, +)` = `closure({[E -> E + ・T]})` = `{ [E -> E + ・T], [T -> ・id] }`
-   **I5**: `goto(I4, T)` = `closure({[E -> E + T・]})` = `{ [E -> E + T・] }`
-   **I6**: `goto(I4, id)` = `closure({[T -> id・]})` = `{ [T -> id・] }` ( = I3 )

**構文解析表:**

| 状態 | ACTION        |       |      | GOTO |   |
| :--- | :------------ | :---- | :--- | :--- | :- |
|      | **id**        | **+** | **$** | **E** | **T** |
| **0** | s3            |       |      | 1    | 2  |
| **1** |               | s4    | acc  |      |    |
| **2** | **r2 / ???** | **r2** | **r2** |      |    |  <-- **コンフリクト発生！**
| **3** | **r3 / ???** | **r3** | **r3** |      |    |  <-- **コンフリクト発生！**
| **4** | s6            |       |      |      | 5  |
| **5** | **r1 / ???** | **r1** | **r1** |      |    |  <-- **コンフリクト発生！**
| **6** | **r3 / ???** | **r3** | **r3** |      |    |  <-- **コンフリクト発生！** (I3と同じ)

（`si` は shift i, `rj` は reduce j (規則jを使用), `acc` は accept）

この表を見ると、状態2, 3, 5, 6において、すべての終端記号に対して還元アクション（r2, r3, r1）が書き込まれています。これはLR(0)の定義通りですが、例えば状態2で次に入力が `+` の場合、`E -> T` で還元すべきか、`+` をシフトすべきか判断できません（シフト/還元コンフリクト）。

このように、LR(0)は非常に単純ですが、扱える文法のクラスは限定的です。このコンフリクトを解消するために、次に説明するSLR(1)法では**FOLLOW集合**という先読み情報を利用します。

## 5.10 SLR(1) - FOLLOW集合でコンフリクト解消を試みる

**SLR(1)**（Simple LR(1)）法は、LR(0)法のコンフリクトを解消するために、**FOLLOW集合**という先読み情報を導入する手法です。LR(0)では、還元アクション `reduce A -> α` を決定する際、次の入力記号に関わらず、項目 `[A -> α・]` を含む状態では常に還元を試みていました。これがコンフリクトの主な原因でした。

SLR(1)では、還元 `reduce A -> α` を行う条件をより限定します。具体的には、状態 `Ii` に項目 `[A -> α・]` が含まれていても、次の入力記号 `a` が **`FOLLOW(A)`** （非終端記号 `A` の後に現れうる終端記号の集合）に含まれている場合にのみ、還元アクション `ACTION[i, a] = "reduce A -> α"` を設定します。

### FOLLOW集合の計算

FOLLOW集合の計算方法は、5.7節のLL(1)で説明したものと同じです。簡単に復習しましょう。

1.  すべての非終端記号 `A` について `FOLLOW(A)` を空集合で初期化する。
2.  開始記号 `S'` の `FOLLOW(S')` に入力終了記号 `$` を追加する。
3.  文法中の各規則 `B -> αAβ` について、
    *   `FIRST(β)` に含まれる `ε` 以外のすべての終端記号を `FOLLOW(A)` に追加する。
    *   もし `β` が `ε` を導出可能（`nullable(β)` が真）ならば、`FOLLOW(B)` のすべての記号を `FOLLOW(A)` に追加する。
4.  新しい記号が追加されなくなるまで、ステップ3を繰り返す。

### SLR(1)構文解析表の作成

SLR(1)の構文解析表の作成手順は、LR(0)とほとんど同じですが、**還元アクションの決定方法**だけが異なります。

1.  **文法の拡張**: LR(0)と同様。
2.  **LR(0)項目集合（状態）の構築**: LR(0)と同様に、閉包とGOTO関数を用いて状態機械を構築します。
3.  **FOLLOW集合の計算**: 上記の手順で、すべての非終端記号のFOLLOW集合を計算します。
4.  **構文解析表の作成**:
    *   **ACTION表**:
        *   **シフト**: `goto(Ii, a) = Ij` （`a` は終端記号）の場合、`ACTION[i, a] = "shift j"`。 (LR(0)と同じ)
        *   **還元**: 状態 `Ii` に項目 `[A -> α・]` （`A ≠ S'`）が含まれる場合、**`FOLLOW(A)` に含まれる各終端記号 `a` に対してのみ**、`ACTION[i, a] = "reduce A -> α"` を設定します。 (ここがLR(0)と異なる！)
        *   **受理**: 状態 `Ii` に項目 `[S' -> S・]` が含まれる場合、`ACTION[i, $]` に `"accept"` を設定します。 (LR(0)と同じ)
    *   **GOTO表**: `goto(Ii, A) = Ij` （`A` は非終端記号）の場合、`GOTO[i, A] = j`。 (LR(0)と同じ)

### SLR(1)によるコンフリクト解消の例

先ほどの文法 G1 でSLR(1)構文解析表を作成してみましょう。

**文法 G1:**

```
(0) S' -> E
(1) E -> E + T
(2) E -> T
(3) T -> id
```

**FOLLOW集合:**

-   `FOLLOW(S')` = `{ $ }`
-   `FOLLOW(E)` = `{ +, $ }` （規則1より `+`、規則0とS'のFOLLOW集合より `$`）
-   `FOLLOW(T)` = `{ +, $ }` （規則1より `FOLLOW(E)` を継承、規則2より `FOLLOW(E)` を継承）

**SLR(1)構文解析表:**

| 状態 | ACTION        |       |      | GOTO |   |
| :--- | :------------ | :---- | :--- | :--- | :- |
|      | **id**        | **+** | **$** | **E** | **T** |
| **0** | s3            |       |      | 1    | 2  |
| **1** |               | s4    | acc  |      |    |
| **2** |               | **r2** | **r2** |      |    |  <-- `FOLLOW(E)` = {+, $} のみ還元
| **3** |               | **r3** | **r3** |      |    |  <-- `FOLLOW(T)` = {+, $} のみ還元
| **4** | s6            |       |      |      | 5  |
| **5** |               | **r1** | **r1** |      |    |  <-- `FOLLOW(E)` = {+, $} のみ還元
| **6** |               | **r3** | **r3** |      |    |  <-- `FOLLOW(T)` = {+, $} のみ還元 (I3と同じ)

LR(0)ではコンフリクトが発生していた状態2, 3, 5, 6を見てみましょう。

-   **状態2**: 項目 `[E -> T・]` を含む。`FOLLOW(E) = {+, $}` なので、`+` と `$` の列にのみ `r2` を設定します。`id` の列にはアクションが設定されず、コンフリクトは解消されました。
-   **状態3**: 項目 `[T -> id・]` を含む。`FOLLOW(T) = {+, $}` なので、`+` と `$` の列にのみ `r3` を設定します。同様にコンフリクトは解消されました。
-   **状態5**: 項目 `[E -> E + T・]` を含む。`FOLLOW(E) = {+, $}` なので、`+` と `$` の列にのみ `r1` を設定します。コンフリクトは解消されました。
-   **状態6**: 項目 `[T -> id・]` を含む。状態3と同じ理由でコンフリクトは解消されました。

このように、SLR(1)はFOLLOW集合を用いることで、LR(0)よりも多くの文法（SLR(1)文法）を解析できるようになります。

### SLR(1)の限界

しかし、SLR(1)でもコンフリクトを解消できない場合があります。FOLLOW集合は、文法全体から見てその非終端記号の後に何が来るかを示すものであり、特定の状態における文脈を十分に考慮できていないためです。

**例：SLR(1)でコンフリクトが発生する文法 G2**

```
(0) S' -> S
(1) S -> L = R
(2) S -> R
(3) L -> * R
(4) L -> id
(5) R -> L
```

この文法は、代入文のような構造を表します。この文法でLR(0)項目集合とSLR(1)解析表を作成すると、ある状態でシフト/還元コンリフクトが発生します（詳細は省略）。これは、状態 `I` に `[R -> L・]` という項目があり、かつ次の入力が `=` である場合に、`FOLLOW(R)` に `=` が含まれているため `reduce 5` が設定される一方で、別の項目 `[S -> L・= R]` により `shift` アクションも設定されるためです。

このコンフリクトは、状態 `I` において `R -> L` で還元した後、次が `=` であることは文法的にありえないにも関わらず、`FOLLOW(R)` という大域的な情報だけではそれを区別できないために発生します。

この問題を解決するには、各状態におけるより詳細な文脈情報、すなわち「その項目に到達した際に、次に何が来ることを期待しているか」という情報が必要になります。これが次に説明するLR(1)法のアイデアです。

## 5.11 LR(1) - より強力な先読み情報を持つ項目

**LR(1)**法は、SLR(1)法の限界を克服するために、各項目に**先読み記号（lookahead symbol）**という、より強力な文脈情報を付加する手法です。これにより、SLR(1)では区別できなかった状態を区別し、コンフリクトを解消することが可能になります。LR(1)法は、理論上、LR(k)文法（k≧1）の中で最も強力な解析能力を持ちます。

### LR(1)項目

LR(1)項目は、LR(0)項目に先読み記号（終端記号）を追加したもので、以下の形式で表されます。

```text
[A -> α・β, a]
```

-   `A -> α・β`: LR(0)項目部分。`α` を認識し、次に `β` を期待する状態。
-   `a`: 先読み記号。この項目が最終的に還元 `A -> αβ` に成功した場合、その直後に入力されることが期待される終端記号。

例えば、`[E -> E・+ T, $]` というLR(1)項目は、「`E` を認識し、次に `+` を期待しており、もしこの `E` が最終的に開始記号 `S'` まで還元された場合、入力の終わり `$` が来るはずだ」という文脈情報を含んでいます。

### LR(1)閉包（Closure）とGOTO関数

LR(1)項目集合（状態）を構築するための閉包とGOTO関数も、先読み記号を考慮するように拡張されます。

#### LR(1)閉包

状態 `I` のLR(1)閉包 `closure(I)` は、以下の手順で計算します。

1.  `closure(I)` を `I` で初期化する。
2.  `closure(I)` 内の各項目 `[A -> α・Bβ, a]` （`B`は非終端記号）について、`B` から始まるすべての規則 `B -> γ` に対して、**`FIRST(βa)` に含まれる各終端記号 `b`** について、項目 `[B -> ・γ, b]` を `closure(I)` に追加する。
    *   `FIRST(βa)` は、`β` の後に `a` が続く記号列から導かれうる最初の終端記号の集合です。`β` が `ε` を含めば `a` も含まれます。
3.  新しい項目が追加されなくなるまで、ステップ2を繰り返す。

LR(0)閉包との違いは、新しい項目 `[B -> ・γ, b]` を追加する際に、元の項目の `β` と先読み記号 `a` から計算される `FIRST(βa)` を使って、新しい項目の先読み記号 `b` を決定する点です。これにより、より正確な文脈情報が伝播します。

#### LR(1) GOTO関数

GOTO関数 `goto(I, X)` の計算方法はLR(0)と似ていますが、LR(1)項目を扱います。

1.  状態 `I` 内のすべての項目 `[A -> α・Xβ, a]` について、ドットを一つ右に移動させた項目 `[A -> αX・β, a]` を集める。
2.  これらの新しい項目の集合に対して **LR(1)閉包** 操作を行い、結果を `goto(I, X)` とする。

### LR(1)構文解析表の作成

LR(1)構文解析表の作成手順もSLR(1)と似ていますが、還元アクションの決定にFOLLOW集合ではなく、**LR(1)項目の先読み記号**を使用します。

1.  **文法の拡張**: LR(0)と同様。
2.  **LR(1)項目集合（状態）の構築**:
    *   初期状態 `I0` は `closure({[S' -> ・S, $]})` とする。
    *   GOTO関数を用いて、到達可能なすべてのLR(1)状態を構築する。
3.  **構文解析表の作成**:
    *   **ACTION表**:
        *   **シフト**: 状態 `Ii` に項目 `[A -> α・aβ, b]` が含まれ、`goto(Ii, a) = Ij` （`a` は終端記号）の場合、`ACTION[i, a] = "shift j"`。
        *   **還元**: 状態 `Ii` に項目 `[A -> α・, a]` （`A ≠ S'`）が含まれる場合、**その項目の先読み記号 `a` に対してのみ**、`ACTION[i, a] = "reduce A -> α"` を設定します。 (ここがSLR(1)と異なる！)
        *   **受理**: 状態 `Ii` に項目 `[S' -> S・, $]` が含まれる場合、`ACTION[i, $]` に `"accept"` を設定します。
    *   **GOTO表**: `goto(Ii, A) = Ij` （`A` は非終端記号）の場合、`GOTO[i, A] = j`。 (LR(0)/SLR(1)と同じ)

### LR(1)によるコンフリクト解消の例

先ほどSLR(1)でコンフリクトが発生した文法 G2 をLR(1)で解析してみましょう。

**文法 G2:**

```
(0) S' -> S
(1) S -> L = R
(2) S -> R
(3) L -> * R
(4) L -> id
(5) R -> L
```

SLR(1)でコンフリクトが発生したのは、ある状態（仮に `Ik` とする）に `[R -> L・]` という項目があり、次の入力が `=` の場合でした。`FOLLOW(R)` には `$` が含まれるため（規則2 `S -> R` より）、SLR(1)では `ACTION[k, $]` に `reduce 5` が設定されます。しかし、この文法では `L` の後には `=` か `$` しか来ません。

LR(1)で状態を構築すると、この状態 `Ik` に対応するLR(1)状態は、先読み記号によって複数の状態に分割される可能性があります。例えば、`L` の後に `=` が期待される文脈から到達した状態には `[R -> L・, =]` という項目が含まれ、`L` の後に `$` が期待される文脈（例えば `S -> R` の場合）から到達した状態には `[R -> L・, $]` という項目が含まれるようになります。

これにより、LR(1)構文解析表では以下のようになります。

-   状態 `Ij` （`[R -> L・, =]` を含む）: `ACTION[j, =] = "reduce 5"`
-   状態 `Ik` （`[R -> L・, $]` を含む）: `ACTION[k, $] = "reduce 5"`

もし、状態 `Ij` に `[S -> L・= R, $]` のようなシフトにつながる項目も含まれていたとしても、還元アクションは `=` の列にしか設定されないため、`=` におけるシフト/還元コンフリクトは発生しません。

このように、LR(1)は項目ごとに正確な先読み記号を持つことで、SLR(1)よりも精密な判断が可能になり、より多くの文法（LR(1)文法）を解析できます。

### LR(1)の欠点：解析表のサイズ

LR(1)法の最大の欠点は、状態数が非常に多くなることです。LR(0)項目が同じでも、先読み記号が異なれば別のLR(1)状態となるため、状態数はSLR(1)（LR(0)状態数と同じ）に比べて大幅に増加する傾向があります。これは、構文解析表のサイズが巨大になることを意味し、メモリ使用量や生成時間の観点から実用的でない場合があります。

この問題を解決するために、次に説明するLALR(1)法が考案されました。

## 5.12 LALR(1) - 実用性と解析能力のバランス

**LALR(1)**（Look-Ahead LR）法は、LR(1)法の強力な解析能力を維持しつつ、構文解析表のサイズをSLR(1)法と同程度に抑えることを目的とした、実用的な上向き構文解析アルゴリズムです。多くの構文解析器生成系（YaccやBisonなど）で採用されている標準的な手法です。

### LALR(1)のアイデア：状態のマージ

LALR(1)法の基本的なアイデアは、LR(1)状態の中で、**LR(0)項目部分（コア）が全く同じ状態を一つにマージ（統合）する**ことです。

LR(1)状態は `[A -> α・β, a]` の形式でした。このうち `A -> α・β` の部分を**コア (core)** と呼びます。LALR(1)では、コアが同じである複数のLR(1)状態を一つのLALR(1)状態にまとめます。

例えば、LR(1)で以下のような二つの状態があったとします。

-   状態 `I`: `{ [A -> α・, a], [B -> γ・, c] }`
-   状態 `J`: `{ [A -> α・, b], [B -> γ・, d] }`

これらの状態は、コア `A -> α・` と `B -> γ・` が共通です。LALR(1)では、これらを一つの状態 `K` にマージします。マージ後の状態 `K` に含まれる項目の先読み記号は、マージ元のすべての先読み記号を合わせたものになります。

-   状態 `K`: `{ [A -> α・, a/b], [B -> γ・, c/d] }`
    （ここで `a/b` は先読み記号が `a` または `b` であることを示す）

このように状態をマージすることで、LALR(1)の状態数はLR(0)の状態数と同じになります。

### LALR(1)構文解析表の作成

LALR(1)構文解析表は、マージされたLALR(1)状態に基づいて作成されます。

1.  **LR(1)状態の構築**: まず、LR(1)法のアルゴリズムに従って、すべてのLR(1)状態（項目集合）を構築します。
2.  **状態のマージ**: コア（LR(0)項目部分）が同じLR(1)状態を特定し、それらを一つのLALR(1)状態にマージします。マージ後の項目の先読み記号は、マージ元の項目の先読み記号の和集合となります。
3.  **構文解析表の作成**: マージ後のLALR(1)状態を用いて、LR(1)と同様の手順でACTION表とGOTO表を作成します。
    *   **シフト**: LR(1)と同様。
    *   **還元**: 状態 `Ii` に項目 `[A -> α・, a]` が含まれる場合、先読み記号 `a` に対して `ACTION[i, a] = "reduce A -> α"` を設定します。マージによって一つの項目に複数の先読み記号が含まれる場合（例：`[A -> α・, a/b]`）、`a` と `b` の両方の列に還元アクションを設定します。
    *   **受理**: LR(1)と同様。
    *   **GOTO**: LR(1)と同様（マージされた状態への遷移となります）。

### LALR(1)の利点と欠点

#### 利点

-   **解析表サイズ**: LALR(1)の解析表のサイズ（状態数）は、LR(0)やSLR(1)と同程度であり、LR(1)に比べて大幅に小さくなります。これにより、メモリ使用量や生成時間の点で実用的です。
-   **解析能力**: ほとんどの実用的なプログラミング言語の文法はLALR(1)で解析可能です。SLR(1)よりも強力であり、LR(1)で解析可能な文法の大部分をカバーします。

#### 欠点

-   **還元/還元コンフリクトの可能性**: LR(1)状態をマージする際に、異なる先読み記号を持つ還元項目が同じLALR(1)状態にまとめられることがあります。もし、マージ元のLR(1)状態では異なるアクション（例えば、異なる規則での還元）が割り当てられていた場合、マージ後のLALR(1)状態では同じ入力記号に対して複数の還元アクションが設定され、**還元/還元コンフリクト**が発生する可能性があります。これはLR(1)では発生しなかったコンフリクトです。
    *   ただし、このようなコンフリクトが発生する文法は稀であり、実用上問題になることは少ないとされています。
-   **シフト/還元コンフリクト**: LALR(1)では、LR(1)で解決されていたシフト/還元コンフリクトが解消されるとは限りません（ただし、新たに発生することもありません）。

### LALR(1)の位置づけ

LALR(1)は、LR(1)の強力な解析能力と、SLR(1)のコンパクトな解析表サイズという、両者の利点を高いレベルで両立させた、非常にバランスの取れた実用的なアルゴリズムです。そのため、Yacc、Bison、PLY（Python Lex-Yacc）など、多くの構文解析器生成系で標準的に採用されています。

もしLALR(1)でコンフリクトが発生した場合、文法を修正するか、より強力な（しかし一般的には効率が劣るか、実装が複雑な）GLR（Generalized LR）などのアルゴリズムを検討することになります。

---

ここまでで、代表的な上向き構文解析アルゴリズムであるLR(0), SLR(1), LR(1), LALR(1)について、その基本的な考え方、構築手順、利点、限界を順に見てきました。次は、近年注目を集めている別のアプローチ、Parsing Expression Grammar (PEG) について見ていきましょう。

## 5.13 - Parsing Expression Grammar(PEG) - 構文解析アルゴリズムのニューカマー

2000年代に入るまで、構文解析手法の主流はLR法の変種であり、上向き構文解析アルゴリズムでした。その理由の一つに、先読みを前提とする限り、従来のLL法はLR法より表現力が弱いという弱点がありました。下向き型でもバックトラックを用いれば幅広い言語を表現できることは比較的昔から知られていましたが、バックトラックによって解析時間が最悪で指数関数時間になるという弱点があります。そのため、コンパイラの教科書として有名な、いわゆるドラゴンブックでも現実的ではないといった記述がありました（初版にはあったはずだが、第二版にも該当記述があるかは要確認）。しかし、2004年にBryan Fordによって提案されたParsing Expression Grammar（PEG）はそのような状況を変えました。

PEGはおおざっぱに言ってしまえば、無制限な先読みとバックトラックを許す下向き型の構文解析手法の一つです。決定的文脈自由言語に加えて一部の文脈依存言語を取り扱うことができますし、Packrat Parsingという最適化手法によって線形時間で構文解析を行うことが保証されているというとても良い性質を持っています。さらに、LL法やLR法でほぼ必須であった字句解析器が要らず、アルゴリズムも非常にシンプルであるため、ここ十年くらいで解析表現手法をベースとした構文解析生成系が数多く登場しました。

他人事のように書いていますが、筆者が大学院時代に専門分野として研究していたのがまさしくこのPEGでした。Python 3.9ではPEGベースの構文解析器が採用されるなど、PEGは近年採用されるケースが増えています。

3章で既にPEGを用いた構文解析器を自作したのを覚えているでしょうか。たとえば、配列の文法を表現した以下のPEGがあるとします。

```text
array = LBRACKET RBRACKET | LBRACKET {value {COMMA value}} RBRACKET ;
```

　このPEGに対応するJavaの構文解析器（メソッド）は以下のようになるのでした。

```java
    public Ast.JsonArray parseArray() {
        int backup = cursor;
        try {
            // LBRACKET RBRACKET
            parseLBracket();
            parseRBracket();
            return new Ast.JsonArray(new ArrayList<>());
        } catch (ParseException e) {
            cursor = backup;
        }

        // LBRACKET
        parseLBracket();
        List<Ast.JsonValue> values = new ArrayList<>();
        // value
        var value = parseValue();
        values.add(value);
        try {
            // {value {COMMA value}}
            while (true) {
                parseComma();
                value = parseValue();
                values.add(value);
            }
        } catch (ParseException e) {
            // RBRACKET
            parseRBracket();
            return new Ast.JsonArray(values);
        }
    }
```

PEGの特色は、

```java
        int backup = cursor;
```

という行によって、解析を始める時点でのソースコード上の位置を保存しておき、もし解析に失敗したら以下のように「巻き戻す」ところにあります。「巻き戻した」位置から次の分岐を試そうとするのです。

```java
        } catch (ParseException e) {
            cursor = backup;
        }
        // LBRACKET
        parseLBracket();
        // ...
```

なお、PEGの挙動を簡単に説明するために3章および本章では例外をスロー/キャッチするという実装にしていますが、現実にはこのような実装にするとオーバーヘッドが大きすぎるため、実用的なPEGパーザでは例外を使わないことが多いです。

一般化すると、PEGの挙動は以下の8つの要素を使って説明することができます。

1. 空文字列： ε
2. 終端記号： t
3. 非終端記号： N
4. 連接： e1 e2
5. 選択： e1 / e2
6. 0回以上の繰り返し： e*
7. 肯定述語： &e
8. 否定述語： !e
  
  次節以降では、この8つの要素がそれぞれどのような意味を持つかを説明していきます。説明のために

```java
match(e, v) == Success(consumed, rest) 
```

や

```java
match(e, v) == Failure
```

というJava言語ライクな記法を使います。

たとえば、

```java
match("x", "xy") == Success("x", "y")`
```

は式`x`が文字列`"xy"`にマッチして残りの文字列が`"y"`であることを示します。また、

```java
match("xy", "x") == Failure
```

は式`"xy"`が文字列`"x"`にマッチしないことを表現します。

### 空文字列

空文字列εは0文字**以上**の文字列にマッチします。たとえば、

```java
match(ε, "") == Success("", "")
```

が成り立つだけでなく、

```java
match(ε, "x") ==  Success("", "x")
```

や

```java
match(ε, "xyz") == Success("", "xyz")
```

も成り立ちます。εは**あらゆる文字列**にマッチすると言い換えることができます。

### 終端記号

終端記号`t`は1文字以上の長さで特定のアルファベットで**始まる**文字列にマッチします。たとえば、

```java
match(x, "x") == Success("x", "")
```

や

```java
match(x, "xy") == Success("x", "y")
```

が成り立ちます。一方、

```java
match(x, "y") == Failure
```

ですし、

```java
match(x, "") == Failure
```

です。εの場合と同じく「残りの文字列」があってもマッチする点に注意してください。

### 選択

`e1`と`e2`は共に式であるものとします。このとき、


```text
e1 / e2
```

に対する`match(e1 / e2, s)`は以下のような動作を行います。

1. `match(e1, s)`を実行する
2. 1.が成功していれば、sのサフィックスを返し、成功する
3. 1.が失敗した場合、`match(e2, s)`を実行し、結果を返す

### 選択

`e1`と`e2`は共に式であるものとします。このとき、

```text
e1 e2
```

　に対する`match(e1 e2, s)`は以下のような動作を行います。

1. `match(e1, s)`を実行する
2. 1.が成功したとき、結果を`Success(s1,s2)`とする。この時、`match(e2,s2)`を実行し、結果を返す
3. 1.が失敗した場合、その結果を返す

### 非終端記号

あるPEGの規則Nがあったとします。

```text
N <- e
```

`match(N, s)`は以下のような動作を行います。

1. `N`に対応する規則を探索する（`N <- e`が該当）
2. `N`の呼び出しから戻って来たときのために、スタックに現在位置`p`を退避
3. `match(e, s)`を実行する。結果を`M`とする。
4. スタックに退避した`p`を戻す
5. `M`を全体の結果とする

### 0回以上の繰り返し

`e`は式であるものとします。

```text
e*
```

このとき、eと文字列sの照合を行うために以下のような動作を行います。

1. `match(e,s)`を実行する
2. 1.が成功したとき（`n`回目）、結果を`Success(s_n,s_(n+1))`とする。`s`を`s_(n+1)`に置き換えて、1.に戻る
3. 1.が失敗した場合（`n`回目）、結果を`Success(s_1...s_n, s[n...])`とする

`e*`は「0回以上の繰り返し」を表現するため、一回も成功しない場合でも全体が成功するのがポイントです。なお、`e*`は規則

```
H <- e H / ε
```

に対して`H`を呼び出すことの構文糖衣であり、全く同じ意味になります。

### 肯定述語

`e`は式であるものとします。このとき、

```text
&e
```
　
は`match(&e,s)`を実行するために、以下のような動作を行います。

1. `match(e,s)`を実行する
2-1. 1.が成功したとき：結果を`Success("", s)`とする
2-2. 1.が失敗した場合：結果は`Failure()`とする

肯定述語は成功したときにも「残り文字列」が変化しません。肯定述語`&e`は後述する否定述語`!!`を二重に重ねたものに等しいことが知られています。


### 否定述語

`e`は式であるものとします。このとき、

```text
!e
```
　
は`match(!e,s)`を実行するために以下のような動作を行います。

1. `match(e,s)`を実行する
2-1. 1.が成功したとき：結果を`Failure()`とする
2-2. 1.が失敗した場合：結果は`Success("", s)`とする

否定述語も肯定述語同様、成功しても「残り文字列」が変化しません。

前述した`&e = !!e`は論理における二重否定の除去に類似するものということができます。

### PEGの操作的意味論

ここまでで、PEGを構成する8つの要素について説明してきましたが、実際のところは厳密さに欠けるものでした。より厳密に説明すると以下のようになります（Ford:04を元に改変）。先程までの説明では、`Success(s1, s2)`を使って、`s1`までは読んだことを、残り文字列が`s2`であることを表現してきました。ここではペア`(n, x)`で結果を表しており、`n`はステップ数を表すカウンタで`x`は残り文字列または`f`（失敗を表す値）となります。⇒を用いて、左の状態になったとき右の状態に遷移することを表現しています。

```
1. 空文字列: 
  (ε,x) ⇒ (1,ε) （全ての x ∈ V ∗ Tに対して）。
2. 終端記号(成功した場合): 
  (a,ax) ⇒ (1,a) （a ∈VT , x ∈V ∗ T である場合）。
3. 終端記号(失敗した場合):
  (a,bx) ⇒ (1, f) iff a ≠ b かつ (a,ε) ⇒ (1, f)。
4. 非終端記号:
  (A,x) ⇒ (n + 1,o) iff A ← e ∈ R かつ(e,x) ⇒ (n,o)。
5. 連接(成功した場合): 
  (e1, x1 x2 y) ⇒ (n1,x1) かつ　(e2, x2 y) ⇒ (n2, x2) のとき、 (e1 e2,x1 x2 y) ⇒ (n1 + n2 + 1, x1 x2)。
6. 連接(失敗した場合１): 
  (e1, x) ⇒ (n1, f) ならば　(e1 e2,x) ⇒ (n1 + 1, f). もし　e1が失敗したならば、e1e2はe2を試すことなく失敗する。
7. 連接(失敗した場合２): 
  (e1, x1 y) ⇒ (n1,x1) かつ　(e2,y) ⇒ (n2, f) ならば (e1e2,x1y) ⇒ (n1 + n2 + 1, f)。
8. 選択(場合１): 
  (e1, x y) ⇒ (n1,x) ならば (e1/e2,xy) ⇒ (n1 +1,x)。
9. 選択(場合２): 
  (e1, x) ⇒ (n1, f) かつ (e2,x) ⇒ (n2,o) ならば (e1 / e2,x) ⇒ (n1 + n2 + 1,o)。
10. 0回以上の繰り返し (繰り返しの場合): 
  (e, x1 x2 y) ⇒ (n1,x1) かつ　(e∗,x2 y) ⇒ (n2, x2) ならば (e∗,x1 x2 y) ⇒ (n1 + n2 +1,x1 x2)。
11. 0回以上の繰り返し (停止の場合）: 
  (e,x) ⇒ (n1, f) ならば (e∗,x) ⇒ (n1 + 1, ε)。
12. 否定述語（場合１): 
  (e,xy) ⇒ (n,x) ならば (!e,xy) ⇒ (n + 1, f)。
13. 否定述語（場合２): 
  (e,x) ⇒ (n, f) ならば (!e,x) ⇒ (n + 1, ε)。
```

## 5.14 - Packrat Parsing

素のPEGは非常に単純でいて、とても幅広い範囲の言語を取り扱うことができます。しかし、PEGには一つ大きな弱点があります。最悪の場合、解析時間が指数関数時間になってしまうことです。現実的にはそのようなケースは稀であるという指摘ありますが（論文を引用）、原理的にはそのような弱点があります。Packrat Parsingはメモ化という技法を用いることでPEGで表現される言語を線形時間で解析可能にします。

メモ化という技法自体をご存じでない読者の方も多いかもしれないので、まずメモ化について説明します。

### fibメソッド

　メモ化の例でよく出てくるのはN番目のフィボナッチ数を求める`fib`関数です。この書籍をお読みの皆様ならお馴染みかもしれませんが、N番目のフィボナッチ数F(n)は次のようにして定義されます：

```
F(0) = 1
F(1) = 1
F(n) = F(n - 1) + F(n - 2)
```

　この再帰的定義を素朴にJavaのメソッドとして書き下したのが以下のfibメソッドになります。

```java
public class Main {
    public static long fib(long n) {
        if(n == 0 || n == 1) return 1L;
        else return fib(n - 1) + fib(n - 2); 
    }
    public static void main(String[] args) {
        System.out.println(fib(5)); // 120
    }
}
```

このプログラムを実行すると、コメントにある通り120が出力されます。しかし、このfibメソッドには重大な欠点があります。それは、nが増えると計算量が指数関数的に増えてしまうことです。たとえば、上のfibメソッドを使うと`fib(30)`くらいまではすぐに計算することができます。しかし、`fib(50)`を求めようとすると皆さんのマシンではおそらく数十秒はかかるでしょう。

　フィボナッチ数を求めたいだけなのに数十秒もかかってはたまったものではありません。

### fib関数のメモ化

そこで出てくるのがメモ化というテクニックです。一言でいうと、メモ化とはある引数nに対して計算した結果f(n)をキャッシュしておき、もう一度同じnに対して呼び出されたときはキャッシュした結果を返すというものです。早速、fibメソッドをメモ化してみましょう。

メモ化されたfibメソッドは次のようになります。

```java
import java.util.*;
public class Main {
    private static Map<Long, Long> cache = new HashMap<>();
    public static long fib(long n) {
        Long value = cache.get(n);
        if(value != null) return value;

        long result;
        if(n == 0 || n == 1) {
            result = 1L;
        } else {
            result = fib(n - 1) + fib(n - 2);
        }
        cache.put(n, result);
        return result;
    }
    public static void main(String[] args) {
        System.out.println(fib(50)); // 20365011074
    }
}
```

`fib(50)`の結果はコメントにある通りですが、今度は一瞬で結果がかえってきたのがわかると思います。メモ化されたfibメソッドでは同じnに対する計算は二度以上行われないので、nが増えても実行時間は線形にしか増えません。つまり、fib(50)の実行時間は概ねfib(25)の二倍であるということです。

ただし、計算量に詳しい識者の方は「おいおい。整数同士の加算が定数時間で終わるという仮定はおかしいんじゃないかい？」なんてツッコミを入れてくださるかもしれませんが、そこを議論するとややこしくなるので整数同士の加算はたかだか定数時間で終わるということにします。

`fib`メソッドのメモ化でポイントとなるのは、記憶領域（`cache`に使われる領域）と引き換えに最悪計算量を指数関数時間から線形時間に減らせるということです。また、メモ化する対象となる関数は一般的には副作用がないものに限定されます。というのは、メモ化というテクニックは「同じ引数を渡せば同じ値が返ってくる」ことを暗黙の前提にしているからです。

次の項ではPEGをナイーヴに実装した`parse`関数をまずお見せして、続いてそれをメモ化したバージョン（Packrat parsing）をお見せすることにします。`fib`メソッドのメモ化と同じようにPEGによる構文解析もメモ化できることがわかるでしょう。

### parseメソッド

　ここからは簡単なPEGで記述された文法を元に構文解析器を組み立てていくわけですが、下記のような任意個の`()`で囲まれた`0`の構文解析器を作ります。

```
A <- "(" A ")"
   / "(" A A ")"
   / "0"
```

　単純過ぎる例にも思えますが、メモ化の効果を体感するにはこれで十分です。早速構文解析器を書いていきましょう。

```java
sealed interface ParseResult permits ParseResult.Success, ParseResult.Failure {
    public abstract String rest();
    record Success(String value, String rest) implements ParseResult {}
    record Failure(String rest) implements ParseResult {}
}
class ParseError extends RuntimeException {
    public final String rest;
    public String rest() {
        return rest;
    }
    ParseError(String rest) {
        this.rest = rest;
    }
}
public class Parser {
    private static boolean isEnd(String string) {
        return string.length() == 0;
    }
    public static ParseResult parse(String input) {
        String start = input;
        try {
            // "(" A ")"
            if(isEnd(input) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            var result = parse(input.substring(1));
            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;

            input = success.rest();
            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        try {
            // "(" A A ")"
            if((isEnd(input)) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            var result = parse(input.substring(1));
            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;
            input = success.rest();

            result = parse(input);

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            success = (ParseResult.Success)result;
            input = success.rest();

            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), success.rest().substring(1));
        } catch (ParseError error) {
            input = start;
        }

        if(isEnd(input) || input.charAt(0) != '0') {
            return new ParseResult.Failure(input);
        }

        return new ParseResult.Success(input.substring(0, 1), input.substring(1));
    }
}
```

このプログラムを使うと以下のように構文解析を行うことが出来ます。

```java
jshell> Parser.parse("(");
$25 ==> Failure[rest=]
jshell> Parser.parse("()");
$26 ==> $26 ==> Failure[rest=)]
jshell> Parser.parse("(0)");
$27 ==> Success[value=), rest=]
```
　
しかし、この構文解析器には弱点があります。`(((((((((((((((((((((((((((0)))`のようなカッコのネスト数が深いケースで急激に解析にかかる時間が増大してしまうのです。これはまさにPEGだからこそ起こる問題点だと言えます。

### parseメソッドのメモ化 - Packrat Parsing

前のコードをもとに`parse`メソッドをメモ化してみましょう。コードは以下のようになります。

```java
import java.util.*;
sealed interface ParseResult permits ParseResult.Success, ParseResult.Failure {
    public abstract String rest();
    record Success(String value, String rest) implements ParseResult {}
    record Failure(String rest) implements ParseResult {}
}
class ParseError extends RuntimeException {
    public final String rest;
    public String rest() {
        return rest;
    }
    ParseError(String rest) {
        this.rest = rest;
    }
}
class PackratParser {
    private Map<String, ParseResult> cache = new HashMap<>();
    private boolean isEnd(String string) {
        return string.length() == 0;
    }
    public ParseResult parse(String input) {
        String start = input;
        try {
            // "(" A ")"
            if(isEnd(input) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            input = input.substring(1);
            ParseResult result;
            result = cache.get(input);
            if(result == null) {
                result = parse(input);
                cache.put(input, result);
            }

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;

            input = success.rest();
            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        try {
            // "(" A A ")"
            if((isEnd(input)) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            input = input.substring(1);
            ParseResult result;
            result = cache.get(input);
            if(result == null){
                result = parse(input);
                cache.put(input, result);
            } 

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;
            input = success.rest();

            result = cache.get(input);
            if(result == null) {
                result = parse(input);
                cache.put(input,result);
            }

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            success = (ParseResult.Success)result;
            input = success.rest();

            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        if(isEnd(input) || input.charAt(0) != '0') {
            return new ParseResult.Failure(input);
        }

        return new ParseResult.Success(input.substring(0, 1), input.substring(1));
    }
}
```

```java
    private Map<String, ParseResult> cache = new HashMap<>();
```

というフィールドが加わったことです。このフィールド`cache`がパーズの途中結果を保持してくれるために計算が高速化されるのです。結果として、PEGでは最悪指数関数時間かかっていたものがPackrat Parsingでは入力長に対してたかだか線形時間で解析できるようになりました。

PEGは非常に強力な能力を持っていますが、同時に線形時間で構文解析を完了できるわけで、これはとても良い性質です。そういった理由もあってか、PEGやPackrat Parsingを用いた構文解析器や構文解析器生成系はここ10年くらいで大幅に増えました。
## 5.15 - 構文解析アルゴリズムの計算量と表現力の限界 

　LL parsing、LR parsing、PEG、Packrat parsingについてこれまで書いてきましたが、計算量的な性質についてまとめておきましょう。なお、`n`は入力文字列長を表します。

| アルゴリズム        | 時間計算量     | 空間計算量                      |
| ------------------- | ------------- | ------------------------------- | 
| LL(1)               | O(n)          | O(|N| * |T|) |
| LL(k)               | O(n)          | ???                             |
| SLR(1)              | O(n)          | O(|N| * |P| * |T|) |
| LR(1)               | O(n)          | O(s * |T|)            |
| LALR(1)             | O(n)          | O(s * |T|)            |
| PEG                 | O(2^n)        | O(n)                            |
| Packrat Parsing     | O(n)          | O(n * |P|)            |

nは全てのアルゴリズムで入力文字列の長さを表します。その他の記号については以下の通りです。

- LL(1)
  - `|N|`: 非終端記号の数
  - `|T|`: 終端記号の数
- SLR(1):
  - `|N|`: 非終端記号の数
  - `|P|`: 生成規則の数
  - `|T|`: 終端記号の数
- LR(1):
  - s: 状態数
  - `|T|`: 終端記号の数
- LALR(1):
  - s: 状態数
  - `|T|`: 終端記号の数
- PEG or packrat parsing
  - `|P|`: 生成規則の数

PEGを除いて、これまで紹介した全ての手法において線形時間で解析を終えられます。といっても、Packrat Parsing自体がPEGの最適化手法なので、PEGも線形時間で解析を終えられることになります。さらに、PEGは最悪指数関数時間がかかるといっても、多くのケースでは経験的には線形時間＋多少のメモ化で解析を終えられるため、実用上は問題ないことが多いです。

一方、空間計算量についてはPackrat Parsingでは線形時間で解析が可能なものの、空間計算量も線形になってしまいます。実用的な文法については不要なメモ化をしないという発展的な手法もありますが、ナイーブなPackrat Parsingではこの点に注意が必要です。LLやLR系の手法では空間計算量は入力長に依存しないため、構文解析表のサイズが極端に大きくならないケースではメモリの心配は不要です。

## 5.16 - まとめ

この章では構文解析アルゴリズムの中で比較的メジャーな手法について、そのアイデアと概要を含めて説明しました。その他にも多数の手法がありますが、いずれにせよ、「上から下に」向かって解析する下向きの手法と「下から上に」向かって解析する上向きの手法のどちらかに分類できると言えます。

LL(1)やLALR(1)、PEGのパーサジェネレータは多数存在するため、基本的な動作原理について押さえておいて損はありません。また、余裕があれば各構文解析手法を使って実際のパーサジェネレータを実装してみるのも良いでしょう。実際にパーサジェネレータを実装することで、より深く構文解析手法を理解することもできます。
