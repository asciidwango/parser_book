# 4. 構文解析アルゴリズム古今東西

第2章でJSONを例にしてPEGによる構文解析器と、単純な字句解析器を用いた構文解析器を実装しました。第3章では文脈自由文法の概念を紹介しました。これでようやく準備が整ったので、本書の本丸である構文解析アルゴリズムの話ができます。

といっても、戸惑う読者の方が多いかもしれません。これまで「構文解析アルゴリズム」について具体的な話はまったくなかったのですから。しかし、皆さんは、第2章で二つの構文解析アルゴリズムを使ってJSONの構文解析器を**すでに**書いているのです。

用語として不正確ですが、第2章で最初に実装したのはPEGと呼ばれる手法の素朴な実装です。次に実装したのは、*LL(1)*っぽい再帰下降構文解析器です。**再帰下降**という言葉は見慣れないものなので、疑問に思われる読者の方も多いと思います。その疑問は脇において、第2章での実装が理解できたのなら、皆さんはすでに直感的に構文解析アルゴリズムを理解していることになります。

この章では、2024年までに発表された主要な構文解析アルゴリズムについて、筆者の独断と偏見を交えて解説します。この章で紹介する構文解析アルゴリズムのほとんどについて、その構文解析アルゴリズムを使った構文解析器を生成してくれる構文解析器生成系が存在します。構文解析機生成系については第5章で説明しますが、ここではさわりだけを紹介しておきます。

たとえば、構文解析アルゴリズムとして有名な*LALR(1)*は、もっともメジャーな構文解析器生成系でCコードを生成するyacc（GNUによる再実装であるbisonが主流）で採用されています。*LL(1)*はJava向けの構文解析器生成系としてメジャーなJavaCCで採用されている方式です。*ALL(*)*は、Javaをはじめとした多言語向け構文解析器生成系として有名なANTLRで採用されています。PEGを採用した構文解析器生成系も多数存在します。

このように、なにかの構文解析アルゴリズムがあれば、構文解析アルゴリズムに基づいた構文解析機生成系を作ることができます。世dんですが、筆者は大学院生時代にPEGおよびPackrat Parsingの研究をしており、その過程でPEGによる構文解析器生成系を作ったものです。

小難しいことばかり言うのは趣味ではないので、さっそく、構文解析アルゴリズムの世界を覗いてみましょう！　

## 4.1 下向き構文解析と上向き構文解析

具体的な構文解析アルゴリズムの説明に入る前に、構文解析アルゴリズムは大別して、

- 上から下へ（下向き）
- 下から上へ（上向き）

の二つのアプローチがあることを理解しておきましょう。下向き構文解析法と上向き構文解析法では真逆の発想で構文解析を行うからです。

## 4.2 下向き構文解析の概要

まずは下向き構文解析法です。下向き構文解析では予測型とバックトラック型で若干異なる方法で構文解析をしますが、ここでは予測型の下向き構文解析法を説明します。予測型の下向き構文解析法ではCFGの開始記号から構文解析を開始し、規則に従って再帰的に構文解析を行っていきます。

第3章で例に出てきたDyck言語を例にして、具体的な方法を説明します。Dyck言語の文法は以下のようなものでした。

$$
\begin{array}{lll}
D & \rightarrow & \$ P \$ \\
P & \rightarrow & ( P ) P \\
P & \rightarrow & \epsilon \\
\end{array}
$$

このCFGはカッコがネストした文字列の繰り返し（空文字列を含む）を過不足無く表現しているわけですが、`(())`という文字列がマッチするかを判定する問題を考えてみましょう。

まず最初に、開始記号が$D$で規則$D \rightarrow \$ P \$$があるので、スタックに積み込みます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \uparrow \$ P \$ \rbrack
\end{align*}
$$

次に最初の1文字を入力文字列から読み込んで、先読み文字列に追加します。

$$
\begin{align*}
先読み文字列：& \$ \\
スタック：& \lbrack D \rightarrow \uparrow \$ P \$ \rbrack
\end{align*}
$$

入力文字列の先頭と現在の解析位置にある文字が`$`であるため、先読み文字列の先頭とマッチします。そこで、文字列を消費します。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$ \rbrack
\end{align*}
$$

その次ですが、候補となる規則には$P \rightarrow (P)P$と$P \rightarrow \epsilon$があるものの、先読み文字列が空なので、次の文字を読み込みます。

$$
\begin{align*}
先読み文字列：\verb|(| & \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$ \rbrack
\end{align*}
$$

規則が$P \rightarrow (P)P$に確定したので、スタックに規則を積みます。

$$
\begin{align*}
先読み文字列：& \verb|((| \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow \uparrow (P) P\rbrack
\end{align*}
$$

次の文字は`(`であり、先読み文字列の先頭とマッチします。そこで、文字列を消費します。

$$
\begin{align*}
先読み文字列：& \verb|(| \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P) P\rbrack
\end{align*}
$$

先ほどと同じように、規則は$P \rightarrow (P)P$に確定します。そこで、スタックに確定した規則を積みます。

$$
\begin{align*}
先読み文字列：& \verb|()| \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P) P, P \rightarrow \uparrow (P)P\rbrack
\end{align*}
$$

先読み文字列の先頭と現在の解析位置にある文字がマッチするので、文字列を消費します。

$$
\begin{align*}
先読み文字列：& ) \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P) P, P \rightarrow ( \uparrow P ) P\rbrack
\end{align*}
$$

次が非終端記号$P$ですが、候補は$P \rightarrow \epsilon$だけです。本来ならスタックにこの規則を積んで下ろすという作業が必要ですが、省略して$P$の分を読み進めてしまいます。

$$
\begin{align*}
先読み文字列：& ) \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P ) P, P \rightarrow ( P \uparrow ) P\rbrack
\end{align*}
$$

先読み文字列の先頭と現在の解析位置にある文字がマッチするので、文字列を消費します。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P ) P, P \rightarrow ( P ) \uparrow P\rbrack
\end{align*}
$$

先ほどと同様、規則の候補は$P \rightarrow \epsilon$だけです。$P$の分を読み進めてしまいます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( \uparrow P ) P, P \rightarrow ( P ) \uparrow \rbrack
\end{align*}
$$

スタックトップの規則を解析し終えたので、スタックから取り除きます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( P \uparrow ) P
\end{align*}
$$

さらに1文字読み込みます。

$$
\begin{align*}
先読み文字列：& \verb|)| \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( P \uparrow ) P
\end{align*}
$$

先読み文字列の先頭とマッチしますから、文字列を消費します。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( P ) \uparrow P \rbrack
\end{align*}
$$

先ほどと同様、規則の候補は$P \rightarrow \epsilon$だけです。$P$の分を読み進めてしまいます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ \uparrow P \$, P \rightarrow ( P ) P \uparrow \rbrack
\end{align*}
$$

スタックトップの規則を解析し終えたので、スタックから取り除きます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ P \uparrow \$ \rbrack
\end{align*}
$$

文字列の末尾なので、$\$$を読み込みます。

$$
\begin{align*}
先読み文字列：\$ & \\
スタック：& \lbrack D \rightarrow \$ P \uparrow \$ \rbrack
\end{align*}
$$

先読み文字列の先頭とマッチしますから、文字列を消費します。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack D \rightarrow \$ P \$ \uparrow \rbrack
\end{align*}
$$

規則の最後に到達したので、スタックから要素を取り除きます。

$$
\begin{align*}
先読み文字列：& \\
スタック：& \lbrack \rbrack
\end{align*}
$$

入力文字列の終端に到達し、スタックが空になったので、入力文字列`(())`はDyck言語の文法に従っていることがわかりました。

予測型の下向き構文解析では以下の動作を繰り返します。

1. 残りの文字列から、1文字とってきて先読み文字列に追加する
2. 次が非終端記号で、先読み文字列から適用すべき規則が決定できる場合スタックにその規則を積む。規則が決定できない場合はエラー。次が終端記号であれば、先読み文字列の先頭とマッチするかを確認し、マッチすれば文字列を消費し、マッチしない場合はエラーを返す
3. 規則の最後に到達した場合は、スタックから要素を取り除く

## 4.3 下向き構文解析法のJavaによる実装

このような動作をJavaコードで表現することを考えてみます。

```java
// D → P
// P → ( P ) P
// P → ε
public class Dyck {
    private final String input;
    private int position;

    public Dyc(String input) {
        this.input = input;
        this.position = 0;
    }

    public boolean parse() {
        boolean result = D();
        return result && position == input.length();
    }

    private boolean D() {
        return P();
    }

    private boolean P() {
        // P → ( P ) P
        if (position < input.length() && input.charAt(position) == '(') {
            position++; // '(' を読み進める
            if (!P()) return false;
            if (position < input.length() && input.charAt(position) == ')') {
                position++; // ')' を読み進める
                return P();
            } else {
                return false;
            }
        // P → ε
        } else {
            // 空文字列にマッチ
            return true;
        }
    }
}
```

クラス`Dyck`は、Dyck言語を構文解析して、成功したら`true`、そうでなければ`false`を返すものです。BNFと比較すると、

- 規則の名前と一対一になるメソッドが存在する
- 非終端記号の参照は規則の名前に対応するメソッドの再帰呼び出しとして実現されている

のが特徴です。

呼び出す規則を上、呼び出される規則を下とした時、上から下に再帰呼び出しが続いていくため、再帰下降構文解析と呼ばれます。このように「上から下に」構文解析を行っていくのが下向き構文解析法の特徴です。

注意しなければいけないのは、下向き構文解析の方法は多数あり、その1つに再帰下降構文解析があるということです。

## 4.4 上向き構文解析の概要

上向き構文解析は下向き構文解析とは真逆の発想で構文解析を行います。こちらの方法は下向き型より直感的に理解しづらいかもしれません。

上向き構文解析（正確にはシフト還元構文解析として知られているもの）では、文字列を左から右に読み込んでいき、順番にスタックにプッシュしていきます。これをシフト（shift）と呼びます。

シフト動作を続けていくうちに、規則の右辺の記号列とスタックトップにある記号列がマッチすれば、規則の左辺にマッチしたとして、スタックトップにある記号列を規則の左辺で置き換えます。これを還元（reduce）と呼びます。

具体例を挙げてみます。以下のCFGがあったとしましょう。ただし、入力の先頭と末尾を表すために`$`を使うものとします。

$$
\begin{align*}
D & \rightarrow \$ P \$ \\
P & \rightarrow ( P ) P \\
P & \rightarrow \epsilon
\end{align*}
$$

これは下向き構文解析で扱ったDyck言語の文法です。説明の都合上、上記と等価な以下の文法を考えます。

$$
\begin{align*}
D & \rightarrow \$ P \$ \\
D & \rightarrow \$ \epsilon \$ \\
P & \rightarrow P\ X  \\
P & \rightarrow X  \\
X & \rightarrow ( X ) \\
X & \rightarrow ()
\end{align*}
$$

これは下向き構文解析で扱ったDyck言語の文法です。

このCFGに対して`(())`という文字列がマッチするかを判定する問題を考えてみましょう。上向き構文解析では、まず最初の「1文字」を左から右にシフトします。以下のようなイメージです。スタックに要素をプッシュすると右に要素が追加されていくものとします。

$$
\begin{align*}
スタック： & \lbrack \$, (\ \rbrack
\end{align*}
$$

このスタックは$P$にも$D$にもマッチしません。そこで、もう1文字をシフトしてみます。

$$
\begin{align*}
スタック： & \lbrack \$, (, ( \rbrack
\end{align*}
$$

まだマッチしませんね。さらにもう1文字シフトしてみます。

$$
\begin{align*}
スタック： & \lbrack \$, (, (, \rbrack
\end{align*}
$$

さらにもう1文字シフトしてみます。

$$
\begin{align*}
スタック： & \lbrack \$, (, (, )\rbrack
\end{align*}
$$

規則$X \rightarrow ()$を使って還元を行います。

$$
\begin{align*}
スタック： & \lbrack \$, (, X\rbrack
\end{align*}
$$

この状態でもう1文字シフトしてみます。

$$
\begin{align*}
スタック： & \lbrack \$, (, X, ) \rbrack
\end{align*}
$$

規則$X \rightarrow (X)$を使って還元を行います。

$$
\begin{align*}
スタック： & \lbrack \$, X \rbrack
\end{align*}
$$

さらに規則$P \rightarrow X$を使って還元を行います。

$$
\begin{align*}
スタック： & \lbrack \$, P \rbrack
\end{align*}
$$

スタックは規則$P \rightarrow ( P ) P$にマッチしますから，還元が行われます。

$$
\begin{align*}
スタック： & \lbrack \$, (, P \rbrack
\end{align*}
$$

1文字シフトします。

$$
\begin{align*}
スタック： & \lbrack \$, (, P, ) \rbrack
\end{align*}
$$

規則$P \rightarrow \epsilon$を使って還元します。

$$
\begin{align*}
スタック： & \lbrack \$, (, P, ), P\rbrack
\end{align*}
$$

スタックは規則$P \rightarrow ( P ) P$にマッチしますから，還元が行われます。

$$
\begin{align*}
スタック： & \lbrack \$, P\rbrack
\end{align*}
$$

文字列の末尾にきたので、$\$$をシフトします。

$$
\begin{align*}
スタック： & \lbrack \$, P, \$ \rbrack
\end{align*}
$$

このスタックは規則$D \rightarrow \$ P \$$にマッチします。還元が行われ、最終的にスタックの状態は次のようになります。

$$
\begin{align*}
スタック： & \lbrack D \rbrack
\end{align*}
$$

めでたく`(())`が`D`とマッチすることがわかりました。上向き構文解析では以下の手順を繰り返していきます。

1. 残りの文字があれば、入力文字をシフトしてスタックにプッシュする（シフト）
2. スタックの記号列が規則の右辺にマッチすれば、左辺の非終端記号で置き換える（還元）

## 4.5 上向き構文解析のJavaによる実装

このような動作をJavaコードで表現することを考えてみます。まず必要なのは、規則を表すクラス`Rule`です。問題を単純化するために、

1. 規則の名前（左辺）は1文字
2. 規則の右辺は終端記号または非終端記号のリストである

とします。このようなクラス`Rule`は以下のように表現できます。

```java
public class Rule {
    private final char lhs;
    private final List<Element> rhs;

    public Rule(char lhs, List<Element> rhs) {
        this.lhs = lhs;
        this.rhs = rhs;
    }

    public char getLhs() {
        return lhs;
    }

    public List<Element> getRhs() {
        return rhs;
    }

    public boolean matches(List<Element> stack) {
        if (stack.size() < rhs.size()) return false;
        for (int i = 0; i < rhs.size(); i++) {
            Element elementInRule = rhs.get(rhs.size() - i - 1);
            Element elementInStack = stack.get(stack.size() - i - 1);
            if (!elementInRule.equals(elementInStack)) {
                return false;
            }
        }
        return true;
    }
}
```

ここで、Elementは終端記号や非終端記号を表すクラスで、以下のように定義されます。

```java
public interface Element {}

public class Terminal implements Element {
    private final char symbol;

    public Terminal(char symbol) {
        this.symbol = symbol;
    }

    public char getSymbol() {
        return symbol;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj instanceof Terminal) {
            return this.symbol == ((Terminal) obj).symbol;
        }
        return false;
    }

    @Override
    public int hashCode() {
        return Character.hashCode(symbol);
    }
}

public class NonTerminal implements Element {
    private final char name;

    public NonTerminal(char name) {
        this.name = name;
    }

    public char getName() {
        return name;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj instanceof NonTerminal) {
            return this.name == ((NonTerminal) obj).name;
        }
        return false;
    }

    @Override
    public int hashCode() {
        return Character.hashCode(name);
    }
}
```

これらのクラスを使ってシフトと還元を行うクラス`Dyck`は次のように定義できます。

```java
public class Dyck {
    private final String input;
    private int position;
    private final List<Rule> rules;

    private final List<Element> stack = new ArrayList<>();

    public Dyck(String input) {
        this.input = input;
        this.position = 0;
        this.rules = List.of(
            // D → $ P $
            new Rule('D', List.of(new Terminal('$'), new NonTerminal('P'), new Terminal('$'))),
            // D → $ ε $
            new Rule('D', List.of(new Terminal('$'), new Terminal('$'))),
            // P → P X
            new Rule('P', List.of(new NonTerminal('P'), new NonTerminal('X'))),
            // P → X
            new Rule('P', List.of(new NonTerminal('X'))),
            // X → ( X )
            new Rule('X', List.of(new Terminal('('), new NonTerminal('X'), new Terminal(')'))),
            // X → ()
            new Rule('X', List.of(new Terminal('('), new Terminal(')')))
        );
    }

    public boolean parse() {
        stack.add(new Terminal('$'));
        while (true) {
            if (!tryReduce()) {
                if (position < input.length()) {
                    stack.add(new Terminal(input.charAt(position)));
                    position++;
                } else {
                    break;
                }
            }
        }
        stack.add(new Terminal('$'));
        while (tryReduce()) {
            // 繰り返し還元を試みる
        }
        return stack.size() == 1 && stack.get(0).equals(new NonTerminal('D'));
    }

    private boolean tryReduce() {
        for (Rule rule : rules) {
            if (rule.matches(stack)) {
                for (int i = 0; i < rule.getRhs().size(); i++) {
                    stack.remove(stack.size() - 1);
                }
                stack.add(new NonTerminal(rule.getLhs()));
                return true;
            }
        }
        return false;
    }
}
```

このプログラムでは、入力文字列を1文字ずつシフトしながら、可能な限り還元を行っています。規則にマッチする場合はスタックから右辺の要素を取り除き、左辺の非終端記号をプッシュします。最終的にスタックにNonTerminal('D')だけが残れば、入力文字列が文法に従っていることが確認できます。

## 4.6 下向き構文解析と上向き構文解析の比較

下向き構文解析法と上向き構文解析法は得手不得手があります。下向き型は規則と関数を対応付けるのが容易なので手書きの構文解析器を書くのに向いています。また、関数の引数として現在の情報を渡して、引数に応じて構文解析の結果を変化させることが比較的容易です。これは複雑で文脈に依存した文法を持った言語を解析するときに有利な性質です。しかし、下向き型は左再帰という形の文法をそのまま処理できないという欠点があります。

たとえば、以下のBNFは、上向き型だとa*に相当する言語を普通に解析できますが、工夫なしに下向き型で実装すると無限再帰に陥ってスタックオーバーフローします。

```
A = A "a"
A = "";
```

このような問題を下向き型で解決する方法も存在します。端的に言うと「再帰をループに置き換える」アプローチです。たとえば、上の文法を以下のように書き換えれば下向き型でも問題なく解析できるようになります。このような処理を左再帰の除去と呼びます。

```
A = "a" A
  | "";
```

しかし、左再帰を問題なく処理できる上向き型が一方的に有利なのかというとそう単純ではありません。たとえば、それまでの文脈に応じて構文解析のルールを切り替えたくなることがあります。最近の言語によく搭載されている文字列補間などはその最たる例です。`"`の中は文字列リテラルとして特別扱いされますが、その中で`#{`が出てきたら（Rubyの場合）、通常の式を構文解析するときのルールに戻る必要があります。このような、文脈に応じて適用するルールを切り替えるのは下向き型が得意です。もちろん、上向き型でも実現できないわけではありません。実際、Rubyの構文解析機はYaccの定義ファイルから生成されるようになっていますが、Yaccが採用しているのは代表的な上向き構文解析法である`LALR(1)`です。ともあれ、下向きと上向きにはそれぞれ異なる利点と欠点があります。

さて、次からは具体的なアルゴリズムの説明に移ります。

## 4.2 LL(1) - 代表的な下向き構文解析アルゴリズム

下向き型構文解析法の中でおそらくもっとも古典的で、よく知られているのは`LL(1)`法です。`LL`は**Left-to-right, Leftmost derivation**の略で、左から右へ文字列をスキャンしながら**最左導出**を行うことを意味しています。最左導出は第3章で説明しましたね。

`LL(1)`の`1`は「1トークン先読み」を意味しています。つまり、`LL(1)`法は、次の1トークンを見て、最左導出を行うような構文解析手法です。この手法は手書きの**再帰下降構文解析**によって簡単に実装できるため、構文解析手法の中でも単純なものと言えるでしょう。字面が一見小難しく見えますが、`LL(1)`のアイデアは意外に簡単なものです。

たとえば、以下のようなJava言語のif文があったとします。

```java
if(age < 18) {
    System.out.println("18歳未満です");
} else {
    System.out.println("18歳以上です");
}
```

我々はどのようにしてこれを見て「if文がある」と認識するのでしょうか。もちろん「人それぞれ」なのですが、最初にキーワード`if`が現れたからif文だと考える人も多いのではないかと思います。

`LL(1)`構文解析アルゴリズムはまさにこのイメージを元にした手法です。プログラムをトークン列に区切った後に、「最初の1トークン」を見て、「これはif文だ」とか「これはwhile文だ」とか認識するようなものですね。

イメージとしては簡単なのですが、アルゴリズムとして実行可能なようにするためには考えなければいけない論点がいくつかあります。以下では、`LL(1)`を実装するに当たって考えなければいけない課題について論じます。

### 課題1 - ある構文の最初のトークンが複数種類ある場合

先程の例ではある構文、たとえばif文が始まるには`if`というキーワードが必須で、それ以外の方法でif文が始まることはありえませんでした。しかし、たとえば、算術式を考えてみると、問題はそう単純ではないことがわかります。少し考えただけでも、以下のような例が思い浮かびます。

- `(`で算術式が始まる場合
- `-`で算術式が始まる場合
- `+`で算術式が始まる場合
- 整数リテラル（`<integer_literal>`）で算術式が始まる場合
- 浮動小数点数リテラル（`<floating_point_literal>`）で算術式が始まる場合

つまり、次のトークンが算術式の始まりである事を確定するためには、トークンの集合という概念が必要になります。たとえば、算術式の始まりは

```
{"(", "-", "+", <integer_literal>, <floating_point_literal>, ...}
```

のようなトークンの集合であると考える事が出来ます。このような、ある構文が始まるかを決定するために必要なトークンの集合のことを**FIRST集合**と呼びます。**FIRST**は非終端記号`N`を引数に取って、Nの先頭1トークンの集合を返す関数`FIRST(N)`と考えることもできます。

たとえば、規則の右辺が複数あって以下のようになっているとします。

```
A = B;
A = C;
```

このとき、`FIRST(B) ∩ FIRST(C) = ∅`が成り立てば、先頭１トークンだけを「先に見て」`B`を選ぶか`C`を選ぶかを安全に決定することができます。

この「先を見る」（Lookahead）という動作がLL(1)のキモです。バックトラックしない下向き型の場合「あ。間違ってたので別の選択肢をためそう」ということができませんから、必然的に一つ先を読んで分岐する必要があるのです。また、一つ先を読んで安全に分岐を選ぶことができるためには、分岐の先頭にあるトークンがお互いに重なっていないことが必要条件になります。この「お互いに重なっていない」というのが、まさに`FIRST(B) ∩ FIRST(C) = ∅`で表されている条件です。

### 課題2 - 省略可能な要素の扱い

if文であるかどうかは、明らかに先頭の1トークンを見ればわかります。しかし、if文であるとして、if-else文なのかelseがない単純なif文であるかどうかを判定するのはどうすればいいでしょうか。たとえば、以下の文は正当です。

if文であるかどうかは、明らかに先頭の1トークンを見ればわかります。しかし、if文であるとして、if-else文なのかelseがない単純なif文であるかどうかを判定するのはどうすればいいでしょうか。たとえば、以下の文は正当です。

```java
if (age < 18) {
    System.out.println("18歳未満です");
}
```

以下の文も正当です。

```java
if (age < 18) {
    System.out.println("18歳未満です");
} else {
    System.out.println("18歳以上です");
}
```

最初のif文の後に、

- 前者はelseが出現しない
- 後者はelseが出現する

という違いがあります。しかし、elseがあるかどうかを1トークン先読みだけで判断できるでしょうか？

つまり、elseが出現するかどうかで、どの規則を適用するかを決定する必要があります。このような場合、次のトークンを見て、elseならif-else文、そうでなければ単純なif文と解釈します。

このような、「ある非終端記号の次に出現しうるトークンの集合」をFOLLOW集合と呼びます。FOLLOW(N)は非終端記号Nの後に出現しうるトークンの集合を表します。FIRST集合とFOLLOW集合はLL(1)にとって重要な概念です。次の項では、このFIRST集合とFOLLOW集合の概念についてより厳密に説明します。

### FIRST集合とFOLLOW集合の計算

LL(1)をアルゴリズムとしてきちんと定義しようとするなら、この二つの概念が必要であることはわかってもらえたのではないかと思います。しかし、この二つですが、プログラム上でどう計算すれば良いのでしょうか？この問いに答えることがLL(1)アルゴリズムをきちんと理解することであり、逆にきちんと理解できれば、自力でLL(1)アルゴリズムによるパーサを記述できるようになるでしょう。

まずはFIRST集合について考えてみます。単純化のために以下のような規則を仮定します。

```text
A = α1
A = α2 
... 
A = αn
```

ここで、αiは終端記号や非終端記号の並びです。FIRST(A)を求めるには以下の手順を用います。

1. FIRST集合を空集合に初期化する。
2. 各生成規則`A = αi`について、次を行う：
 - αiの最初の記号X1が終端記号ならば、FIRST(A)にX1を追加する。
 - X1が非終端記号の場合、FIRST(X1)を計算し、FIRST(A)にFIRST(X1)を追加する。
 - X1がnullable（空文字列を生成可能）である場合、次の記号X2について同様の処理を行う。

nullableとは、その非終端記号が空文字列を生成可能かどうかを示すものです。nullableの計算は以下の手順で行います。

1. 全ての非終端記号をfalse（nullableでない）に初期化する。
2. 生成規則`A = α`について、αが空（ε）ならAをtrue（nullableである）に設定する。
3. 生成規則`A = α`について、αが全てnullableならAをtrueに設定する。
4. 値が変化しなくなるまで2と3を繰り返す。

次にFOLLOW集合の計算です。FOLLOW(A)は、非終端記号Aの後に現れる可能性のある終端記号の集合です。計算手順は以下の通りです。

1. FOLLOW集合を空集合に初期化する。
2. 開始記号のFOLLOW集合に入力の終端記号$を追加する。
3. 各生成規則`B = αAβ`について、以下を行う：
  -  `FIRST(β)`からεを除いたものを`FOLLOW(A)`に追加する。
  - βがnullable（空文字列を生成可能）ならば、FOLLOW(B)をFOLLOW(A)に追加する。
4. 値が変化しなくなるまで3を繰り返す。

これらのFIRSTとFOLLOW集合を用いて、LL(1)構文解析表を作成します。

## LL(1)構文解析表の作成

構文解析表は、非終端記号と入力の次のトークン（終端記号）の組み合わせで、次にどの生成規則を適用すべきかを示すものです。構文解析表の作成手順は以下の通りです。

1. 各生成規則`A = α`について、次を行う：
  - `FIRST(α)`からεを除いた全ての終端記号aに対して、表の項目`[A, a]`に規則`A = α`を入れる。
  - もし`ε ∈ FIRST(α)`なら、`FOLLOW(A)`の全ての終端記号bに対して、表の項目`[A, b]`に規則`A = α`を入れる。
2. 構文解析表において、同じ項目に複数の規則が入る場合、その文法はLL(1)ではない

つまり、LL(1)構文解析表が作成できるかどうかは、その文法がLL(1)であるかどうかの判定に等しいと言えます。

## LL(1)の問題点と限界

`LL(1)`は古典的でありかつそれなりに実用的でもありますが、アルゴリズムがシンプルである故の問題点や限界も存在します。この節では`LL(1)`の抱える問題点について述べます。

### 問題点1 - 最初の1トークンで構文要素を決められないことがある

例えば、以下の文法を考えてみましょう。

```text
S = "a" A
S = "a" B
A = "b"
B = "c"
```

この場合、Sの最初のトークンは常に"a"ですが、その次のトークンが"b"ならAを、"c"ならBを選択します。LL(1)では最初の1トークンだけではどちらの規則を適用すべきか決められません。

この問題は左因子化（left factoring）によって解決できます。共通部分をくくり出すことで、LL(1)で解析可能な文法に変換します。

```text
S = "a" S'
S' = A
S' = B
A = "b"
B = "c"
```

しかし、それでも先読み1トークンでは不十分な場合があります。

### 問題点2 - 左再帰の問題

LL(1)では左再帰を含む文法を扱うことができません。例えば、以下の文法は左再帰を含んでいます。

```text
E = E "+" T 
E =  T
```

この文法はEの定義にE自身が左側に出現しています。左再帰を除去することでLL(1)で扱えるように変換できます。

```text
E = T E'
E' = "+" T E'
E' =  ""
```

この変換はすべての場合に簡単に行えるわけではありません。

## 4.3 LL(k) - LL(1)の拡張

LL(1)の限界を克服するために、LL(k)という概念が導入されました。kは先読みするトークン数を示します。kを増やすことで、より複雑な文法を扱えるようになりますが、解析表のサイズや計算量が増加します。

しかし、LL(k)でもすべての文脈自由言語を扱えるわけではありません。たとえば、文脈自由言語の例として以下のようなものがあります。

```text
a^i b^j` (`i >= j >= 1)
```

これはaがi回あらわれてその後にbがj回（i回以上）あらわれるような言語ですが、`LL(k)`言語ではありません。後述しますが、`LR(1)`言語にはなるので、純粋に言語としての表現能力を考えると`LL(k)`は`LR(1)`よりも弱い言語であると言えます。

## 4.5 SLR - 単純な上向き構文解析アルゴリズム

SLR（Simple LR）は、LR法の中でも最も単純な手法です。LRはLeft-to-right（左から右への入力）とRightmost derivation（最右導出）の略です。 ここで、Left-to-rightは「左から右に文字列を読み込む」を指します。これは直感的にわかりやすいでしょう。Rightmost derivationは「最右導出を行う」という意味です。最右導出とは、文脈自由文法に関連した用語です。文脈自由文法から文を生成する過程には大きく分けて最左導出と最右導出があります。

最左導出は文法規則を適用していくことで文を生成する過程のことです。たとえば、以下の文脈自由文法を考えてみましょう：

```text
S -> aSSb | c
```

この文法規則に対して、最左導出で`accb`という文字列を生成する過程は以下のようになります：

```text
S -> aSSb -> acSb -> accb
```

Sを展開するときに、一番左のSを展開していますね。これが「最左」ということです。

一方、最右導出は文法規則を適用していく際に右側から展開していくことを指します。先ほどと同じ文脈自由文法を考えてみましょう：

```
S -> aSSb | c
```

この文法規則に対して、最右導出で`accb`という文字列を生成する過程は以下のようになります：

```
S -> aSSb -> aScb -> accb
```

Sを展開するときに、一番右のSを展開していますね。これが「最右導出」ということです。最右導出の過程を逆にたどることが `SLR`ひいては`LR`法の基本的な考え方です。

これだけだとわけがわからないという方が大半ではないかと思います。しかし、実は読者の皆さんがこの章で既に見たシフト還元構文解析が理解できていれば、その入口に立ったようなものです。

というのはシフト還元構文解析の「シフト」が上でいうLeft-to-right、「還元」がRightmost derivationに対応しているからです。シフトは左から右に文字列を読み込むことを意味し、還元は最右導出の逆を行うことを意味します。SLRはシフト還元構文解析の基本的な考え方を取り入れているわけです。

しかし、素朴なシフト還元構文解析とSLR法が大きく異なる点があります。それは構文解析表と呼ばれる表を用いてシフトするか還元するかを決定する点です。素朴なシフト還元構文解析ではスタックを毎回スキャンしていましたが、これではスタックのサイズが大きくなってきたときに遅くなるのが想像できますね。一方、SLRでは構文解析表を使ってシフトするか還元するかを決定するため、効率的に構文解析を行うことができます。

では、SLRではどのように構文解析表を作り出すのでしょうか？そのための道具立てを次節以降で説明します。

### LR(0)項

SLRでは、文法規則を`LR(0)項`（以下、単に項と書きます）という形に変換します。項は規則の右辺にドット（・）を挿入したものです。たとえば：

```
E -> E + T
```

この規則に対して、以下のような項を作ることができます：

```
E -> . E + T,
```

ドットは現在の解析位置を示します。1つの項は構文解析の途中経過を表すものと見ることができます。この項はEの右辺の最初の記号を読み込もうとしている状態です。

さらに、項集合という概念を導入します。規則

```
E -> E + T
```

から得られる項の集まりは以下のようになります：

```
1. E -> . E + T
2. E -> E . + T
3. E -> E + . T
4. E -> E + T .
```

ある規則から得られる項集合は、その規則の左辺に対応する構文解析の途中状態の集合と見ることができます。この規則の右辺は3つの要素からなるため、4つの項が得られます。

よりわかりやすく言うなら、4つの項は以下のような状態を表しています：

1. Eの右辺の最初の記号を読み込もうとしている
2. Eの右辺の最初の記号を読み込んだ後、+を読み込もうとしている
3. Eの右辺の最初の記号と+を読み込んだ後、Tを読み込もうとしている
4. Eの右辺の最初の記号と+とTを読み込んだ後。還元しようとしている

### 状態の構築

SLRでは、項目の集合を「状態」として扱います。初期状態から始めて、遷移を繰り返すことで全ての状態を構築します。
例として、以下の簡単な文法を考えてみましょう：

```text
{
  S -> E,
  E -> E + T | T,
  T -> x
}
```

この文法に対して入力を解析するときの初期状態は以下のようになります：

```text
{
  S -> . E,
  E -> . E + T,
  E -> . T,
  T -> . x
}
```

この状態から、各記号（E, T, x）に対する遷移を考えます。例えば、xに対する遷移は以下のようになります：

```
{
  S -> . E,
  E -> . E + T,
  E -> . T,
  T -> x .
}
```

遷移元の状態、つまり項集合と比較して、最後の項がxを読み込んでいる状態になっていることがわかります。このようにして、各記号に対する遷移を考えていくことで、全ての状態を構築していきます。

### 閉包（Closure）

状態を構築する際、ある非終端記号に対する項目がある場合、その非終端記号から始まる全ての規則も状態に含める必要があります。これを閉包操作と呼びます。

閉包操作は以下の手順で行います：

1. 現在の状態に含まれる全ての項について、ドットの直後にある非終端記号を取得
2. その非終端記号に対応する全ての規則を取得
3. それらの規則を新しい項として状態に追加
4. 項集合が変化しなくなるまで、1から3を繰り返す

### GOTO関数

SLR（Simple LR）法において、GOTO関数は構文解析器の中心的な役割を果たす重要な概念です。GOTO関数は、現在の状態と入力記号に基づいて次の状態を決定する関数です。具体的には、ある状態から特定の記号を「読む」（読むとはその記号に関連するシフトまたは非終端記号の展開を意味します）ことで遷移する先の状態を指し示します。

GOTO関数は次のように定義されます：

```text
GOTO(I, X) = J
```

ここで、

- I は現在の状態（項目集合）
- X は遷移の基となる記号（終端記号または非終端記号）、
- J は遷移後の状態（新しい項目集合）

です。

#### GOTO関数の計算方法

GOTO関数を計算するためには、現在の状態Iに含まれる項目に対して、特定の記号Xがドット（・）の直後に現れるものを探し、そのドットを1つ右に移動させた新しい項目を生成します。これらの新しい項目の閉包を取り、その結果が遷移後の状態Jとなります。

具体的な手順は以下の通りです：

1. 項目の選択： 現在の状態Iに含まれるすべての項目`A → α・Xβ`を選びます。Xは終端記号または非終端記号です。
2. ドットの移動： 選択した各項目について、ドットを1つ右に移動させた項目`A → αX・β`を生成します。
3. 閉包の計算： 生成した新しい項目集合に対して閉包操作を行います。これは、非終端記号 β が現れた場合、その非終端記号に関連するすべての規則を追加する操作です。
4. 新しい状態の確定： 閉包操作後の項目集合が新しい状態Jとなります。

#### 例でみるGOTO関数の適用

具体的な文法と項目集合を用いてGOTO関数の動作を確認してみましょう。

##### 文法：

```text
S -> E
E -> E + T
E -> T
T -> id
```

##### 項目集合の例：

例えば、ある状態 I が以下の項目を含んでいるとします：

```text
1. S -> . E
2. E -> . E + T
3. E -> . T
4. T -> . id
```

この状態Iに対して、記号Eに対するGOTO関数`GOTO(I, E)`を計算してみます。

1. 項目の選択：

- `S -> . E` （ドットの直後が E）
- `E -> . E + T` （ドットの直後が E）

2. ドットの移動：

- `S -> E .`
- `E -> E . + T`

3. 閉包の計算：

- `S -> E .`はドットが右端にあるため、閉包には新たな項目は追加されません。
- `E -> E . + T`はドットの直後が + なので、閉包には新たな項目は追加されません。

したがって、GOTO関数 GOTO(I, E) によって生成される新しい状態 J は以下の項目を含みます：

```text
1. S → E .
2. E → E . + T
```

のように、GOTO関数は現在の状態と特定の記号に基づいて新しい状態を導出します。

### 構文解析表

SLR法における構文解析表は、構文解析器が入力を解析する際に必要なアクション（シフト、還元、受理、エラー）を決定するための表です。この表は、各状態と各入力記号の組み合わせに対して、どのアクションを取るべきかを示します。

構文解析表は主に2つの部分から構成されます：

1. ACTION表：終端記号に対するアクションを示す部分。
2. GOTO表：非終端記号に対する次の状態を示す部分。

#### 構文解析表の作成手順

構文解析表を作成する手順は以下の通りです：

TBD

### 構文解析の実行

構文解析表を使って、実際の入力文字列を解析します。スタックと入力バッファを用いて、以下の操作を繰り返します：

- 現在の状態と次の入力記号に基づいて、構文解析表からアクションを決定
- アクションにしたがって、シフトまたは還元を実行
- 受理に到達したら解析成功、エラーが発生したら解析失敗

### 具体例

TBD

このように、SLR(0)法では構文解析表を参照しながら、入力文字列を左から右に読み込み、適切なタイミングでシフトと還元を繰り返すことで構文解析を行います。
SLR(0)法は比較的単純ですが、扱える文法に制限があります。次にSLR(0)を拡張して先読みを考慮したSLR(1)法について説明します。

## 4.6 SLR(1) - 先読みを考慮した上向き構文解析アルゴリズム

SLR(1)（Simple LR(1)）法は、SLR(0)法を先読み情報で強化した上向き構文解析アルゴリズムです。SLR(1)法では、LR(0)項目集合を用いて状態を構築し、さらに文法のFOLLOW集合を利用して解析表を作成します。これにより、LR(0)法で生じるシフト・還元（shift-reduce）コンフリクトや還元・還元（reduce-reduce）コンフリクトを解消することが可能になります。

### 構文解析表の作成方法

それでは、SLR(1)法における構文解析表の作成手順を詳しく説明していきましょう。

#### 手順1: LR(0)項目集合の構築

まず、与えられた文法についてLR(0)項目集合を構築します。LR(0)項目は、ドット（・）の位置で解析の進行状況を示すものでしたね。この項目集合と状態遷移を構築する際には、前節で説明した閉包とGOTO関数を用います。

#### 手順2: FOLLOW集合の計算

次に、各非終端記号のFOLLOW集合を計算します。FOLLOW集合とは、ある非終端記号の直後に現れうる可能性のある終端記号の集合です。計算手順は以下の通りです。

1. 各非終端記号のFOLLOW集合を空集合に初期化します。
2. 開始記号のFOLLOW集合に入力の終端記号$を追加します。
3. 各生成規則`A → αBβ`について、`FIRST(β)`からεを除いたものを`FOLLOW(B)`に追加します。
4. もしβがε（空文字列）に導出可能であれば、`FOLLOW(A)`を`FOLLOW(B)`に追加します。
5. 値が変化しなくなるまで、ステップ3と4を繰り返します。

#### 手順3: 構文解析表（ACTION表とGOTO表）の作成

ACTION表とGOTO表を以下の手順で作成します。

#### ACTION表の作成

1. シフト動作の設定

状態Iにおいて、項目`[A → α・aβ]`が含まれている場合、かつaが終端記号であるとき、`GOTO(I, a) = J`であれば、ACTION表の`(I, a)`にshift Jを設定します。

2. 還元動作の設定

状態Iにおいて、項目`[A → α・]`（ドットが右端にある項目）が含まれている場合、`A → α`の規則番号をrとします。このとき、`FOLLOW(A)`に含まれる全ての終端記号aに対して、ACTION表の`(I, a)`に`reduce r`を設定します。

3. 受理動作の設定

状態Iにおいて、項目`[S' → S・]`（S'は拡張した開始記号）が含まれている場合、ACTION表の`(I, $)`にacceptを設定します。

##### GOTO表の作成

状態Iにおいて、非終端記号Aに対して`GOTO(I, A) = J`が定義されている場合、GOTO表の`(I, A)`にJを設定します。

#### 手順4: コンフリクトの検出

構文解析表を作成した後、以下のコンフリクトがないか確認します。

- シフト・還元コンフリクト：同じセルにshiftとreduceが存在する場合。
- 還元・還元コンフリクト：同じセルに複数のreduceが存在する場合。

これらのコンフリクトがなければ、その文法はSLR(1)文法であり、SLR(1)構文解析器を構築できます。コンフリクトがある場合は、文法を変更するか、より強力なLR(1)法やLALR(1)法を検討する必要があります。

### 具体例

具体的な例を用いて、SLR(1)法の構文解析表の作成手順を示します。

以下の文法を考えます。

```
1. E → E + T
2. E → T
3. T → T * F
4. T → F
5. F → ( E )
6. F → id
```

この文法は四則演算の式を表現しています。

#### ステップ1：LR(0)項目集合の構築

各項目集合（状態）を構築します。TBD

#### ステップ2：FOLLOW集合の計算

各非終端記号のFOLLOW集合を計算します。

- FOLLOW(E) = `{ ), $ }`
- FOLLOW(T) = `{ +, ), $ }`
- FOLLOW(F) = `{ *, +, ), $ }`

##### ステップ3：構文解析表の作成

各状態に対して、ACTION表とGOTO表を作成します。

- シフト動作：項目`[A → α・aβ]`に基づいて設定。
- 還元動作：項目`[A → α・]`とFOLLOW(A)に基づいて設定。

##### ステップ4：コンフリクトの検出

作成した構文解析表を確認し、コンフリクトがないことを確認します。この文法では、SLR(1)法でコンフリクトなく解析可能です。

#### SLR(1)法の利点と限界

SLR(1)法は、SLR(0)法よりも多くの文法を扱える一方、LR(1)法よりは弱い解析能力しか持ちません。SLR(1)法でコンフリクトが発生する場合、LR(1)法やLALR(1)法を検討する必要があります。

## 4.7 LR(1) - 項目集合に先読みを追加したSLR(1)の拡張

LR(1)法は、SLR(1)法をさらに強化した上向き構文解析アルゴリズムです。LR(1)法では、各項目に**先読み記号（lookahead）**を付加します。これにより、解析中の文脈をより正確に把握し、コンフリクトを解消することが可能になります。

### LR(1)項目

LR(1)法では、項目は以下の形式で表されます。

```text
[A → α・β, a]
```

- A → αβ：文法規則
- ・：ドット（現在の解析位置）
- a：先読み記号（終端記号または終端記号の集合）

この項目は、「αを既に解析し、次にβを解析しようとしている。さらに、入力の先頭にaが現れることを期待する」という意味を持ちます。

### LR(1)項目集合の構築

LR(1)項目集合を構築するために、以下の手順を踏みます。

#### 手順1: 初期項目の作成

開始記号S'に対して、初期項目`[S' → ・S, $]`を作成します。ここで、$は入力の終端記号を表します。

#### 手順2: LR(1)閉包（closure）の計算

項目集合Iの閉包closure(I)を以下の手順で計算します。

1. `closure(I) = I`とする。
2. `closure(I)`に新しい項目が追加されなくなるまで、以下を繰り返す。
  - `closure(I)`内の各項目`[A → α・Bβ, a]`について、Bが非終端記号であれば、Bのすべての規則`B → γ`に対して、`FIRST(βa)`に含まれる全ての終端記号bについて、項目`[B → ・γ, b]`を`closure(I)`に追加する。

#### 手順3: GOTO関数の計算

項目集合`I`と記号`X`に対して、`GOTO(I, X)`は以下の項目からなる集合の閉包です。

- I内の項目`[A → α・Xβ, a]`に対して、`[A → αX・β, a]`を集めた集合の閉包。

#### 手順4: LR(1)項目集合の全体構築

初期項目集合から出発し、GOTO関数を用いて新たな項目集合を構築します。この過程を新しい項目集合が生まれなくなるまで繰り返します。

### LR(1)構文解析表の作成

LR(1)項目集合を用いて、構文解析表（ACTION表とGOTO表）を作成します。

#### ACTION表の作成

1. シフト動作の設定

状態Iにおいて、項目`[A → α・aβ, b]`が含まれている場合、aが終端記号であれば、`GOTO(I, a) = J`として、ACTION表の`(I, a)`に`shift J`を設定します。

2. 還元動作の設定

状態Iにおいて、項目`[A → α・, a]`（ドットが右端にある項目）が含まれている場合、`A → α`の規則番号をrとして、ACTION表の`(I, a)`にreduce rを設定します。

3. 受理動作の設定

状態Iにおいて、項目`[S' → S・, $]`が含まれている場合、ACTION表の`(I, $)`に`accept`を設定します。

### GOTO表の作成

GOTO表の作成方法はSLR(1)法と同様です。

### LR(1)法の利点と欠点

#### 利点

- 強力な解析能力：LR(1)法は、すべてのLR(1)文法を解析可能であり、SLR(1)法やLALR(1)法で解析できない文法も扱えます。
- コンフリクトの解消：先読み記号を明示的に扱うことで、コンフリクトを細かく解消できます。

#### 欠点

解析表のサイズが大きい：LR(1)項目集合は非常に大きくなる傾向があり、解析表も巨大になります。これにより、実用上のメモリ消費や処理時間が問題となる場合があります。

### 具体例

簡単な文法を用いて、LR(1)項目集合と解析表の作成を示します。

```text
1. S → L = R
2. S → R
3. L → * R
4. L → id
5. R → L
```

#### LR(1)項目集合の構築

初期項目：`[S' → ・S, $]`

#### ステップ1：閉包の計算

初期項目の閉包を計算し、項目集合を構築します。

#### ステップ2：GOTO関数の計算

各項目集合に対して、GOTO関数を計算し、新たな項目集合を生成します。

#### ステップ3：全体の項目集合の構築

この過程を繰り返し、全ての項目集合を構築します。

#### 構文解析表の作成

構築したLR(1)項目集合を用いて、ACTION表とGOTO表を作成します。

#### コンフリクトの解消

この文法では、SLR(1)法では解消できないコンフリクトが発生しますが、LR(1)法では正しく解析できます。

#### LR(1)法の欠点

LR(1)法は強力ですが、解析表のサイズが大きくなるため、実用上はメモリや処理時間の問題があります。そこで、次節で説明するLALR(1)法がよく用いられます。LALR(1)法は、LR(1)法の解析能力を保ちつつ、解析表のサイズをSLR(1)法と同程度に抑えた手法です。

## 4.8 LALR(1) - 現実的に取り扱いやすい上向き構文解析アルゴリズム

LR(1)法は強力な手法ですが、解析表が大きくなるという欠点があります。LALR(1)（Look-Ahead LR）は、LR(0)の状態を結合し、LR(1)の性能を持ちながら解析表のサイズを抑える手法です。

### LALR(1)解析表の作成

LR(1)アイテムの集合を構築し、同じLR(0)アイテムを持つ状態をマージします。その際、先読み記号を適切に管理します。

### 利点と欠点

LALR(1)は多くの実用的な文法を扱えるため、構文解析器生成器（例えばYacc）で広く使われています。しかし、まれにLALR(1)では解析できない文法も存在します。

## 4.7 - Parsing Expression Grammar(PEG) - 構文解析アルゴリズムのニューカマー

　2000年代に入るまで、構文解析手法の主流はLR法の変種であり、上向き構文解析アルゴリズムでした。その理由の一つに、先読みを前提とする限り、従来のLL法はLR法より表現力が弱いという弱点がありました。下向き型でもバックトラックを用いれば幅広い言語を表現できることは比較的昔から知られていましたが、バックトラックによって解析時間が最悪で指数関数時間になるという弱点があります。そのため、コンパイラの教科書として有名な、いわゆるドラゴンブックでも現実的ではないといった記述がありました（初版にはあったはずだが、第二版にも該当記述があるかは要確認）。しかし、2004年にBryan Fordによって提案されたParsing Expression Grammar（PEG）はそのような状況を変えました。

　PEGはおおざっぱに言ってしまえば、無制限な先読みとバックトラックを許す下向き型の構文解析手法の一つです。決定的文脈自由言語に加えて一部の文脈依存言語を取り扱うことができますし、Packrat Parsingという最適化手法によって線形時間で構文解析を行うことが保証されているというとても良い性質を持っています。さらに、LL法やLR法でほぼ必須であった字句解析器が要らず、アルゴリズムも非常にシンプルであるため、ここ十年くらいで解析表現手法をベースとした構文解析生成系が数多く登場しました。

　他人事のように書いていますが、筆者が大学院時代に専門分野として研究していたのがまさしくこのPEGでした。Python 3.9ではPEGベースの構文解析器が採用されるなど、PEGは近年採用されるケースが増えています。

　2章で既にPEGを用いた構文解析器を自作したのを覚えているでしょうか。たとえば、配列の文法を表現した以下のPEGがあるとします。

```text
array = LBRACKET RBRACKET | LBRACKET {value {COMMA value}} RBRACKET ;
```

　このPEGに対応するJavaの構文解析器（メソッド）は以下のようになるのでした。

```java
    public Ast.JsonArray parseArray() {
        int backup = cursor;
        try {
            // LBRACKET RBRACKET
            parseLBracket();
            parseRBracket();
            return new Ast.JsonArray(new ArrayList<>());
        } catch (ParseException e) {
            cursor = backup;
        }

        // LBRACKET
        parseLBracket();
        List<Ast.JsonValue> values = new ArrayList<>();
        // value
        var value = parseValue();
        values.add(value);
        try {
            // {value {COMMA value}}
            while (true) {
                parseComma();
                value = parseValue();
                values.add(value);
            }
        } catch (ParseException e) {
            // RBRACKET
            parseRBracket();
            return new Ast.JsonArray(values);
        }
    }
```

　PEGの特色は、

```java
        int backup = cursor;
```

　という行によって、解析を始める時点でのソースコード上の位置を保存しておき、もし解析に失敗したら以下のように「巻き戻す」ところにあります。「巻き戻した」位置から次の分岐を試そうとするのです。

```java
        } catch (ParseException e) {
            cursor = backup;
        }
        // LBRACKET
        parseLBracket();
        // ...
```

　なお、PEGの挙動を簡単に説明するために2章および本章では例外をスロー/キャッチするという実装にしていますが、現実にはこのような実装にするとオーバーヘッドが大きすぎるため、実用的なPEGパーザでは例外を使わないことが多いです。

　一般化すると、PEGの挙動は以下の8つの要素を使って説明することができます。

1. 空文字列： ε
2. 終端記号： t
3. 非終端記号： N
4. 連接： e1 e2
5. 選択： e1 / e2
6. 0回以上の繰り返し： e*
7. 肯定述語： &e
8. 否定述語： !e
  
  次節以降では、この8つの要素がそれぞれどのような意味を持つかを説明していきます。説明のために

```java
match(e, v) == Success(consumed, rest) 
```

や

```java
match(e, v) == Failure
```

というJava言語ライクな記法を使います。

たとえば、

```java
match("x", "xy") == Success("x", "y")`
```

は式`x`が文字列`"xy"`にマッチして残りの文字列が`"y"`であることを示します。また、

```java
match("xy", "x") == Failure
```

は式`"xy"`が文字列`"x"`にマッチしないことを表現します。

### 空文字列

空文字列εは0文字**以上**の文字列にマッチします。たとえば、

```java
match(ε, "") == Success("", "")
```

が成り立つだけでなく、

```java
match(ε, "x") ==  Success("", "x")
```

や

```java
match(ε, "xyz") == Success("", "xyz")
```

も成り立ちます。εは**あらゆる文字列**にマッチすると言い換えることができます。

### 終端記号

終端記号`t`は1文字以上の長さで特定のアルファベットで**始まる**文字列にマッチします。たとえば、

```java
match(x, "x") == Success("x", "")
```

や

```java
match(x, "xy") == Success("x", "y")
```

が成り立ちます。一方、

```java
match(x, "y") == Failure
```

ですし、

```java
match(x, "") == Failure
```

です。εの場合と同じく「残りの文字列」があってもマッチする点に注意してください。



### 選択

`e1`と`e2`は共に式であるものとします。このとき、


```text
e1 / e2
```

に対する`match(e1 / e2, s)`は以下のような動作を行います。

1. `match(e1, s)`を実行する
2. 1.が成功していれば、sのサフィックスを返し、成功する
3. 1.が失敗した場合、`match(e2, s)`を実行し、結果を返す

### 選択

`e1`と`e2`は共に式であるものとします。このとき、

```text
e1 e2
```

　に対する`match(e1 e2, s)`は以下のような動作を行います。

1. `match(e1, s)`を実行する
2. 1.が成功したとき、結果を`Success(s1,s2)`とする。この時、`match(e2,s2)`を実行し、結果を返す
3. 1.が失敗した場合、その結果を返す

### 非終端記号

あるPEGの規則Nがあったとします。

```text
N <- e
```

`match(N, s)`は以下のような動作を行います。

1. `N`に対応する規則を探索する（`N <- e`が該当）
2. `N`の呼び出しから戻って来たときのために、スタックに現在位置`p`を退避
3. `match(e, s)`を実行する。結果を`M`とする。
4. スタックに退避した`p`を戻す
5. `M`を全体の結果とする

### 0回以上の繰り返し

`e`は式であるものとします。

```text
e*
```

このとき、eと文字列sの照合を行うために以下のような動作を行います。

1. `match(e,s)`を実行する
2. 1.が成功したとき（`n`回目）、結果を`Success(s_n,s_(n+1))`とする。`s`を`s_(n+1)`に置き換えて、1.に戻る
3. 1.が失敗した場合（`n`回目）、結果を`Success(s_1...s_n, s[n...])`とする

`e*`は「0回以上の繰り返し」を表現するため、一回も成功しない場合でも全体が成功するのがポイントです。なお、`e*`は規則

```
H <- e H / ε
```

に対して`H`を呼び出すことの構文糖衣であり、全く同じ意味になります。

### 肯定述語

`e`は式であるものとします。このとき、

```text
&e
```
　
は`match(&e,s)`を実行するために、以下のような動作を行います。

1. `match(e,s)`を実行する
2-1. 1.が成功したとき：結果を`Success("", s)`とする
2-2. 1.が失敗した場合：結果は`Failure()`とする

肯定述語は成功したときにも「残り文字列」が変化しません。肯定述語`&e`は後述する否定述語`!!`を二重に重ねたものに等しいことが知られています。


### 否定述語

`e`は式であるものとします。このとき、

```text
!e
```
　
は`match(!e,s)`を実行するために以下のような動作を行います。

1. `match(e,s)`を実行する
2-1. 1.が成功したとき：結果を`Failure()`とする
2-2. 1.が失敗した場合：結果は`Success("", s)`とする

否定述語も肯定述語同様、成功しても「残り文字列」が変化しません。

前述した`&e = !!e`は論理における二重否定の除去に類似するものということができます。

### PEGの操作的意味論

ここまでで、PEGを構成する8つの要素について説明してきましたが、実際のところは厳密さに欠けるものでした。より厳密に説明すると以下のようになります（Ford:04を元に改変）。先程までの説明では、`Success(s1, s2)`を使って、`s1`までは読んだことを、残り文字列が`s2`であることを表現してきました。ここではペア`(n, x)`で結果を表しており、`n`はステップ数を表すカウンタで`x`は残り文字列または`f`（失敗を表す値）となります。⇒を用いて、左の状態になったとき右の状態に遷移することを表現しています。

```
1. 空文字列: 
  (ε,x) ⇒ (1,ε) （全ての x ∈ V ∗ Tに対して）。
2. 終端記号(成功した場合): 
  (a,ax) ⇒ (1,a) （a ∈VT , x ∈V ∗ T である場合）。
3. 終端記号(失敗した場合):
  (a,bx) ⇒ (1, f) iff a ≠ b かつ (a,ε) ⇒ (1, f)。
4. 非終端記号:
  (A,x) ⇒ (n + 1,o) iff A ← e ∈ R かつ(e,x) ⇒ (n,o)。
5. 連接(成功した場合): 
  (e1, x1 x2 y) ⇒ (n1,x1) かつ　(e2, x2 y) ⇒ (n2, x2) のとき、 (e1 e2,x1 x2 y) ⇒ (n1 + n2 + 1, x1 x2)。
6. 連接(失敗した場合１): 
  (e1, x) ⇒ (n1, f) ならば　(e1 e2,x) ⇒ (n1 + 1, f). もし　e1が失敗したならば、e1e2はe2を試すことなく失敗する。
7. 連接(失敗した場合２): 
  (e1, x1 y) ⇒ (n1,x1) かつ　(e2,y) ⇒ (n2, f) ならば (e1e2,x1y) ⇒ (n1 + n2 + 1, f)。
8. 選択(場合１): 
  (e1, x y) ⇒ (n1,x) ならば (e1/e2,xy) ⇒ (n1 +1,x)。
9. 選択(場合２): 
  (e1, x) ⇒ (n1, f) かつ (e2,x) ⇒ (n2,o) ならば (e1 / e2,x) ⇒ (n1 + n2 + 1,o)。
10. 0回以上の繰り返し (繰り返しの場合): 
  (e, x1 x2 y) ⇒ (n1,x1) かつ　(e∗,x2 y) ⇒ (n2, x2) ならば (e∗,x1 x2 y) ⇒ (n1 + n2 +1,x1 x2)。
11. 0回以上の繰り返し (停止の場合）: 
  (e,x) ⇒ (n1, f) ならば (e∗,x) ⇒ (n1 + 1, ε)。
12. 否定述語（場合１): 
  (e,xy) ⇒ (n,x) ならば (!e,xy) ⇒ (n + 1, f)。
13. 否定述語（場合２): 
  (e,x) ⇒ (n, f) ならば (!e,x) ⇒ (n + 1, ε)。
```

## 4.9 - Packrat Parsing

素のPEGは非常に単純でいて、とても幅広い範囲の言語を取り扱うことができます。しかし、PEGには一つ大きな弱点があります。最悪の場合、解析時間が指数関数時間になってしまうことです。現実的にはそのようなケースは稀であるという指摘ありますが（論文を引用）、原理的にはそのような弱点があります。Packrat Parsingはメモ化という技法を用いることでPEGで表現される言語を線形時間で解析可能にします。

メモ化という技法自体をご存じでない読者の方も多いかもしれないので、まずメモ化について説明します。

### 4.9.1 fibメソッド

　メモ化の例でよく出てくるのはN番目のフィボナッチ数を求める`fib`関数です。この書籍をお読みの皆様ならお馴染みかもしれませんが、N番目のフィボナッチ数F(n)は次のようにして定義されます：

```
F(0) = 1
F(1) = 1
F(n) = F(n - 1) + F(n - 2)
```

　この再帰的定義を素朴にJavaのメソッドとして書き下したのが以下のfibメソッドになります。

```java
public class Main {
    public static long fib(long n) {
        if(n == 0 || n == 1) return 1L;
        else return fib(n - 1) + fib(n - 2); 
    }
    public static void main(String[] args) {
        System.out.println(fib(5)); // 120
    }
}
```

　このプログラムを実行すると、コメントにある通り120が出力されます。しかし、このfibメソッドには重大な欠点があります。それは、nが増えると計算量が指数関数的に増えてしまうことです。たとえば、上のfibメソッドを使うと`fib(30)`くらいまではすぐに計算することができます。しかし、`fib(50)`を求めようとすると皆さんのマシンではおそらく数十秒はかかるでしょう。

　フィボナッチ数を求めたいだけなのに数十秒もかかってはたまったものではありません。

### 4.9.2 fib関数のメモ化

　そこで出てくるのがメモ化というテクニックです。一言でいうと、メモ化とはある引数nに対して計算した結果f(n)をキャッシュしておき、もう一度同じnに対して呼び出されたときはキャッシュした結果を返すというものです。早速、fibメソッドをメモ化してみましょう。

　メモ化されたfibメソッドは次のようになります。

```java
import java.util.*;
public class Main {
    private static Map<Long, Long> cache = new HashMap<>();
    public static long fib(long n) {
        Long value = cache.get(n);
        if(value != null) return value;

        long result;
        if(n == 0 || n == 1) {
            result = 1L;
        } else {
            result = fib(n - 1) + fib(n - 2);
        }
        cache.put(n, result);
        return result;
    }
    public static void main(String[] args) {
        System.out.println(fib(50)); // 20365011074
    }
}
```

　`fib(50)`の結果はコメントにある通りですが、今度は一瞬で結果がかえってきたのがわかると思います。メモ化されたfibメソッドでは同じnに対する計算は二度以上行われないので、nが増えても実行時間は線形にしか増えません。つまり、fib(50)の実行時間は概ねfib(25)の二倍であるということです。

　ただし、計算量に詳しい識者の方は「おいおい。整数同士の加算が定数時間で終わるという仮定はおかしいんじゃないかい？」なんてツッコミを入れてくださるかもしれませんが、そこを議論するとややこしくなるので整数同士の加算はたかだか定数時間で終わるということにします。

　`fib`メソッドのメモ化でポイントとなるのは、記憶領域（`cache`に使われる領域）と引き換えに最悪計算量を指数関数時間から線形時間に減らせるということです。また、メモ化する対象となる関数は一般的には副作用がないものに限定されます。というのは、メモ化というテクニックは「同じ引数を渡せば同じ値が返ってくる」ことを暗黙の前提にしているからです。

　次の項ではPEGをナイーヴに実装した`parse`関数をまずお見せして、続いてそれをメモ化したバージョン（Packrat parsing）をお見せすることにします。`fib`メソッドのメモ化と同じようにPEGによる構文解析もメモ化できることがわかるでしょう。

### 4.9.3 parseメソッド

　ここからは簡単なPEGで記述された文法を元に構文解析器を組み立てていくわけですが、下記のような任意個の`()`で囲まれた`0`の構文解析器を作ります。

```
A <- "(" A ")"
   / "(" A A ")"
   / "0"
```

　単純過ぎる例にも思えますが、メモ化の効果を体感するにはこれで十分です。早速構文解析器を書いていきましょう。

```java
sealed interface ParseResult permits ParseResult.Success, ParseResult.Failure {
    public abstract String rest();
    record Success(String value, String rest) implements ParseResult {}
    record Failure(String rest) implements ParseResult {}
}
class ParseError extends RuntimeException {
    public final String rest;
    public String rest() {
        return rest;
    }
    ParseError(String rest) {
        this.rest = rest;
    }
}
public class Parser {
    private static boolean isEnd(String string) {
        return string.length() == 0;
    }
    public static ParseResult parse(String input) {
        String start = input;
        try {
            // "(" A ")"
            if(isEnd(input) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            var result = parse(input.substring(1));
            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;

            input = success.rest();
            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        try {
            // "(" A A ")"
            if((isEnd(input)) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            var result = parse(input.substring(1));
            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;
            input = success.rest();

            result = parse(input);

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            success = (ParseResult.Success)result;
            input = success.rest();

            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), success.rest().substring(1));
        } catch (ParseError error) {
            input = start;
        }

        if(isEnd(input) || input.charAt(0) != '0') {
            return new ParseResult.Failure(input);
        }

        return new ParseResult.Success(input.substring(0, 1), input.substring(1));
    }
}
```

このプログラムを使うと以下のように構文解析を行うことが出来ます。

```java
jshell> Parser.parse("(");
$25 ==> Failure[rest=]
jshell> Parser.parse("()");
$26 ==> $26 ==> Failure[rest=)]
jshell> Parser.parse("(0)");
$27 ==> Success[value=), rest=]
```
　
しかし、この構文解析器には弱点があります。`(((((((((((((((((((((((((((0)))`のようなカッコのネスト数が深いケースで急激に解析にかかる時間が増大してしまうのです。これはまさにPEGだからこそ起こる問題点だと言えます。

### 4.9.4 parseメソッドのメモ化 - Packrat Parsing

4.9.3のコードをもとに`parse`メソッドをメモ化してみましょう。コードは以下のようになります。

```java
import java.util.*;
sealed interface ParseResult permits ParseResult.Success, ParseResult.Failure {
    public abstract String rest();
    record Success(String value, String rest) implements ParseResult {}
    record Failure(String rest) implements ParseResult {}
}
class ParseError extends RuntimeException {
    public final String rest;
    public String rest() {
        return rest;
    }
    ParseError(String rest) {
        this.rest = rest;
    }
}
class PackratParser {
    private Map<String, ParseResult> cache = new HashMap<>();
    private boolean isEnd(String string) {
        return string.length() == 0;
    }
    public ParseResult parse(String input) {
        String start = input;
        try {
            // "(" A ")"
            if(isEnd(input) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            input = input.substring(1);
            ParseResult result;
            result = cache.get(input);
            if(result == null) {
                result = parse(input);
                cache.put(input, result);
            }

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;

            input = success.rest();
            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        try {
            // "(" A A ")"
            if((isEnd(input)) || input.charAt(0) != '(') {
                throw new ParseError(input);
            }

            input = input.substring(1);
            ParseResult result;
            result = cache.get(input);
            if(result == null){
                result = parse(input);
                cache.put(input, result);
            } 

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            var success = (ParseResult.Success)result;
            input = success.rest();

            result = cache.get(input);
            if(result == null) {
                result = parse(input);
                cache.put(input,result);
            }

            if(!(result instanceof ParseResult.Success)) {
                throw new ParseError(result.rest());
            }

            success = (ParseResult.Success)result;
            input = success.rest();

            if(isEnd(input) || input.charAt(0) != ')') {
                throw new ParseError(input);
            }

            return new ParseResult.Success(success.value(), input.substring(1));
        } catch (ParseError error) {
            input = start;
        }

        if(isEnd(input) || input.charAt(0) != '0') {
            return new ParseResult.Failure(input);
        }

        return new ParseResult.Success(input.substring(0, 1), input.substring(1));
    }
}
```

```java
    private Map<String, ParseResult> cache = new HashMap<>();
```

というフィールドが加わったことです。このフィールド`cache`がパーズの途中結果を保持してくれるために計算が高速化されるのです。結果として、PEGでは最悪指数関数時間かかっていたものがPackrat Parsingでは入力長に対してたかだか線形時間で解析できるようになりました。

PEGは非常に強力な能力を持っていますが、同時に線形時間で構文解析を完了できるわけで、これはとても良い性質です。そういった理由もあってか、PEGやPackrat Parsingを用いた構文解析器や構文解析器生成系はここ10年くらいで大幅に増えました。

## 4.10 - Generalized LR (GLR) Parsing

GLR（Generalized LR）法は、Tomitaによって提案された手法で、曖昧な文法や非決定性を含む文法を扱うことができます。GLRは解析中に可能性のある複数の解析パスを同時に追跡し、すべての解釈を得ることができます。

### GLRの特徴

- 複数の解析スタックを同時に管理
- シフト・還元動作を一般化
- 木構造の共有によりメモリ効率を向上

GLRは曖昧さを扱えるため、自然言語処理や曖昧な構文を持つプログラミング言語の解析に適しています。

## 4.11 - Generalized LL (GLL) Parsing

GLL（Generalized LL）法は、LL法を拡張して曖昧な文法を扱えるようにした手法で、Scottらによって2010年に提案されました（Scott:2010）。GLL法は再帰下降構文解析機を一般化したもので、非決定性を処理するために解析スタックと呼ばれるデータ構造を用います。

GLLの特徴は以下の通りです。

- 再帰下降構文解析機の拡張
- 非決定性を処理できる
- 部分的なメモ化による効率化

## 4.12 - Parsing with Derivatives (PwD)

Parsing with derivatives(PwD)はPwD（Parsing with Derivatives）は、正規表現の微分の概念を文脈自由文法に拡張した手法で、Mightらによって2011年に提案されました（Might:2011）。関数型のプログラムとして記述され、遅延評価や無限リストを活用します。

PwDの特徴は以下の通りです。

- 理論的にシンプル
- 遅延評価による効率化
- 関数型プログラミング言語での実装が容易

## 4.13 - Tunnel Parsing 

[トンネル構文解析](https://dl.acm.org/doi/abs/10.2478/cait-2022-0021)は、曖昧性のある文法を効率的に解析するための新しい手法です。解析の過程で不要な部分をスキップ（トンネル）することで、効率的な解析を実現します。

トンネル構文解析の特徴は以下の通りです。

- 不要な解析パスを早期に除外
- メモリ使用量の削減
- 特定の問題領域での効率的な解析

## 4.1４ - 構文解析アルゴリズムの計算量と表現力の限界 

　LL parsing、LR parsing、PEG、Packrat parsing、GLR parsing、GLL parsingについてこれまで書いてきましたが、計算量的な性質についてまとめておきましょう。なお、`n`は入力文字列長を表します。

| アルゴリズム        | 時間計算量     | 空間計算量                      |
| ------------------- | ------------- | ------------------------------- | 
| LL(1)               | O(n)          | O(&#124;N&#124; * &#124;T&#124;) |
| LL(k)               | O(n)          | ???                             |
| SLR(1)              | O(n)          | O(&#124;N&#124; * &#124;P&#124; * &#124;T&#124;) |
| LR(1)               | O(n)          | O(s * &#124;T&#124;)            |
| LALR(1)             | O(n)          | O(s * &#124;T&#124;)            |
| PEG                 | O(2^n)        | O(n)                            |
| Packrat Parsing     | O(n)          | O(n * &#124;P&#124;)            |
| GLR                 | O(n^3)        | O(n^3)                          |
| GLL                 | O(n^3)        | O(n^3)                          |
| PwD                 | O(n^3)        | O(n^3)                          |
| トンネル構文解析    | 問題に依存     | 問題に依存                      |

nは全てのアルゴリズムで入力文字列の長さを表します。その他の記号については以下の通りです。

- LL(1)
  - `|S|`: 開始記号列のサイズ
  - `|T|`: は終端記号の数
- SLR(1):
  - `|N|`: 規則の右辺のサイズ
  - `|P|`: 規則の数
  - `|T|`: 終端記号の数
- LR(1):
  - s: 状態数
  - `|T|`: 終端記号の数
- LALR(1):
  - s: 状態数
  - `|T|`: 終端記号の数
- PEG or packrat parsing
  - `|P|`: 規則の数

LL(1)やLR(1)は線形時間で解析を終えられますが、GLRやGLLは最悪の場合多項式時間を要します。PEGは指数時間がかかることがありますが、Packrat Parsingによって線形時間で解析できるようになります。

## 4.15 - まとめ

この章では構文解析アルゴリズムの中で比較的メジャーな手法について、そのアイデアと概要を含めて説明しました。その他にも多数の手法がありますが、いずれにせよ、「上から下に」向かって解析する下向きの手法と「下から上に」向かって解析する上向きの手法のどちらかに分類できると言えます。

GLRやGLL、PwDについては普段触れる機会はそうそうありませんが、LLやLR、PEGのパーサジェネレータは多数存在するため、基本的な動作原理について押さえておいて損はありません。また、余裕があれば各構文解析手法を使って実際のパーサジェネレータを実装してみるのも良いでしょう。実際にパーサジェネレータを実装することで、より深く構文解析手法を理解することもできます。