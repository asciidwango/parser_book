# 第5章 構文解析アルゴリズム古今東西

第4章で学んだ文脈自由文法は、構文解析の理論的な基礎です。特にDyck言語（ディック言語）を例に、括弧の対応という根本的な問題を通して、再帰的な構造を文法でどう表現するかを学びました。この章では、いよいよその文法を実際に解析するための「アルゴリズム」について深く掘り下げていきます。

## 本章で学ぶこと

「構文解析アルゴリズム」と聞くと難しそうに感じるかもしれません。しかし、実は皆さんはすでに2つの構文解析アルゴリズムを実装しているのです。

第3章を思い出してください。最初に実装した`PegJsonParser`は、**PEG（Parsing Expression Grammar）**という手法の素朴な実装でした。次に実装した`SimpleJsonParser`は、実は**LL(1)**（「エルエルワン」と読みます）と呼ばれる手法に近い**再帰下降構文解析器**だったのです。

この章では、これらのアルゴリズムがどのような仕組みで動いているのか、他にどのようなアルゴリズムが存在するのかを体系的に学びます。具体的には：

1. **予測型下向き構文解析（Predictive Top-down Parsing）**：文法の開始記号から始めて、入力文字列に向かって解析を進める方法
    - 先読みを使って適用する規則を予測する
    - LL(1)
   
2. **予測型上向き構文解析（Predictive Bottom-up Parsing）**：入力文字列から始めて、文法の開始記号に向かって解析を進める方法
    - シフトと還元を使って解析を進める
    - LR(0)、SLR(1)、LR(1)、LALR(1)
   
3. **下向き構文解析+バックトラック**：先読みの代わりにバックトラックを使う方法
    - PEG（Parsing Expression Grammar）、Packrat Parsing

それぞれのアルゴリズムには得意・不得意があり、実際のプログラミング言語の構文解析器では、言語の特性に応じて最適なアルゴリズムが選ばれています。

## 構文解析器生成系との関係

各アルゴリズムには、対応する**構文解析器生成系**（パーサージェネレータ）が存在します（自作することもできます）：

- **Yacc/Bison**：
  - LALR(1)を採用
  - C言語向け
- **JavaCC**：
  - LL(1)を採用
  - Java向け
- **ANTLR**：
  - ALL(*)を採用（拡張されたLL系を採用）
  - 多言語対応
- **各種PEGパーサジェネレータ**：PEGを採用

これらのツールについては第6章で詳しく説明しますが、本章でアルゴリズムを理解することで、各ツールがなぜそのアルゴリズムを選んだのかが見えてくるはずです。

## 下向き構文解析と上向き構文解析 - 2つの世界観

構文解析アルゴリズムの世界には、大きく分けて2つの「世界観」があります。それが**下向き（Top-down）**と**上向き（Bottom-up）**です。この2つは、同じ構文解析という仕事を、まったく逆のアプローチで実現します。

### なぜ2つのアプローチが必要なのか？

第4章で学んだDyck言語を例に考えてみましょう。文法は以下でした：

```
D → P
P → ( P ) P
P → ε
```

入力文字列 `(())` を解析する際、2つの考え方ができます：

1. **下向き（予測的）**：「Dから始まって、どうすれば`(())`が導出できるか？」
2. **上向き（還元的）**：「`(())`から始めて、どうすればDに辿り着けるか？」

これは、迷路を解くときに「入口から出口を探す」か「出口から入口を探す」かの違いに似ています。どちらも正解に辿り着きますが、効率や適用できる問題が異なるのです。

## 下向き構文解析の基本原理

下向き構文解析は、文法の開始記号から出発し、入力文字列に向かって「上から下へ」解析を進めます。

### Dyck言語で学ぶ予測型下向き構文解析

第4章で学んだDyck言語（括弧の対応が取れた文字列を表す言語）を例に、具体的に動作を追ってみましょう。説明のために、文法に入力の開始・終了を表す`$`（ドル記号）を追加します：

```
D -> $ P $
P -> ( P ) P
P -> ε
```

入力文字列 `(())` に対して、この文法が受理するかどうかを判定してみましょう。

### スタックを使った解析の追跡

予測型下向き構文解析では、**スタック**を使って解析の進行状況を管理します。スタックには、「今どの規則のどの位置を解析しているか」という情報を記録します。

ドット記号「・」（中黒）を使って、規則内の現在位置を表します。例えば：

- `D -> ・$ P $` ：まだ何も解析していない状態
- `D -> $・P $` ：`$`を解析済み、次は`P`を解析する
- `D -> $ P $・` ：すべて解析完了

このドット記号は、Javaでいえばデバッガーでステップ実行する時の「現在の実行位置」のようなものだと考えてください。

では、実際に解析を開始しましょう：

```
入力: $ ( ( ) ) $
スタック: [ D -> ・$ P $ ]
```

1. 最初の記号 `$` を入力から読み込みます。スタックトップの規則が期待する記号と一致するので、ドットを進めます：

```
入力: ( ( ) ) $
スタック: [ D -> $・P $ ]
```

2. 非終端記号 `P` を解析する必要があります。ここで「予測」（あるいは先読み）、が必要になります。

非終端記号とは、第2章で学んだように「まだ展開の余地がある記号」のことでした。Javaでいえばメソッド呼び出しのようなものです。

次の入力文字（先読み文字）は `(` です。`P`の規則は2つあります：

- `P -> ( P ) P` ：`(`で始まる
- `P -> ε` ：空文字列（何もない）

ここで、どちらを選ぶかを事前に決める必要があります。先読み文字が`(`でかつ`P`は常に`(`で始まるので、`P -> ( P ) P`を選択します。この規則をスタックに追加します：

```
入力: ( ( ) ) $
スタック: [P -> ・( P ) P, D -> $・P $]
```

3. 入力の先頭の `(` を読み込み、スタックトップの規則のドットを進めます：

```
入力: ( ) ) $
スタック: [P -> (・ P ) P, D -> $・P $]
```

4. 非終端記号 `P` を解析するため、再び先読み文字を見ます。

次の先読み文字は `(` です。先ほどと同様に `P -> ( P ) P` を選択して、この規則をスタックに追加します：

```text
入力: ( ) ) $
スタック: [P -> ・ ( P ) P, P -> ( ・ P ) P, D -> $・P $]
```

5. 入力の先頭の `(` を読み込み、スタックトップの規則のドットを進めます：

```
入力: ) ) $
スタック: [P -> ( ・ P ) P, P -> ( ・P ) P, D -> $・P $]
```

6. 非終端記号 `P` を解析するため、先読み文字を見ます。

次の先読み文字は `)` です。今度は、`P -> ε` を選択します。空文字列にマッチするので、ドットを進めるだけで、入力からは何も消費しません：

```
入力: ) ) $
スタック: [P -> ( P ・ ) P, P -> ( ・P ) P, D -> $・P $]
```

7. 入力の先頭の `)` を読み込み、スタックトップの規則のドットを進めます：

```
入力: ) $
スタック: [P -> ( P ) ・ P, P -> ( ・P ) P, D -> $・P $]
```

8. 非終端記号 `P` を解析するため、先読み文字を見ます。

次の先読み文字は `)` です。ここで、`P -> ε` を選択します。空文字列にマッチするので、ドットを進めるだけで、入力からは何も消費しません：

```
入力: ) $
スタック: [P -> ( P ) P ・, P -> ( ・P ) P, D -> $・P $]
```

9. スタックトップの規則のドットが最後まで進んだので、スタックからその規則を除去すると同時に、新たなスタックトップのドットを進めます：


```
入力: ) $
スタック: [P -> ( P ・) P, D -> $・P $]
```

10.  入力の先頭の `)` を読み込み、スタックトップの規則のドットを進めます：

```
入力: $
スタック: [P -> ( P ) ・ P, D -> $・P $]
```

11. 非終端記号 `P` を解析するため、先読み文字を見ます。

次の先読み文字は `$` です。ここで、`P -> ε` を選択します。空文字列にマッチするので、ドットを進めるだけで、入力からは何も消費しません：

```
入力: $
スタック: [P -> ( P ) P ・, D -> $ ・ P $]
```

12. スタックトップの規則のドットが最後まで進んだので、スタックからその規則を除去すると同時に、新たなスタックトップのドットを進めます：

```
入力: $
スタック: [D -> $ P ・ $]
```

13. 入力の先頭の `$` を読み込み、スタックトップの規則のドットを進めます：

```
入力:
スタック: [D -> $ P $ ・]
```

14. ここでスタックトップの規則のドットが最後まで進んだので、スタックからその規則を除去します。スタックが空になり、入力もすべて消費されたので、受理されます。

```
入力:
スタック: []
```

このように、「先読み文字を見て、次に適用すべき規則を予測する」のが予測型下向き構文解析の特徴です。

### 予測型下向き構文解析のアルゴリズム

予測型下向き構文解析の動作パターンをまとめると以下のようにになります：

1. 先読み文字の取得：
    - 現在の入力位置から1文字先を見る

2. 非終端記号の展開：
    - スタックトップが非終端記号の場合、先読み文字に基づいて適用する規則を「予測」
    - 選択した規則をスタックに追加
    - 適切な規則がない場合はエラー

3. 終端記号のマッチング：
    - スタックトップが終端記号の場合、入力文字と比較
    - 一致すれば入力を消費してドットを進める
    - 一致しなければエラー

4. 規則の完了：
    - 規則の最後まで進んだら、スタックからその規則を除去
    - 一つ上の規則の解析を続行

5. 受理判定：
    - 入力がすべて消費され、スタックが空になれば受理
    - それ以外は拒否

## 予測型再帰下降構文解析 - 下向き構文解析のJava実装

スタックを使った下向き構文解析の動作を理解したところで、これをJavaで実装してみましょう。多くの場合、スタックを明示的に使わずに**再帰呼び出し**を使って実装できます。第3章で実装した`SimpleJsonParser`は、予測型再帰下降構文解析の一種で、実装もほぼ同じです。

```java
// 文法規則：
// D -> P
// P -> ( P ) P
// P -> ε（イプシロン：空文字列）
public class Dyck {
    private final String input;
    private int pos;

    public Dyck(String input) {
        this.input = input;
        this.pos = 0;
    }

    public boolean parse() {
        boolean result = D();
        return result && pos == input.length();
    }

    private boolean D() {
        return P();
    }

    private boolean P() {
        // 先読み文字が '(' の場合
        if (pos < input.length() && input.charAt(pos) == '(') {
            // P -> ( P ) P
            pos++; // '(' を読み進める
            if (!P()) return false;
            if (pos < input.length() && input.charAt(pos) == ')') {
                pos++; // ')' を読み進める
                return P();
            } else {
                return false;
            }
        } else {
            // P -> ε
            return true;
        }
    }
}
```

### コードの解説

この実装では、各非終端記号に対応するメソッドを作成しています：

- `D()`メソッド：文法の開始記号`D`に対応
  - 規則 `D -> P` をそのまま実装：`P()`を呼び出すだけ

- `P()`：非終端記号`P`に対応
  - 最初に `P -> ( P ) P` を試す：先読み文字が`(`か確認
  - 適用できない場合は `P -> ε` を適用：常に`true`を返す

- 文字の消費：`pos`をインクリメントすることで実現

- バックトラックのない予測型：一度選択した規則で失敗したら、即座に`false`を返す

### 文法規則とコードの対応関係

BNF規則とJavaコードの対応を見てみましょう：

```
文法規則： D -> P
Javaコード： private boolean D() { return P(); }

文法規則： P -> ( P ) P | ε  
Javaコード： private boolean P() {
    if (先読み文字 == '(') {
        // P -> ( P ) P を適用
    } else {
        // P -> ε を適用
    }
}
```

- 各非終端記号にメソッドが対応
- 非終端記号の参照はメソッド呼び出しに変換
- 選択はif文で実現
- 連接は順次実行で実現

と対応しています。

### 「再帰」「下降」という名前の由来

この実装方法が「再帰下降」と呼ばれる理由は：

1. 再帰：メソッドが自分自身または他のメソッドを呼び出す
2. 下降：文法の開始記号から「下」の規則へと解析が進む

実際に`parse("(())")`を実行すると、以下のような呼び出しの連鎖が発生します：

```
parse() -> D() -> P() -> P() -> P() -> ...
```

この呼び出しスタックが、先ほどスタックで説明した状態と対応しているのです。

## 上向き構文解析の基本原理

下向き構文解析を理解したところで、次は**上向き構文解析**を見ていきましょう。こちらは下向きとは全く逆のアプローチを取ります。

### シフト還元構文解析の基本アイデア

ナイーブな（素直な）上向き構文解析は**シフト還元構文解析**とも呼ばれます。この名前は、2つの基本操作から来ています：

- シフト（Shift）：入力から1文字読み込んでスタックに積む
- 還元（Reduce）：スタック上の記号列が某規則の右辺と一致したら、左辺に置き換える

下向き構文解析が「文法から入力へ」と進むのに対し、上向き構文解析は「入力から文法へ」と進みます。入力文字列を徐々に「縮めて」いって、最終的に開始記号に辿り着けるかを確認するのです。

比喩としては、テトリスのブロックを積み上げていくようなイメージです。入力文字列を1文字ずつ積み上げ、規則にマッチしたらその部分を消すことで、最終的に開始記号だけが残るようにします。

### 例で学ぶシフト還元構文解析

同じDyck言語を例にしますが、ナイーブな上向き構文解析では空文字列規則（ε規則）が扱いづらいので、等価な別の文法を使います：

```
D -> $ P $
D -> $ ε $
P -> P X
P -> X
X -> ( X )
X -> ()
```

この文法の特徴は以下の通りです：

- `X`は内側の括弧ペアを表す
- `P`は括弧ペアの列を表す
- `D`は全体を表す

では、入力文字列 `(())` に対してシフト還元構文解析を行ってみましょう。

1. 開始記号`$`をシフト

```
スタック: [ $ ]
入力: ( ( ) ) $
```

2. 最初の`(`をシフト

```
入力: ( ) ) $
スタック: [ $, ( ]
```

3. さらに`(`をシフト

```
入力: ) ) $
スタック: [ $, (, ( ]
```

4. さらに`)`をシフト

```
入力: ) $
スタック: [ $, (, (, ) ]
```

5. スタックの末尾`(, )`が規則`X -> ()`の右辺と一致。2つの記号を`X`に**還元**：

```
入力: ) $
スタック: [ $, (, X ]
```

6. 次の`)`をシフト

```
入力: $
スタック: [ $, (, X, ) ]
```

7. スタックの末尾`(, X, )`が規則`X -> ( X )`の右辺と一致。3つの記号を`X`に**還元**：

```
入力: $
スタック: [ $, X ]
```

8. スタックの末尾`X`が規則`P -> X`の右辺と一致。1つの記号を`P`に**還元**：

```
入力: $
スタック: [ $, P ]
```

9. `$`をシフト

```
入力: 
スタック: [ $, P, $ ]
```

9. スタックの末尾`$, P, $`が規則`D -> $ P $`の右辺と一致。3つの記号を`D`に**還元**：

```
入力:
スタック: [ D ]
```

入力が空になり、スタックに開始記号`D`だけが残ったので、受理されます。

### シフト還元構文解析のアルゴリズム

シフト還元構文解析の動作パターンをまとめると：

1. シフト操作：
  - 入力から1文字読み込んでスタックに積む
  - 常に左から右へ順番に読む

2. 還元操作：
  - スタック上端の記号列が、ある規則の右辺と一致したら
  - その記号列を取り除いて、規則の左辺の非終端記号を積む

3. アクションの選択：
  - シフトと還元のどちらを行うかを決定する必要がある
  - この決定方法がLR(0)、SLR(1)、LR(1)などの違いになる

4. 受理判定：
  - 入力をすべて読み、スタックが開始記号だけになれば受理
  - それ以外は拒否

### 下向きと上向きの違い

ここまでの例からわかるように：

- **下向き**：`D`から始めて`(())`を「生成」しようとする
- **上向き**：`(())`から始めて`D`に「還元」しようとする

上向き構文解析の還元操作は、第4章で学んだ「最右導出」の逆操作に相当します。つまり、導出の過程を逆再生しているのです。

## シフト還元構文解析のJava実装

シフト還元構文解析をJavaで実装してみましょう。予測型下向き構文解析とは異なり、明示的にスタックを使い、規則をデータ構造として扱います。

### 必要なデータ構造

まず、記号（終端記号・非終端記号）を表すクラスと、文法規則を表すクラスが必要です：

```java
// 記号を表すインターフェース
interface Element {
    char value();
}

// 終端記号（実際の文字：'(', ')', '$'など）
record Terminal(char value) implements Element {}

// 非終端記号（文法記号：'D', 'P', 'X'など）
record NonTerminal(char value) implements Element {}
```

次に、文法規則を表す`Rule`クラスを定義します：

```java
import java.util.List;
import java.util.ArrayList;

public record Rule(char lhs, List<Element> rhs) {
    // 可変長引数コンストラクタ（便利のため）
    public Rule(char lhs, Element... rhs) {
        this(lhs, List.of(rhs));
    }
    
    // スタックの上端がこの規則の右辺と一致するか判定
    public boolean matches(List<Element> stack) {
        if (stack.size() < rhs.size()) return false;
        
        // スタックの上からrhs.size()個の要素を比較
        for (int i = 0; i < rhs.size(); i++) {
            Element elementInRule = rhs.get(i);
            Element elementInStack = stack.get(
                stack.size() - rhs.size() + i
            );
            if (!elementInRule.equals(elementInStack)) {
                return false;
            }
        }
        return true;
    }
}
```

### シフト還元構文解析器の実装

上記のデータ構造を使って、実際のシフト還元構文解析器を実装します：

```java
import java.util.List;
import java.util.ArrayList;

public class DyckShiftReduce {
    private final String input;
    private int position;
    private final List<Rule> rules;
    private final List<Element> stack = new ArrayList<>();

    public DyckShiftReduce(String input) {
        this.input = input;
        this.position = 0;
        
        // 文法規則の定義
        this.rules = List.of(
            // D -> $ P $
            new Rule('D', 
                new Terminal('$'), 
                new NonTerminal('P'), 
                new Terminal('$')
            ),
            // D -> $ $ (空文字列の場合)
            new Rule('D', 
                new Terminal('$'), 
                new Terminal('$')
            ),
            // P -> P X
            new Rule('P', 
                new NonTerminal('P'), 
                new NonTerminal('X')
            ),
            // P -> X
            new Rule('P', 
                new NonTerminal('X')
            ),
            // X -> ( X )
            new Rule('X', 
                new Terminal('('), 
                new NonTerminal('X'), 
                new Terminal(')')
            ),
            // X -> ()
            new Rule('X', 
                new Terminal('('), 
                new Terminal(')')
            )
        );
    }

    public boolean parse() {
        // 開始記号$をスタックに積む
        stack.add(new Terminal('$'));
        
        // メインループ：シフトと還元を繰り返す
        while (true) {
            // まず還元を試みる
            if (!tryReduce()) {
                // 還元できない場合、シフトを試みる
                if (position < input.length()) {
                    char c = input.charAt(position);
                    stack.add(new Terminal(c));
                    position++;
                } else {
                    // シフトもできないので終了
                    break;
                }
            }
        }
        
        // 終端記号$をスタックに積む
        stack.add(new Terminal('$'));
        
        // 最後に可能な限り還元を繰り返す
        while (tryReduce()) {
            // 還元ができなくなるまで続ける
        }
        
        // スタックが[D]のみになったら受理
        return stack.size() == 1 && 
               stack.get(0).equals(new NonTerminal('D'));
    }

    private boolean tryReduce() {
        for (Rule rule : rules) {
            if (rule.matches(stack)) {
                // マッチしたら右辺の長さ分スタックから削除
                for (int i = 0; i < rule.rhs().size(); i++) {
                    stack.remove(stack.size() - 1);
                }
                // 左辺の非終端記号をスタックに追加
                stack.add(new NonTerminal(rule.lhs()));
                return true; // 還元成功
            }
        }
        return false; // 還元できる規則がなかった
    }
}
```

### 実装のポイント

この実装の重要な点は以下の通りです：

1. シフトより還元を優先：  まず`tryReduce()`で還元を試み、できない場合のみシフト
2. 単純な還元ルール：     すべての規則を順番にチェックし、最初にマッチしたものを使う
3. 明示的なスタック操作： `List<Element>`をスタックとして使い、要素の追加・削除を明示的に行う

この実装は最も単純なシフト還元構文解析で、実用的なパーサでは洗練されたアルゴリズム（LR(0)、SLR(1)、LR(1)、LALR(1)）が使われます。

## 下向き構文解析と上向き構文解析の比較

ここまで下向き構文解析と上向き構文解析の具体例を見てきました。両者にはそれぞれ得意不得意があります。

### 下向き構文解析の利点と欠点

**利点：**

1. 直感的な実装

  - 文法規則とメソッドが1対1に対応
  - 手書きの構文解析器が書きやすい
  - 多くのプログラミング言語のコンパイラが手書き再帰下降を採用

2. 文脈依存の扱いやすさ

  - メソッドの引数で情報を渡せる
  - 解析中に状態を管理しやすい
  - エラー回復やエラーメッセージの生成が容易

3. デバッグのしやすさ

  - 通常の関数呼び出しなのでデバッガで追える
  - 構文解析の過程が理解しやすい

**欠点：**

1. 左再帰の問題

たとえば、以下のBNFは上向き型だと普通に解析できますが、工夫なしに下向き型で実装すると無限再帰に陥ってスタックオーバーフローします。

```text
A -> A "a" | ε // 左再帰を含む文法の例 (εは空文字列)
```

この文法は「`A`は、`A`の後に`a`が続くか、何もないか」という意味ですが、`A`を解析するためにまず`A`を解析する必要があるので無限ループになります。

このような問題を下向き型で解決する方法も存在します。例えば、以下のように等価な右再帰の文法に書き換えることで除去できます。

```text
A -> "a" A | ε
```

この変換により、下向き構文解析で問題となる無限再帰を避けることができます。ただし、文法の書き換えは常に簡単とは限りません。

### 上向き構文解析の利点と欠点

**利点：**

1. 左再帰を自然に扱える
2. より広いクラスの文法を扱える
3. 効率的な構文解析表による高速化が可能

**欠点：**

1. 実装が複雑
2. 文脈依存の処理が難しい

たとえば、それまでの文脈に応じて構文解析のルールを切り替えたくなることがあります。最近の言語によく搭載されている文字列補間などはその最たる例です。

たとえば、`"`の中は文字列リテラルとして特別扱いされますが、その中で`#{`が出てきたら（Rubyの場合）、通常の式を構文解析するときのルールに戻る必要があります。

このように、文脈に応じて適用するルールを切り替えるのは下向き型が得意です。もちろん、上向き型でも実現できないわけではありません。実際、Rubyの構文解析機はYaccの定義ファイルから生成されるようになっていますが、Yaccが採用しているのは代表的な上向き構文解析法である`LALR(1)`です。

## LL(1) - 代表的な下向き構文解析アルゴリズム

ここからは、具体的な構文解析アルゴリズムについて詳しく見ていきましょう。まずは下向き構文解析の代表格である**LL(1)**から始めます。

### LL(1)とは？

**LL(1)**という名前は以下の意味を持ちます：

1. 最初のL：**L**eft-to-right（左から右へ入力を読む）
2. 2番目のL：**L**eftmost derivation（最左導出を行う）
3. (1)：1トークン先読み

つまり「1トークン先を見て、次に適用すべき規則を一意に決定できる」という制約を持つ下向き構文解析法です。

この「LL」という名前の由来ですが、構文解析の研究が盛んだった1960年代に、様々な手法を分類するために考案された命名規則です。同様に、後で出てくる「LR」も「Left-to-right, Rightmost derivation」を表します。

### LL(1)の直感的な理解

身近な例で考えてみましょう。Javaのif文とwhile文の解析を例にします：

```java
if (age < 18) {
    System.out.println("18歳未満です");
}

while (count > 0) {
    count--;
}
```

プログラマがこのコードを見たとき、最初のトークンだけで文の種類を判断できます：
    - `if`で始まる → if文だ！
    - `while`で始まる → while文だ！

LL(1)は、まさにこの「最初の1トークンで判断」というアイデアをアルゴリズム化したものです。

しかし、すべての構文がこのように単純ではありません。例えば、以下の単純な算術式を考えてみましょう。`Num`は終端記号とします：

```
E  → Num
E  → ( E )
E  → - E
```

この場合、`E`は以下のいずれかで始まる可能性があります：

- Num（例：`42`）
- 左括弧（例：`(3 + 5)`）
- マイナス記号（例：`-10`）

つまり、`E`という非終端記号は複数のトークンで始まる可能性があるのです。

### なぜFIRST集合とFOLLOW集合が必要か

LL(1)を実現するには、以下の2つの問題を解決する必要があります：

1. 複数のトークンで始まる構文

上の算術式の例のように、一つの非終端記号が複数のトークンで始まる場合があります。これを体系的に扱うために**FIRST集合**（その非終端記号から始まる可能性のあるトークンの集合）が必要です。

2. 省略可能な要素

Javaのif文には、else節があるものとないものがあります：

```java
// else節なし
if (condition) { ... }

// else節あり
if (condition) { ... } else { ... }
```

else節は「あってもなくてもいい」要素です。このような場合、else節の後に何が来るかを知る必要があります。これが**FOLLOW集合**（その非終端記号の後に来る可能性のあるトークンの集合）です。

### FIRST集合とFOLLOW集合

LL(1)構文解析を実現するには、これらの集合を計算して利用します：

#### FIRST集合

ある非終端記号から導出される文字列の「最初に現れうるトークンの集合」を**FIRST集合**と呼びます。

正式には、非終端記号`A`に対して以下のように定義されます：

```
FIRST(A) = { a | A ⇒* aβ であるような終端記号 a }
```

ここで、`A ⇒* aβ`は、非終端記号`A`が何らかの導出を経て、終端記号`a`で始まる文字列に変換できることを意味します。

例えば、先ほどでてきた以下の算術式の文法を考えます。

```
E  → Num
E  → ( E )
E  → - E
```

この場合、FIRST集合は次のようになります：

```
FIRST(E) = { '(', '-', Num }
```

#### nullable - 空文字列を生成できるか

LL(1)構文解析で重要な概念として、**nullable**（ヌラブル）があります。これは、ある非終端記号が空文字列（ε）を生成できるかどうかを示すブール値です。

**nullable**という名前はJavaの`null`とは関係ありません。「空にできる」つまり「何も生成しないことができる」という意味です。

例えば、以下の文法を考えます：

```
A -> $ a B C $
B -> b | ε
C -> d C | ε
```

この場合：

- `nullable(A) = false`（`A`は必ず`a`と`$`を含むため）
- `nullable(B) = true`（`B -> ε`という規則があるため）
- `nullable(C) = true`（`C -> ε`という規則があるため）

何故`nullable`が重要かというと、**FIRST集合**及び**FOLLOW集合**を計算するためです。**FIRST集合**の計算では、非終端記号が空文字列を生成できるかどうかを確認する必要があります。また、**FOLLOW集合**の計算でも、非終端記号が空文字列を生成できる場合、その後に来るトークンを正しく扱うために`nullable`が必要です。

#### FOLLOW集合

非終端記号の後に現れうるトークンの集合を**FOLLOW集合**と呼びます。これは、**nullable**な非終端記号（空文字列規則を持つ非終端記号）を扱うために特に重要です。

例えば、以下の文法を考えてみます：

```
A -> $ a B C $
B -> b | ε
C -> c C | ε
```

この場合、`FOLLOW`集合は次のようになります：

```
FOLLOW(A) = { $ }     // Aは開始記号
FOLLOW(B) = { c, $ }  // Bの後にはcまたは入力の終端が来る
FOLLOW(C) = { $ }     // Cの後には入力の終端が来る
```

### FIRST集合、FOLLOW集合、nullableの計算方法

これらの集合を実際に計算する方法を見ていきましょう。

#### nullableの計算アルゴリズム

1. すべての非終端記号について`nullable = false`に初期化
2. `A -> ε`の形の規則があれば`nullable(A) = true`
3. `A -> X₁ X₂ ... Xₖ`について、すべての`Xᵢ`がnullableなら`nullable(A) = true`
4. `false` -> `true`への変化がなくなるまで繰り返す

例：

```
E → T E'
E' → + T E' | ε
T → F T'
T' → * F T' | ε
F → ( E ) | id
```

計算過程：

- 初期化：すべて`false`
- `E' → ε`があるので`nullable(E') = true`
- `T' → ε`があるので`nullable(T') = true`
- 他の非終端記号はε規則を持たず、右辺もnullableでないので`false`のまま

結果：

- `nullable(E) = false`
- `nullable(E') = true`
- `nullable(T) = false`
- `nullable(T') = true`
- `nullable(F) = false`

#### FIRST集合の計算アルゴリズム

各規則 `A → α` について次の手順で計算します：

1. `α = X1 X2 ... Xn` とする
2. `X1`が終端記号なら、`FIRST(A)`に`X1`を追加
3. `X1`が非終端記号なら：
   - `FIRST(X1) - {ε}`を`FIRST(A)`に追加
   - `X1`が**nullable**なら`X2`も確認（以下同様）
4. すべての`X1`が**nullable**なら、`ε`を`FIRST(A)`に追加

例の文法での計算は以下のようになります：

1. `F → ( E ) | id`
    - `FIRST(F) = { '(', id }`（両方の規則の最初の終端記号）

2. `T → F T'`
    - `FIRST(T) = FIRST(F) = { '(', id }`（`F`は非終端記号なので`FIRST(F)`を使用）

3. `E → T E'`
    - `FIRST(E) = FIRST(T) = { '(', id }`

4. `E' → + T E' | ε`
    - `FIRST(E') = { '+', ε }`（最初の規則から`+`、2番目の規則から`ε`）

5. `T' → * F T' | ε`
    - `FIRST(T') = { '*', ε }`

#### FOLLOW集合の計算アルゴリズム

1. すべての非終端記号の`FOLLOW`を空集合に初期化
2. 開始記号`S`に対して`FOLLOW(S) = {$}`（入力終端）
3. 規則`B → αAβ`に対して：
    - `FIRST(β) - {ε}`を`FOLLOW(A)`に追加
    - `β`がnullableなら`FOLLOW(B)`を`FOLLOW(A)`に追加
4. 規則`B → αA`（末尾に`A`）に対して：
    - `FOLLOW(B)`を`FOLLOW(A)`に追加
5. 変化がなくなるまで繰り返す

例の文法での計算は以下のようになります：

1. 初期状態：
    - `FOLLOW(E) = {$}`（開始記号として）

2. 規則`F → ( E )`から：

    - `E`の後に`)`が来るので、`FOLLOW(E) = {$, ')'}`

3. 規則`E → T E'`から：

    - `T`の後に`E'`が来る。`FIRST(E') = {'+', ε}`
    - `E'`が**nullable**なので、`FOLLOW(E)`も`FOLLOW(T)`に追加
    - `FOLLOW(T) = {'+', $, ')'}`

4. 規則`E → T E'`から：
    - `E'`は末尾なので、`FOLLOW(E')`に`FOLLOW(E)`を追加
    - `FOLLOW(E') = {$, ')'}`

同様に計算を続けると以下のようになります：

- `FOLLOW(E) = {$, ')'}`
- `FOLLOW(E') = {$, ')'}`
- `FOLLOW(T) = {'+', $, ')'}`
- `FOLLOW(T') = {'+', $, ')'}`
- `FOLLOW(F) = {'*', '+', $, ')'}`

### LL(1)構文解析とFIRST集合・FOLLOW集合の関係

6章ででてくる構文解析器生成系では、FIRST集合とFOLLOW集合を使って、LL(1)構文解析表を作成します。これは「非終端記号」と「先読みトークン」の組み合わせから、適用すべき規則を決定する表です。ただし、手書きでLL(1)構文解析器を実装する場合は、表を明示的に作成せず、FIRST集合とFOLLOW集合に相当するものを手で（あるいは頭の中で）作って、適用すべき規則を決定します。

たとえば、以下のような文法があったとします：

```
A → α
A → β
```

このとき、FIRST集合とFOLLOW集合を使って、どちらの規則を適用するかを決定します：

- もし`FIRST(α)`と`FIRST(β)`に共通の要素がなければ、先読みトークンを見てどちらの規則を適用するか判断できます
    - このとき、共通の要素があればそれは衝突が発生しており、LL(1)構文解析は不可能です
- もし`α`または`β`がnullable（空文字列を生成可能）な場合は、FOLLOW集合も考慮する必要があります

次に、FOLLOW集合が必要になる具体例を見ていきましょう。以下の文法を考えます：

```
S → A B
A → a | ε    （Aは空文字列も生成可能）
B → b
```

`A`を解析する際、先読みトークンが`a`なら`A → a`を適用しますが、`b`の場合はどうでしょうか？

- `FIRST(A) = {a}` （εは含まない）
- `nullable(A) = true` （A → εがあるため）
- `FOLLOW(A) = {b}` （Aの後にBが来て、FIRST(B) = {b}）

先読みトークンが`b`の場合：

- `b ∉ FIRST(A)`なので、通常なら`A → a`は適用できない
- しかし`nullable(A) = true`かつ`b ∈ FOLLOW(A)`なので、`A → ε`を適用すべき

つまり、LL(1)構文解析では以下のような戦略をとります：

- 先読みトークンが`FIRST(α)`に含まれる → `A → α`を適用
- `nullable(α) = true`かつ先読みトークンが`FOLLOW(A)`に含まれる → `A → α`を適用（αは空文字列を生成）

FOLLOW集合を適用する場合でも先程と同じように衝突が発生する可能性があります。例えば、以下のような文法を考えてみましょう：

```
S → A B | C D
A → a | ε
C → c | ε  
B → b
D → b
```

この文法では`FIRST`と`FOLLOW`は次のようになります：

- `FIRST(A) = {a}`, `nullable(A) = true`
- `FIRST(C) = {c}`, `nullable(C) = true`
- `FOLLOW(A) = {b}` （Aの後にBが来る）
- `FOLLOW(C) = {b}` （Cの後にDが来る）

ここで、先読みトークンが`b`の場合、次のような問題が発生します：

- `S → A B`を選ぶなら、`A → ε`を適用して`B → b`に進む
- `S → C D`を選ぶなら、`C → ε`を適用して`D → b`に進む

どちらの場合も`b ∈ FOLLOW(A)`かつ`b ∈ FOLLOW(C)`なので、Sの段階でどちらの規則を選ぶべきか判断できません。この場合は、文法がLL(1)ではない、つまりLL(1)での解析が不可能であることを示しています。

構文解析表を明示的に作らなくても、FIRST集合とFOLLOW集合の概念を理解していれば、直感的にLL(1)パーサを実装できるのです。

### LL(1)の問題点と限界

LL(1)はシンプルで実用的ですが、いくつかの限界があります。

1. 共通前置辞問題

LL(1)では、同じ非終端記号から始まる複数の規則がある場合、先読みトークンだけではどの規則を適用すべきか判断できません。

```
S -> a B
S -> a C
```

両方の規則が`a`で始まるため、1文字先読みでは判断できません。この問題は**左因子化**（Left Factoring）で解決できます：

```
S  -> a S'
S' -> B
S' -> C
```

左因子化は直観的には、共通の前置きを抽出して新しい非終端記号を導入することで、先読みトークンだけで規則を一意に決定できるようにする変換操作です。

2. 左再帰の問題

LL(1)の最大の欠点は、**左再帰**を扱えないことです。

```
E -> E + T
E -> T
```

この問題は**左再帰の除去**で解決できます：

```
E  -> T E'
E' -> + T E'
E' -> ε
```

しかし、この変換により文法の直感性が失われ、抽象構文木の構築も複雑になります。

ここまでで下向き構文解析の基本的な考え方とLL(1)について学びました。次は、より効率的な上向き構文解析の代表格である**LR構文解析**を見ていきましょう。

## LR構文解析 - 素朴なシフト還元の効率化

最初に見た素朴なシフト還元構文解析には、大きな問題がありました：

1. **いつシフトして、いつ還元するか？** - 毎回スタック全体を調べる必要がある
2. **どの規則で還元するか？** - すべての規則を順番に試す必要がある

これらの判断を効率的に行うのが**LR構文解析**です。

### 素朴な方法の問題点

先ほどの`DyckShiftReduce`の実装を思い出してください：

```java
private boolean tryReduce() {
    for (Rule rule : rules) {  // すべての規則を試す！
        if (rule.matches(stack)) {  // スタック全体をチェック！
            // 還元処理
        }
    }
    return false;
}
```

入力が長くなると、この方法は非効率的です。LR構文解析は、この問題を**オートマトン**で解決します。

### LR構文解析のアイデア

素朴なシフト還元構文解析の問題点は、毎回スタック全体を見て、どの規則が適用できるかを総当たりで確認する必要があることでした。しかし、ここで重要な観察があります：

**スタックの「状態」は有限個に分類できる**

第4章で学んだ有限オートマトンを思い出してください。有限オートマトンは、有限個の状態と状態間の遷移で表現される計算モデルでした。LR構文解析の革新的なアイデアは、シフト還元構文解析の過程を有限オートマトンとして表現できることです。

具体的には：

1. スタックに積まれた記号列の「パターン」を状態として管理
2. シフトや還元の操作を状態遷移として表現
3. 各状態で「次に何をすべきか」を事前に計算して表に保存

これにより、構文解析時は単に「現在の状態」と「次の入力」から表を引くだけで、次の動作（シフトか還元か）が決定できるようになります。これが**LR構文解析表**と呼ばれるものです。

### LR(0)項 - 解析の進行状況を表す

LR構文解析の中核となる概念が**LR(0)項**です。これは、構文解析の進行状況を表現する方法です。

文法規則の中にドット（・）を挿入して、「どこまで認識したか」を表します：

```
A → ・α β    （まだ何も認識していない）
A → α・β     （αまで認識した）
A → α β・    （すべて認識した = 還元可能）
```

例えば、規則 `E → T + E` に対するLR(0)項目は：

- `E → ・T + E`：まだ何も認識していない
- `E → T・+ E`：Tまで認識した
- `E → T +・E`：T + まで認識した
- `E → T + E・`：すべて認識した（還元可能）

の5つとなります。

### LR(0)項集合 - 同じ「状況」をまとめる

ここで重要な概念が**LR(0)項集合**です。構文解析の過程で、複数のLR(0)項が同時に「有効」になることがあります。これらをまとめて1つの「状態」として扱います。

例えば、以下のような状況を考えてみましょう：

```
現在の状態 = {
    E → T・+ E    （Tを認識済み、次は+を期待）
    E → T・       （Tを認識済み、ここで還元も可能）
}
```

この状態では、2つの可能性が同時に存在しています：

1. 次に`+`が来れば、最初の規則に従って解析を続ける
2. ここで`E → T`として還元することもできる

LR(0)項集合は、このような「同じ状況で有効な項目の集まり」を表現します。オートマトンの各状態は、実はLR(0)項の集合なのです。

なぜ集合として扱うのでしょうか？それは、構文解析の過程で複数の可能性を同時に追跡する必要があるからです。例えば、`if`文の解析中に、`else`節があるかないかの両方の可能性を考慮する必要があるような場合です。

### 閉包 - 項目の展開

LR(0)項集合を構築する上で最も重要なのが、LR(0)項の**閉包**（Closure）です。これは、あるLR(0)項から「論理的に導かれる全ての項目」を表す概念です。

例えば、項目 `S → ・E $` があるとします。これは「これからEを認識したい」という状況を表しています。しかし、Eを認識するためには、Eから始まる規則も考慮する必要があります。このために閉包を求めます。

```
S → ・E $     （これからEを認識したい）
↓
Eを認識するには、Eから始まる規則も必要：
E → ・T
E → ・E + T
```

さらに、Tを認識するためには：

```
T → ・id
```

このように、ドットの直後に非終端記号がある場合、その非終端記号から始まる全ての規則を追加していく必要があります。

#### LR(0)項の閉包を求めるアルゴリズム

```
closure(I) {
    J = I
    repeat {
        for (各項目 A → α・Bβ in J) {
            for (各規則 B → γ) {
                J = J ∪ {B → ・γ}
            }
        }
    } until Jに変化がなくなる
    return J
}
```

### 拡張開始記号の必要性

LR構文解析では、文法に**拡張開始記号**（augmented start symbol）を追加するのが一般的です。元の開始記号がSだとすると、新しい開始記号S'を追加し、規則 `S' → S $` を追加します。

なぜこれが必要なのでしょうか？主な理由は以下の通りです：

1. **受理状態の明確化**：構文解析が「いつ終了するか」を明確にするため
2. **還元の一意性**：開始記号への還元を他の還元と区別するため
3. **実装の簡潔性**：特別な終了処理を不要にするため

例えば、以下の文法を考えてみましょう：

```
E → T
E → E + T
T → id
```

この文法で入力 `id` を解析する場合、`T → id` で還元した後、`E → T` で還元してEになりますが、「ここで解析終了」という明確な信号がありません。

拡張開始記号を追加すると、以下のようになります：

```
S' → E $
E → T
E → E + T
T → id
```

`S' → E $・` という項目に到達したときに「入力を全て消費し、開始記号に還元できた」ことが明確になります。

### 閉包からオートマトンへ

閉包を理解したところで、これをどのようにオートマトン構築に活用するかを見ていきましょう。

LR(0)オートマトンは以下の要素から構成されます：

1. 状態： LR(0)項集合（閉包を取った後の項目の集合）
2. 遷移： ある状態から記号を読んで次の状態へ移る関係
3. 初期状態： 拡張開始記号から始まる項目の閉包
4. 受理状態： `S' → E $・` を含む状態

構築の基本的な流れは次のようになります：

1. 初期項目 `S' → ・E $` から始める
2. その閉包を計算して初期状態とする
3. 各状態から可能な遷移を計算
4. 新しい状態が生まれたら、その閉包を計算
5. 新しい状態が生まれなくなるまで繰り返す

このプロセスはグラフの幅優先探索に似ています。各ノード（状態）から到達可能な全てのノードを探索していくのです。

以下の文法に対してLR(0)オートマトンを構築してみましょう：

```
S' → E $     （拡張開始記号）
E → T
E → E + T
T → id
```

### ステップ1：初期状態（I0）の作成

初期状態は、拡張開始記号から始まる項目のクロージャです：

```
I0 = closure({S' → ・E $})
```

クロージャを計算すると：

1. `S' → ・E $` がある
2. ドットの後にEがあるので、Eから始まる規則を追加：
  - `E → ・T`
  - `E → ・E + T`
3. `E → ・T` のドットの後にTがあるので、Tから始まる規則を追加：
  - `T → ・id`

結果：

```
I0 = {
    S' → ・E $
    E → ・T
    E → ・E + T
    T → ・id
}
```

### ステップ2：GOTO関数による遷移の計算

GOTO関数は、ある状態から記号を読んだときの次の状態を計算します：

```
GOTO(I, X) = closure({A → αX・β | A → α・Xβ ∈ I})
```

I0からの各遷移を計算してみましょう：

GOTO(I0, E) = I0でドットの後にEがある項目に対して状態I1を求める：

1. `S' → ・E $` のドットの後にEがあるので、`S' → E・$` を得る
2. `E → ・E + T` のドットの後にEがあるので、`E → E・+ T` を得る
3. 上記の項目集合の閉包をとって状態I1を得る：

```
I1 = closure({S' → E・$, E → E・+ T})
   = {
       S' → E・$
       E → E・+ T
   }
```

GOTO(I0, T) = I0でドットの後にTがある項目に対して状態I2を求める：

1. `E → ・T` のドットの後にTがあるので、`E → T・` を得る
2. 上記の項目集合の閉包をとって状態I2を得る：

```
I2 = closure({E → T・})
   = {E → T・}
```

GOTO(I0, id) = I0でドットの後にidがある項目に対して状態I3を求める：

1. `T → ・id` のドットの後にidがあるので、`T → id・` を得る
2. 上記の項目集合の閉包をとって状態I3を得る：

```
I3 = closure({T → id・})
   = {T → id・}
```

### ステップ3：全ての状態を探索

I1からの遷移：

GOTO(I1, $) = I1でドットの後に$がある項目に対して状態I4を求める：

1. `S' → E・$` のドットの後に$があるので、`S' → E $・` を得る
2. これは受理状態なので、I4は受理状態として定義

```
I4 = {S' → E $・}  （受理状態）
```

GOTO(I1, +) = I1でドットの後に+がある項目に対して状態I5を求める：

1. `E → E・+ T` のドットの後に+があるので、`E → E +・T` を得る
2. `T`から始まる規則も追加するため、`T → ・id` を得る
3. 上記の項目集合の閉包をとって状態I5を得る：

```
I5 = closure({E → E +・T, T → ・id})
   = {
       E → E +・T
       T → ・id
   }
```

I5からの遷移：

GOTO(I5, T) = I5でドットの後にTがある項目に対して状態I6を求める：

1. `E → E +・T` のドットの後にTがあるので、`E → E + T・` を得る
2. 上記の項目集合の閉包をとって状態I6を得る：

```
I6 = {E → E + T・}
```

GOTO(I5, id) = I5でドットの後にidがある項目に対して状態I3を求める：

1. `T → ・id` のドットの後にidがあるので、`T → id・` を得る
2. これは既存の状態I3と同じなので、新しい状態は作成しない
3. つまり、I3を再利用する

```
I3 = {T → id・}
```

### 完成したLR(0)オートマトン

状態：

- `I0: {S' → ・E $, E → ・T, E → ・E + T, T → ・id}`
- `I1: {S' → E・$, E → E・+ T}`
- `I2: {E → T・}`
- `I3: {T → id・}`
- `I4: {S' → E $・}`
- `I5: {E → E +・T, T → ・id}`
- `I6: {E → E + T・}`

遷移：

- `I0 --E--> I1`
- `I0 --T--> I2`
- `I0 --id--> I3`
- `I1 --$--> I4`
- `I1 --+--> I5`
- `I5 --T--> I6`
- `I5 --id--> I3`

### LR(0)構文解析表の構築

オートマトンから構文解析表を作成します。表には2種類の情報を記録します：

1. ACTION表：終端記号に対するアクション

  - `s n`：シフトして状態nへ遷移
  - `r n`：規則nで還元
  - `acc`：受理

2. GOTO表：非終端記号に対する遷移

### 構築規則

1. 項目 `A → α・aβ` が状態iにあり、GOTO(i, a) = j なら：
  - ACTION[i, a] = s j

2. 項目 `A → α・` が状態iにある（還元可能）なら：
  - 全ての終端記号に対してACTION[i, *] = r (A→α)

3. 項目 `S' → E $・` が状態iにあるなら：
  - ACTION[i, $] = acc

4. GOTO(i, A) = j なら：
  - GOTO[i, A] = j

#### 完成した解析表

| 状態 | ACTION |     |     | GOTO |     |
|------|--------|-----|-----|------|-----|
|      | id     | +   | $   | E    | T   |
| 0    | s3     |     |     | 1    | 2   |
| 1    |        | s5  | acc |      |     |
| 2    | r1     | r1  | r1  |      |     |
| 3    | r3     | r3  | r3  |      |     |
| 4    | acc    |     |     |      |     |
| 5    | s3     |     |     |      | 6   |
| 6    | r2     | r2  | r2  |      |     |

規則番号：

- 0: S' → E $
- 1: E → T
- 2: E → E + T
- 3: T → id

### LR(0)構文解析の実行

では、構築した構文解析表を使って、入力 `id + id $` を解析してみましょう：

- ステップ1：
  - スタック: [0]
  - 入力: id + id $
  - アクション: ACTION[0, id] = s3
  - 実行: idをシフトして状態3へ
- ステップ2：
  - スタック: [0, 3]
  - 入力: + id $
  - アクション: ACTION[3, +] = r3 (T → id)
  - 実行: T → id で還元
    - スタックから1つ削除: [0]
    - GOTO[0, T] = 2
    - 状態2をプッシュ: [0, 2]
- ステップ3：
  - スタック: [0, 2]
  - 入力: + id $
  - アクション: ACTION[2, +] = r1 (E → T)
  - 実行: E → T で還元
    - スタックから1つ削除: [0]
    - GOTO[0, E] = 1
    - 状態1をプッシュ: [0, 1]
- ステップ4：
  - スタック: [0, 1]
  - 入力: + id $
  - アクション: ACTION[1, +] = s5
  - 実行: +をシフトして状態5へ
- ステップ5：
  - スタック: [0, 1, 5]
  - 入力: id $
  - アクション: ACTION[5, id] = s3
  - 実行: idをシフトして状態3へ
- ステップ6：
  - スタック: [0, 1, 5, 3]
  - 入力: $
  - アクション: ACTION[3, $] = r3 (T → id)
  - 実行: T → id で還元
    - スタックから1つ削除: [0, 1, 5]
    - GOTO[5, T] = 6
    - 状態6をプッシュ: [0, 1, 5, 6]
- ステップ7：
  - スタック: [0, 1, 5, 6]
  - 入力: $
  - アクション: ACTION[6, $] = r2 (E → E + T)
  - 実行: E → E + T で還元
    - スタックから3つ削除: [0]
    - GOTO[0, E] = 1
    - 状態1をプッシュ: [0, 1]
- ステップ8：
  - スタック: [0, 1]
  - 入力: $
  - アクション: ACTION[1, $] = acc
  -実行: 受理！

このように、LR(0)構文解析は：

1. 現在の状態と入力記号から表を引く
2. シフトか還元かを決定
3. 還元の場合は、どの規則を使うかも一意に決まる

という単純な操作の繰り返しで、効率的に構文解析を実現します。

### LR(0)の限界：コンフリクト

LR(0)は効率的ですが、重要な限界があります。以下の算術式の文法を考えてみましょう：

```
E → E + T
E → T
T → id
```

この文法でLR(0)オートマトンを構築すると、ある状態で以下の項目を含むことになります：

```
状態X = {
    E → T・       （還元準備完了）
    E → E・+ T    （+を期待）
}
```

この状態で問題が発生します。何故なら：

- 入力が`+`なら → シフトして`+`を読むべき
- 入力が`$`（終端）なら → `E → T`で還元すべき

しかし、LR(0)は**次の入力を見ない**ので、どちらを選ぶか決められません。これを**シフト/還元コンフリクト**と呼びます。

### なぜコンフリクトが起きるのか

素朴なシフト還元では、実は暗黙的に「次の文字」を見ていました。しかし、LR(0)では「状態だけ」で判断しようとするため、情報が不足するのです。

## SLR(1)、LR(1)、LALR(1) - 先読みによる改良

LR(0)のコンフリクトを解決するため、**先読み**（次の入力を見る）を導入した手法が開発されました。

### SLR(1) - FOLLOW集合による改良

**SLR(1)**（Simple LR(1)）は、LL(1)で学んだFOLLOW集合の考え方を使います。

**基本アイデア：**

「ある非終端記号Aの後に来うる記号」が分かれば、還元すべきタイミングが分かる

先ほどのコンフリクトの例を考えてみましょう：

```
状態X = {
    E → T・       （還元準備完了）
    E → E・+ T    （+を期待）
}
```

この状態で、次の入力が`+`か`$`かによって、どのアクションを取るべきかが変わります。SLR(1)では、以下のように判断します：

- `FOLLOW(E) = {+, $}`（Eの後には+か$が来る）
- 次の入力が`+`なら：
  - シフト（`E → E・+ T`のため）
  - 還元も可能（`+` ∈ FOLLOW(E)）だが、シフトを優先
- 次の入力が`$`なら：
  - 還元のみ（`$` ∈ FOLLOW(E)）

これで多くのコンフリクトが解消されます。

#### SLR(1)構文解析表の構築

SLR(1)のアクション表の構築は、LR(0)と以下の点で異なります：

**LR(0)の還元ルール（問題あり）：**
- 項目 `A → α・` が状態iにあるなら、**全ての終端記号**に対して還元

**SLR(1)の還元ルール（改善版）：**
- 項目 `A → α・` が状態iにあるなら、**FOLLOW(A)内の終端記号**に対してのみ還元

つまり、「Aの後に来る可能性がある記号」の時だけ還元することで、不要な還元を防ぎます。

### SLR(1)で解決できるコンフリクトの例

先ほどの文法でSLR(1)がどのようにコンフリクトを解決するか見てみましょう：

```
S' → E $
E → E + T
E → T
T → id
```

LR(0)では状態2で以下のコンフリクトが発生していました：

```
状態2 = {E → T・}
```

LR(0)では、この状態で全ての終端記号（id, +, $）に対して `E → T` で還元しようとしました。しかし、これは過剰です。

SLR(1)では、FOLLOW(E)を計算します：

1. `S' → E $` より、Eの後に$が来る可能性がある
2. `E → E + T` より、Eの後に+が来る可能性がある

よって `FOLLOW(E) = {+, $}`

これにより、状態2では以下のようになります：

- `+`に対して：`E → T`で還元
- `$`に対して：`E → T`で還元
- `id`に対して：**何もしない**（エラー）

このように、SLR(1)は無駄な還元を防ぎ、より正確な構文解析表を構築できます。

### SLR(1)構文解析表の完成版

| 状態 | ACTION |     |     | GOTO |     |
|------|--------|-----|-----|------|-----|
|      | id     | +   | $   | E    | T   |
| 0    | s3     |     |     | 1    | 2   |
| 1    |        | s5  | acc |      |     |
| 2    |        | r1  | r1  |      |     |
| 3    |        | r3  | r3  |      |     |
| 4    | acc    |     |     |      |     |
| 5    | s3     |     |     |      | 6   |
| 6    |        | r2  | r2  |      |     |

LR(0)との違いは、状態2と状態3、状態6の`id`列が空欄（エラー）になっていることです。これにより、不適切な還元を防いでいます。

### SLR(1)の限界

SLR(1)は多くの実用的な文法を扱えますが、以下のような場合にはまだコンフリクトが残ります：

```
S → L = R | R
L → * R | id
R → L
```

この文法は「代入文」を表現しています（`*p = q`のような）。この文法では、ある状態で以下の項目が含まれます：

```
状態X = {
    R → L・      （Lで還元準備完了）
    S → L・= R   （=を期待）
}
```

`FOLLOW(R) = {=, $}`なので、入力が`=`の時に：

- シフト（`S → L・= R`のため）
- 還元（`R → L`、かつ`=` ∈ FOLLOW(R)のため）

両方が可能となり、SLR(1)でもコンフリクトが解決できません。このような場合には、より強力なLR(1)が必要になります。

### LR(1) - より精密な先読み

SLR(1)でも解決できないコンフリクトがあります。**LR(1)**は、各項目に「その項目に到達した文脈での先読み記号」を付加します：

```
[E → T・, +]    （この還元の後には+が来る）
[E → T・, $]    （この還元の後には$が来る）
```

同じ`E → T・`でも、文脈によって異なる先読み記号を持つことで、より精密な判断が可能になります。

### LR(1)項目の構造

LR(1)項目は、LR(0)項目に**先読み記号**（lookahead symbol）を追加したものです：

```
[A → α・β, a]
```

ここで、`a`は先読み記号で、「この項目で還元した後に期待される記号」を表します。

例えば：
- `[E → T・, +]`：Tを認識済み、還元後に+が来ることを期待
- `[E → T・, $]`：Tを認識済み、還元後に入力終端が来ることを期待

同じ`E → T・`でも、文脈によって異なる先読み記号を持つため、より精密な判断が可能です。

### LR(1)閉包の計算

LR(1)の閉包計算は、先読み記号の伝播を考慮する必要があります：

```
closure(I) {
    J = I
    repeat {
        for (各項目 [A → α・Bβ, a] in J) {
            for (各規則 B → γ) {
                for (FIRST(βa)内の各終端記号b) {
                    J = J ∪ {[B → ・γ, b]}
                }
            }
        }
    } until Jに変化がなくなる
    return J
}
```

重要なのは、`FIRST(βa)`の計算です：

- βが空でない場合：FIRST(β)を使う
- βが空またはnullableな場合：aも含める

### LR(1)の具体例

SLR(1)で問題となった代入文の文法で、LR(1)がどのように動作するか見てみましょう：

```
S' → S $
S → L = R | R
L → * R | id
R → L
```

#### 初期状態I0の構築

I0 = closure({[S' → ・S $, $]})

閉包を計算すると：

```
I0 = {
    [S' → ・S $, $]
    [S → ・L = R, $]
    [S → ・R, $]
    [L → ・* R, =]     // 注目：先読みは=
    [L → ・id, =]      // 注目：先読みは=
    [R → ・L, $]
    [L → ・* R, $]     // 注目：先読みは$
    [L → ・id, $]      // 注目：先読みは$
}
```

ここで重要なのは、同じ`L → ・* R`や`L → ・id`が、異なる先読み記号（=と$）を持って複数存在することです。

#### 問題となる状態の解析

`GOTO(I0, L)`を計算すると：

```
I2 = {
    [S → L・= R, $]    // =を期待
    [R → L・, $]       // $を期待（還元可能）
}
```

この状態で、次の入力が`=`の場合、以下のようになります：

- `[S → L・= R, $]`により、シフトする
- `[R → L・, $]`は、先読みが$なので還元しない

つまり、LR(1)では**コンフリクトが解決**されます！

### LR(1)とSLR(1)の違い

同じ状態をSLR(1)で見ると：

```
状態X = {
    S → L・= R
    R → L・
}
```

SLR(1)では`FOLLOW(R) = {=, $}`なので、`=`に対して還元も可能となり、コンフリクトが発生します。

LR(1)の優位性は以下の点です：

- 文脈を考慮：項目がどのような経路で到達したかを記憶
- 精密な先読み：FOLLOW集合ではなく、実際の文脈での先読み記号を使用
- より多くの文法を扱える：SLR(1)で発生するコンフリクトの多くを解決

### LR(1)の欠点

LR(1)は強力ですが、以下の重大な欠点があります：

1. **状態数の爆発**

- 同じコア（ドットの位置まで同じ項目）でも、先読み記号が異なれば別状態
- 実用的な文法では、状態数が数千～数万になることも

2. **構文解析表のサイズ**

- 状態数×記号数のテーブルが必要
- メモリ使用量が問題となる場合がある

3. **構築時間**

- 状態数が多いため、オートマトン構築に時間がかかる

例えば、プログラミング言語の文法では次のようになります：

- LR(0)：数百状態
- SLR(1)：数百状態（LR(0)と同じ）
- LR(1)：数千～数万状態
- LALR(1)：数百状態（後述）

この問題を解決するために開発されたのがLALR(1)です。

### LALR(1) - 実用的な妥協点

**LALR(1)**（Look-Ahead LR(1)）は、LR(1)の強力さとLR(0)のコンパクトさを両立させた「実用的な妥協点」です。

### LALR(1)の基本アイデア

LR(1)の問題は状態数の爆発でした。しかし、よく観察すると多くの状態が「ほぼ同じ」であることがわかります：

```
状態10: {
    [E → T・, +]
    [T → T・* F, +]
}

状態25: {
    [E → T・, $]
    [T → T・* F, $]
}
```

これらの状態は、先読み記号以外は全く同じです。このような状態の「コア」（先読み記号を除いた部分）は同一です：

```
コア: {
    E → T・
    T → T・* F
}
```

LALR(1)は、同じコアを持つLR(1)状態をマージすることで、状態数を削減します。

### LALR(1)状態のマージ

マージのプロセスを具体的に見てみましょう：

```
LR(1) 状態A: {
    [A → α・β, a]
    [B → γ・δ, b]
}

LR(1) 状態B: {
    [A → α・β, c]
    [B → γ・δ, d]
}
```

これをマージすると、以下のようになります：

```
LALR(1) 状態: {
    [A → α・β, a/c]
    [B → γ・δ, b/d]
}
```

先読み記号が和集合になることに注目してください。

### LALR(1)の構築方法

LALR(1)オートマトンの構築には主に2つの方法があります：

#### 方法1：LR(1)からの変換

1. 完全なLR(1)オートマトンを構築
2. 同じコアを持つ状態を識別
3. それらの状態をマージ（先読み記号は和集合）
4. 遷移関係を調整

この方法は概念的に分かりやすいですが、一時的に大きなLR(1)オートマトンを構築する必要があります。

#### 方法2：直接構築

1. LR(0)オートマトンを構築
2. 各状態に対して、効率的に先読み記号を計算
3. 先読み伝播グラフを使って先読み記号を伝播

実用的な構文解析器生成系（Yacc、Bison）は、効率的な方法2を採用しています。

### LALR(1)で新たに生じるコンフリクト

状態のマージにより、LR(1)では解決できていたコンフリクトが再発することがあります。以下の文法を考えてみましょう：

```
S' → S $
S → a A d | b B d | a B e | b A e
A → c
B → c
```

この文法は、前半の記号（aかb）と後半の記号（dかe）の組み合わせで、中間のAかBを決定する必要があります。

LR(1)では、以下のような状態が別々に存在します：

```
状態X: { [A → c・, d] }  // aで始まりdで終わる文脈
状態Y: { [A → c・, e] }  // bで始まりeで終わる文脈
状態Z: { [B → c・, d] }  // bで始まりdで終わる文脈
状態W: { [B → c・, e] }  // aで始まりeで終わる文脈
```

LALR(1)では、これらがマージされます：

```
マージ後の状態: {
    [A → c・, d/e]
    [B → c・, d/e]
}
```

この状態で、先読みがdまたはeの時、AとBのどちらで還元すべきか決定できません（reduce/reduceコンフリクト）。

### LALR(1)とLR(1)の実用的な比較

実際のプログラミング言語の文法での比較：

| 特性 | LR(1) | LALR(1) |
|------|-------|---------|
| 状態数 | 数千～数万 | 数百（LR(0)と同程度） |
| 構文解析表サイズ | 非常に大きい | 実用的なサイズ |
| 構築時間 | 遅い | 高速 |
| 解析能力 | 最も強力 | わずかに劣る |
| 実用性 | メモリ制約で困難 | 十分実用的 |

### なぜYaccはLALR(1)を選んだのか

1975年にStephen C. JohnsonがYaccを開発した際、LALR(1)を採用した理由は以下のようなものです：

1. **メモリ制約**：当時のコンピュータでは、LR(1)の巨大な解析表は非現実的
2. **十分な表現力**：ほとんどのプログラミング言語の文法はLALR(1)で記述可能
3. **効率的な実装**：DeRemerの効率的なアルゴリズムが利用可能

### LALR(1)の実用例

実際のプログラミング言語の構文解析ではLALR(1)が使われていることが多いです：

- **C言語**：元々Yaccで記述されたLALR(1)文法
- **Ruby**：Bisonを使用（LALR(1)）
- **PostgreSQL**：SQL文法をBisonで解析

### LALR(1)の限界を超えて

LALR(1)でもコンフリクトが解決できない場合には以下のような対処法があります：

1. **文法の書き換え**：多くの場合、等価な文法に変換可能
2. **GLR（Generalized LR）**：非決定的な解析を許容
3. **優先順位と結合性**：Yacc/Bisonの`%left`、`%right`、`%prec`
4. **意味的な処理**：構文解析後に意味解析で解決

ちなみに、GLRはBisonなどでサポートされていますが、実装が複雑になるため、一般的にはLALR(1)で十分な場合が多いです。

### まとめ：素朴な方法からの進化

1. **素朴なシフト還元**：毎回すべての規則をチェック
2. **LR(0)**：オートマトンで効率化、ただし先読みなし
3. **SLR(1)**：FOLLOW集合で簡単な先読み
4. **LR(1)**：文脈ごとの先読みで精密化
5. **LALR(1)**：実用的なバランス

この流れを理解することで、各手法の存在意義が明確になります。

## Parsing Expression Grammar(PEG) - 新しいアプローチ

2004年にBryan Fordが提案した**Parsing Expression Grammar（PEG）**は、全く違うアプローチを取ります。これまでの構文解析手法は大前提として、文脈自由文法を元にしていましたが、PEGは文脈自由文法に一見よく似た、それでいて異なる新たな形式文法です。異なる形式文法であるため、CFGと表現能力はことなります。

正確にいうと、PEG自体を構文解析アルゴリズムというのは多少不適切なのですが、PEG自体に標準的な操作的意味論（実行の方法くらいの意味）が定義されているため、ここではPEGを構文解析アルゴリズムとして扱います。

### PEGの基本アイデア

PEGの最大の特徴は以下の通りです：

1. 順序付き選択とバックトラック：`A / B`は「まずAを試し、失敗したらBを試す」
2. 字句解析が不要：文字列レベルで直接解析
3. いくつかの文脈依存言語を扱える： たとえば、`a^n b^n c^n`も扱える
4. 全てのLR(1)文法を表現可能
5. 非常に単純：アルゴリズムが非常に単純で、実装が容易

### 第3章で実装したPEG

思い出してください。第3章で最初に実装した`PegJsonParser`がまさにPEGの実装でした：

```java
public Ast.JsonArray parseArray() {
    int backup = cursor;
    try {
        // LBRACKET RBRACKET
        parseLBracket();
        parseRBracket();
        return new Ast.JsonArray(new ArrayList<>());
    } catch (ParseException e) {
        cursor = backup;  // バックトラック！
        // LBRACKET value {COMMA value} RBRACKET
        parseLBracket();
        // ... 省略 ...
    }
}
```

この「バックトラック」がPEGの核心です。LLにせよLRにせよ、構文解析は「一度決めたら戻れない」ので、バックトラックができません。しかし、PEGでは「失敗したら前の状態に戻って別の選択肢を試す」ことができます。LLやLRが非常に複雑なのはひとはえに「バックトラックができない」からでもあります。PEGはこのバックトラックを行うことで、非常にシンプルな構文解析を実現しています。

### PEGの形式的定義

PEGは以下の8つの構成要素から成り立ちます：

1. 空文字列： ε
2. 終端記号： t
3. 非終端記号： N
4. 連接： e1 e2（e1の後にe2）
5. 選択： e1 / e2（e1またはe2）
6. 0回以上の繰り返し： e*
7. 肯定述語： &e（eにマッチするが消費しない）
8. 否定述語： !e（eにマッチしないことを確認）

特に7番と8番は文脈自由文法にはない、PEG特有の機能です。

### PEGとCFGの違い

| 特徴 | CFG | PEG |
|------|-----|-----|
| 選択演算子 | `｜`（非決定的） | `/`（順序付き） |
| 曖昧性 | あり得る | 常に一意 |
| 字句解析 | 必須 | 不要 |
| 左再帰 | 問題なし（LR系） | 無限ループ |
| 表現力 | 文脈自由言語 | LR(k) + 一部の文脈依存言語 |

ちなみに、言語クラスとしてみたとき、明らかにPEG⊆CFGはなりたちません。それはCFGで表現できない`a^n b^n c^n`のような言語をPEGは表現できるからです。一方、CFG⊆PEGが成り立つかは不明（open problem）ですが、こちらも成り立たないと予想されています。何故かと言うと、以下のような明らかに不自然な状態があるからです。

- 回文を表現できない可能性が高い： `A → aAa | bAb | ε` のような文法に相当する文法をPEGで記述すると、PEGでは2の累乗 - 2の長さの回文という非常に不自然な表現になります。さらに、現状、PEGでは回文を表現するための文法が発見されていません。
- 線形時間で解析が可能： PEGは後述するPackrat Parsingにより、線形時間で解析が可能です。CFGでは線形時間の解析は知られていません。

## Packrat Parsing - PEGの線形時間化

PEGの最大の弱点は、バックトラックにより最悪の場合に指数関数時間がかかることです。**Packrat Parsing**は、メモ化（memoization）を使ってこの問題を解決します。

### メモ化とは？

メモ化（memoization）は、「同じ引数で関数を呼んだら、同じ結果が返る」ことを利用して、一度計算した結果をキャッシュする技法です。

「メモ化」という名前は「memoize」（記憶する）から来ています。「メモリ化」ではなく「メモ化」であることに注意してください。

### フィボナッチ数で学ぶメモ化

フィボナッチ数の素朴な実装を考えてみます：

```java
public static long fib(long n) {
    if(n == 0) return 0L;
    if(n == 1) return 1L;
    else return fib(n - 1) + fib(n - 2); 
}
```

この実装の問題点は、同じ値を何度も計算してしまうことです。メモ化を適用すると次のようになります：

```java
private static Map<Long, Long> cache = new HashMap<>();

public static long fib(long n) {
    Long value = cache.get(n);
    if(value != null) return value;

    long result;
    if(n == 0) {
        result = 0L;
    } else if (n == 1) {
        result = 1L;
    } else {
        result = fib(n - 1) + fib(n - 2);
    }
    cache.put(n, result);
    return result;
}
```

メモ化の効果はこのようなケースで絶大です。具体的には：

- 時間計算量：`O(2^n)` → `O(n)`
- 空間計算量：`O(1)` → `O(n)`

メモ化により、同じ計算を何度も行わず、結果をキャッシュすることで大幅に計算量を削減できます。

### PEGパーサのメモ化

PEGパーサにもメモ化を適用できます。単に全ての規則に対してメモ化を行ったものを**Packrat Parsing**と呼びます。Packrat Parsingでは、各規則のパース結果をキャッシュし、同じ位置で同じ規則を再度パースする際にキャッシュを利用します。このようにすることで、PEGのバックトラックによる指数関数的な計算量を線形時間に抑えることができます。

Packrat Parsingの基本的な実装は以下のようになります：

```java
public class PackratParser {
    private Map<Integer, Map<String, MemoEntry>> memo;
    
    static class MemoEntry {
        boolean success;
        int endPos;
    }
    
    private boolean memoized(String ruleName, Supplier<Boolean> parser) {
        // メモ化テーブルをチェック
        Map<String, MemoEntry> posCache = memo.get(pos);
        if (posCache != null) {
            MemoEntry entry = posCache.get(ruleName);
            if (entry != null) {
                // キャッシュヒット！
                pos = entry.endPos;
                return entry.success;
            }
        }
        
        // キャッシュミス：実際にパース
        int startPos = pos;
        boolean success = parser.get();
        int endPos = pos;
        
        // 結果をキャッシュに保存
        // ... 省略 ...
        
        return success;
    }
}
```

ここでのポイントは`memo`というマップを使って、各位置（`pos`）と規則名（`ruleName`）に対するパース結果をキャッシュすることです。これにより、同じ位置で同じ規則を再度パースする際に、キャッシュを利用して高速化できます。

### Packrat Parsingの特徴

利点：

- 線形時間：`O(n)`（`n`は入力長）
- 左再帰対応：工夫により可能
- 実装が単純（単なるメモ化）

欠点：

- メモリ使用量：`O(n×m)`（`m`は文法規則数）
- キャッシュミスのオーバーヘッド
- 並列化が困難

Packrat Parsingは、PEGのバックトラックによる指数関数的な計算量を線形時間に抑えるための強力な手法です。しかし、理論上は線形時間であるものの、その代償としてメモリ使用量が大きくなるため、注意が必要です。

## 構文解析アルゴリズムの計算量と表現力

各アルゴリズムの計算量をまとめると：

| アルゴリズム | 時間計算量 | 空間計算量 | 備考 |
|-------------|-----------|-----------|------|
| LL(1) | O(n) | O(\|N\| × \|T\|) | \|N\|:非終端記号数, \|T\|:終端記号数 |
| LL(k) | O(n) | O(\|N\| × \|T\|^k) | kが大きくなると表サイズが指数的に増大 |
| SLR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数はLR(0)と同じ |
| LR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数が多い |
| LALR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数はLR(0)と同程度 |
| PEG | O(2^n) (最悪) | O(n) | バックトラック用スタック |
| Packrat | O(n) | O(n × \|P\|) | \|P\|: 規則数 |

この表の「O表記」は、アルゴリズムの計算量を表す記法で、`O(n)`は「入力の長さに比例した時間」、`O(n^2)`は「入力の長さの2乗に比例した時間」を意味します。

注目すべきは、PEGを除くすべての手法が線形時間で解析できることです。また、Packrat Parsingを使えばPEGも線形時間になります。

## まとめ

この章では、文脈自由文法を実際に解析するための様々なアルゴリズムを学びました。

### 学んだアルゴリズムの整理

**下向き構文解析（トップダウン）**

- 予測的構文解析：Dyck言語を例に、スタックを使った実装
- LL(1)構文解析：FIRST集合とFOLLOW集合による効率化

**上向き構文解析（ボトムアップ）**

- シフト還元構文解析：葉から根に向かって構文木を構築
- LR(0)、SLR(1)、LR(1)、LALR(1)：段階的に強力になる手法

**その他の手法**

- PEG：順序付き選択による決定的な構文解析
- Packrat Parsing：メモ化によるPEGの線形時間化

これらについて知っていることは、以下のような実践的なスキルにつながります：

1. **構文解析器生成系の選択**：各ツールの特性を理解して選択できる
- 例：ANTLRはエラーリカバリーが優れているのでIDE向き
- Yacc/Bisonは高速だがエラーメッセージが分かりにくい

2. **エラーメッセージの理解**：コンフリクトの意味がわかる
- 「shift/reduce conflict」→ シフトと還元のどちらを選ぶか決まらない
- 「reduce/reduce conflict」→ 複数の還元規則から選べない

3. **DSLの設計**：パースしやすい文法設計ができる
- シンプルな設定ファイルならLL(1)で十分
- 複雑な表現が必要ならPEGやLALR(1)を検討

4. **パフォーマンスの理解**：適切な最適化を選択できる
- 大量のデータ処理なら線形時間が保証される手法を選ぶ
- IDEのリアルタイム解析ならインクリメンタル対応を考慮

構文解析は一見難しく感じるかもしれませんが、基本的なアイデアは「文字列を構造化する」というシンプルなものです。この章で学んだ各手法の特徴を理解しておけば、実際の開発で構文解析が必要になった時に、適切な選択ができるはずです。

次章では、ここで学んだアルゴリズムを実装したパーサジェネレータ（構文解析器生成系）について具体的に見ていきます。