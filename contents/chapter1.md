
# 第1章 構文解析の世界へようこそ

皆さん、はじめまして！この本は「構文解析」というテーマについて扱った、一風変わった本です。これまで「構文解析」については、コンパイラや言語処理系を扱った書籍の一部で触れられる程度でした。「Parsing Techniques」という英語の書籍があるものの、英語圏ですら広く知られているとは言い難いですし、内容も網羅的ではあるものの平易とは言えません。

私がはじめて「構文解析」の入口に立ったのは高校三年生のときでした。当時、私はプログラミング言語に興味を持ち始め、いつかは自分のプログラミング言語を作ってみたいと思っていました。しかし、高校の図書館にあった「プログラミング言語を作る」本を借りて読んでみたものの、とても難しく当時の私には理解できませんでしたし、コンパイラ開発者のバイブルともよばれる「ドラゴンブック」[^1]も同様でした。

何がきっかけかは覚えていないのですが、いきなり大きな言語を作ろうとしても難しいということでまずは括弧を含む算術式を計算できる「電卓」アプリを作ることにしました。非常に単純なもので

```sh
(1 + 2) * (3 + 4) 
```

のようにテキストフィールドに入力して「計算」ボタンを押すと`21`と表示される、ただそれだけの代物です。今振り返れば、この電卓アプリはごく初歩的な「構文解析」と「インタプリタ」を実装したものとも言えます。

ただし、当時の私は言語処理系を作る際に必須の知識がほとんどなく、抽象構文木も典型的な構文解析のアルゴリズムも知らず、足りない知恵を振り絞って括弧の対応や演算子の優先順位を自力で計算したのでした。それは本当に拙いものでしたが、それでもなんとか動くものを作ることができたのです。

それから二十年余り。筆者は現在、研究職ではないものの構文解析の手法の一つである、Parsing Expression Grammar（PEG）を専門として、時折関連する論文の査読を引き受けたりしています。

現在の私は研究に未練を残しつつちょっとアカデミアに関わりがある微妙な立場ですが、そんな中でも折に触れて思うことがありました。構文解析はなぜ、一般の技術書であまり取り上げられないのだろうか、ということです。

言語処理系を扱う書籍の一部として構文解析が取り上げられることは珍しくありません。しかし、その扱いはあくまで「おまけ」であって、言語を作る上での通過点としてしか位置づけられていません。これについては、言語の本質は構文解析の「後」にあるのであり、構文は本質ではないというのが大きいでしょう。筆者もこの点に異論はありません。ただ、構文（正確には具象構文）はほんとうに「おまけ」なのでしょうか。ときどき疑問に思います。

プログラミング言語に携わる研究者の間では、プログラミング言語の「意味」は抽象構文木に対して定められるものであり、構文は「ガワ」に過ぎないという考え方の人が多いように思いますし、その考えも間違ってはいないと思います。

しかし、現実に我々が読み書きするのはプログラムの抽象構文木ではなく、プログラムの文字列です。構文はUIであると言えます。多くのアプリケーションにおいてUIが果たす役割は非常に大きく、UI自体が専門分野として存在しているくらいです。そのUIたる構文とUIを適切な内部構造に変換する構文解析は軽視されていいのだろうか。筆者が構文解析の本を書こうと思い立ったのはそんな「こだわり」からでした。

本書の読者の皆さんには、構文解析の世界を少しでも楽しんでいただければと思います。構文解析は非常に奥深いテーマであり、その奥深さを一冊の本で完全に網羅することはできません。しかし、本書を通じて構文解析の基礎を学び、その面白さを感じていただければと思います。

## 構文解析の歴史的背景

構文解析の歴史は、コンピュータサイエンスの黎明期にまで遡ります。1950年代から1960年代にかけて、初期のコンパイラ開発者たちは、人間が書いたプログラムをコンピュータが理解できる形に変換する方法を模索していました。当時、プログラミング言語の文法を厳密に定義し、それを機械的に処理する方法は確立されていませんでした。

転機となったのは、言語学者ノーム・チョムスキーが1956年に発表した形式言語理論でした。チョムスキーは言語を4つの階層（チョムスキー階層）に分類し、その中で「文脈自由文法」（第4章で解説）がプログラミング言語の記述に適していることが明らかになりました。この理論的基盤により、構文解析は科学的なアプローチが可能な分野となったのです。

構文解析アルゴリズムの発展において重要な貢献をした人物たちがいます。1965年、Donald Knuth（ドナルド・クヌース）はLR法（第5章で解説）を発表しました。これは「Left-to-right, Rightmost derivation」の略で、効率的な構文解析を可能にする画期的なアルゴリズムでした。一方、LL法（Left-to-right, Leftmost derivation）（第5章で解説）は、1960年代後半にPhilip M. Lewis II（フィリップ・ルイス）とRichard E. Stearns（リチャード・スターンズ）によって体系化されました。LL法は再帰下降構文解析の理論的基礎を提供し、より単純で理解しやすい手法として普及しました。これらのアルゴリズムは、現在でも多くの構文解析器の基礎となっています。

初期のプログラミング言語の開発においても、構文解析は重要な役割を果たしました。John Backus（ジョン・バッカス）は1950年代にFORTRANの開発を主導し、Peter Naur（ピーター・ナウア）とともにBNF（Backus-Naur Form）（第2章で解説）という文法記述法を確立しました。BNFは、プログラミング言語の文法を形式的に記述するための標準的な記法となり、現在でも広く使われています。また、Grace Hopper（グレース・ホッパー）は初期のコンパイラ開発のパイオニアとして、人間が理解しやすい言語から機械語への変換技術の基礎を築きました。

1970年代に入ると、Stephen C. Johnson（スティーブン・ジョンソン）によってYacc（Yet Another Compiler Compiler）が開発され、Mike Lesk（マイク・レスク）とEric Schmidt（エリック・シュミット）によってLex（Lexical Analyzer Generator）が開発されました。これらのツールは、文法定義から自動的に構文解析器を生成することを可能にし、コンパイラ開発の民主化に大きく貢献しました。現在でも、これらのツールの思想は多くのパーサージェネレータに受け継がれています。

現代では、ANTLR（ANother Tool for Language Recognition）のような、より強力で使いやすいツールが登場し、構文解析はますます身近なものになっています。また、Parsing Expression Grammar（PEG）（第5章で解説）のような新しい形式文法も提案され、構文解析の世界は今なお進化を続けています。

## 構文解析とは何か

このテーマについては別の立場からの意見もあるかもしれませんが、筆者は構文解析を以下のように定義しています。

構文解析とは、入力された文字列が特定の文法に従っているかどうかを判断し、その構造を抽出するプロセスです。プログラミング言語においては、ソースコードを解析して文法に従っているかを真偽値で返したり、抽象構文木（AST: Abstract Syntax Tree）を生成することが一般的な目的です。抽象構文木については第2章の後半で詳しく説明します。

文法に従っているかを真偽値で返す場合、構文解析のためのメソッドはJavaでは以下のように表現できます。

```java
boolean parse(String input);
```

文法に従っているかを真偽値で返すだけではなく、構文解析の結果として抽象構文木を生成する場合、メソッドは以下のように表現できます。ここで、記述を簡便にするため、Java 17から正式導入されたsealed interfaceとJava 16から正式導入されたrecordを使っています。

```java
interface Tree {}
sealed interface ParseResult 
  permits ParseResult.Success, ParseResult.Failure {
  record Success(Tree ast) implements ParseResult {}
  record Failure(String errorMessage) implements ParseResult {}
}
ParseResult parse(String input);
```

インタフェース`Tree`は抽象構文木の基底クラスであり、`ParseResult`は構文解析の結果を表すクラスです。`ParseResult.Success`は構文解析が成功した場合の結果を表し、抽象構文木を含みます。一方、`ParseResult.Failure`は構文解析が失敗した場合の結果を表し、エラーメッセージを含みます。

構文解析によって得られる抽象構文木を処理することで、さまざまな操作が可能になります。例えば、抽象構文木を使ってコードの最適化や変換、静的解析、コード生成などを行うことができます。

皆さんが何かしらの言語（プログラミング言語に限りません。HTMLやMarkdown、JSONなども含みます）で書かれたテキストを扱っているとき、構文解析器は必ずどこかで動いています。例えば、JavaScriptのコードをブラウザで実行する際、ブラウザはまずJavaScriptのコードを構文解析し、抽象構文木を生成してから実行します。また、JSONを扱うAPIでは、JSON文字列を構文解析して抽象構文木に変換し、その後の処理に利用します。

## 構文解析の身近な応用例

構文解析は、皆さんが日常的に使っているツールの中で活躍しています。いくつか具体例を見てみましょう。

**IDEの機能**: Visual Studio CodeやIntelliJ IDEAなどの統合開発環境では、コードを書いている最中にリアルタイムで構文解析が行われています。コード補完（入力途中で候補を表示）、コードの構造表示やナビゲーション、エラーの即座の検出などは構文解析によって実現されています。

**リンターとフォーマッター**: コードの品質チェックや自動整形を行うツールが昨今一般的に使われています。たとえば、ESLintやPrettierなどがあります。これらも内部で構文解析を行っています。コードを抽象構文木に変換し、その構造を解析することで、潜在的な問題を検出したり、一貫したスタイルに整形できるのです。

**マークダウンパーサー**: ドキュメントを執筆する際に使われるMarkdownも、構文解析の対象です。`**太字**`や`*斜体*`、見出しやリストなどの記法を解釈し、HTMLに変換するためには、Markdownの文法に従った構文解析が必要です。

**設定ファイルの解析**: `.env`ファイルの環境変数、`.gitignore`のパターン、`package.json`の依存関係など、様々な設定ファイルも構文解析の対象です。

**データベースクエリ**: SQLクエリを実行する際、データベースエンジンはまずクエリを構文解析し、実行計画を立てます。`SELECT * FROM users WHERE age > 18`のようなクエリも、構文解析を経て初めて実行可能になります。

**正規表現エンジン**: 正規表現そのものも、実は小さな言語です。`/^[a-zA-Z0-9]+@[a-zA-Z0-9]+\.[a-zA-Z]+$/`のようなパターンを解釈するには、正規表現の文法に従った構文解析が必要です。

これらの例からわかるように、構文解析は特別な分野の技術ではなく、私たちの開発を支える基盤技術なのです。

## 構文解析の奥深さ

皆さんがもっとも身近に使っている言語の1つであるJavaScriptを例にとって、構文解析の奥深さについて説明してみます。

以下のJavaScriptプログラムを構文解析することにします。

```js
x = 1 +
  2
```
このコードは、JavaScriptエンジンによって `x = 1 + 2;` と解釈され、直観的には以下のような抽象構文木が結果として返ってくるのが正しいように思われます（抽象構文木の説明は、いったんおいておきます）。

```{=latex}
\begin{center}
\begin{tikzpicture}[
  level distance=1.5cm,
  sibling distance=2cm,
  every node/.style={circle,draw,minimum size=0.8cm},
  root/.style={fill=gray!50},
  internal/.style={fill=brown!50},
  leaf/.style={fill=green!30}
]
  \node[root] {=}
    child { node[leaf] {x} }
    child { node[internal] {+}
      child { node[leaf] {1} }
      child { node[leaf] {2} }
    };
\end{tikzpicture}
\end{center}
```


では、次のJavaScriptプログラムはどうでしょうか？

```js
x = 1
+ 2
```

おそらく多くの方は先ほどと同じ構文木になることを期待するのではないでしょうか。

しかし、実際にはJavaScriptの自動セミコロン挿入（ASI: Automatic Semicolon Insertion）というルールにより、`x = 1; +2;` と解釈され、結果として以下のような2つの文として扱われます。

```{=latex}
\begin{center}
\begin{tikzpicture}[
  level distance=1.5cm,
  sibling distance=3cm,
  every node/.style={circle,draw,minimum size=0.8cm},
  root/.style={fill=gray!50},
  internal/.style={fill=brown!50},
  leaf/.style={fill=green!30}
]
  \node[root] {;}
    child { node[internal] {=}
      child { node[leaf] {x} }
      child { node[leaf] {1} }
    }
    child { node[internal] {+}
      child[missing] {}
      child { node[leaf] {2} }
    };
\end{tikzpicture}
\end{center}
```

`+`の後で改行するか、あるいは`+`の前に改行するかという一見**ささいな違い**によって、構文解析の結果が変わってしまうのです。JavaScriptのASIは、特定のルールに基づいて行末にセミコロンが自動的に挿入される機能ですが、そのルールは時として直感に反する結果を生むことがあります。例えば、`return`文の直後で改行すると、

```js
return
a + b;
```

これはASIにより `return; a + b;` と解釈され、意図しない結果（`undefined`が返される）になることがあります。ASIの主なルールには、「行終端文字の後に続くトークンが、現在の文法的文脈で許されない場合、行終端文字の位置にセミコロンを挿入する」といったものがありますが、例外も存在します。このような複雑さが、構文解析器の実装を難しくする一因となります。ASIによる予期せぬ挙動を避けるために、行頭にセミコロンを記述するスタイルや、式の途中では改行しないといったコーディング規約を採用する開発者もいます。

2000年以降に登場して普及した言語は、このような特徴を持っていることが多いです。たとえば、Go、Swift、Kotlin、Scalaの文法はこのような特徴を持っています。より古い言語であるRubyやPythonも同じ特徴を持っています。このように、ちょっとした違いで構文解析結果が変わってしまう例は珍しくありません。

このような文法の進化の背景には、プログラマにとって「書きやすく読みやすい」文法を提供するという意図があります。このような「改行に敏感な」文法があると、構文解析器装が複雑になりがちです。プログラミング言語の設計者にとっては考慮すべき点が増えるので、このような文法を嫌う言語設計者もいますが、利用者にとってはセミコロンの入力を省略できるなどの利便性があるため、広く採用されています。

しかし「構文解析が複雑になる」というのは一体どういうことでしょうか。ほとんどの方はピンとこないのではないでしょうか。この本では、このような問いに対して一定の答えを提示することを目指します。「構文解析の複雑さ」と一言で言っても、その要因は様々です。例えば、文法が曖昧であるか（一つの文に対して複数の解釈が可能か）、解析にバックトラック（試行錯誤）が必要か、どれだけの先読みトークン（入力の一部を先に見る数）が必要か、といった要素が複雑さに関わってきます。

本書では、これらの概念に触れながら、構文解析の奥深さを探求していきます。これらの複雑さを理解する上で重要な役割を果たすのが、「文脈自由文法」という考え方です。文脈自由文法とは、簡単に言えば、プログラムの構造を定義するための一連の書き換え規則のことです。例えば、「数値は式である」や「式は、式と演算子と式からなる」といったルールを形式的に記述するものです。詳細については第4章で詳しく解説しますが、この文脈自由文法という道具立てがあることで、構文解析の様々な側面を体系的に議論できるようになります。

読者の皆さんは既存の言語に歯がゆさを感じたことはないでしょうか。たとえば、昨今はJSONやYAMLを使って領域特化言語（DSL:Domain Specific Language）を提供することが一般的になっています。Amazon Web Services（AWS）のCloudFormationやGoogle Cloud Platform（GCP）のDeployment Managerなどがその例です。これらのDSLは、JSONやYAMLという既存のデータ形式を利用して、特定のドメインに特化した言語を提供しています。

しかし、これらのDSLはJSONやYAMLの枠に収めるために無理をしており、どうしても「不自然」な文法になってしまいます。JSONやYAMLは世界中に普及していますから、JSONやYAMLを使ったDSLを提供する合理性はあるもの、場合によってはJSONやYAMLに縛られないDSLの文法を考案することが求められることもあります。そのためには構文解析の知識が必要です。

構文解析は単に実用的であるにとどまらず非常に「楽しい」テーマです。読者の皆さんには本書を通じて、是非「構文解析の面白さ」を感じていただければと思います。

本書は次のような構成になっています。

第2章では簡単な算術式を例題にして、構文解析とはどういう処理かを体感してもらいます。定義を天下り式に提示するような本もありますが、構文解析については「まずは書いてみる」のが手っ取り早いというのが筆者の持論です。

第3章ではJSONの構文解析器を書いてもらいます。JSONは世界中で使われている非常に実用的なデータ形式（言語）でありながら、非常にシンプルです。そのシンプルなJSONを通して、実用的な言語の構文解析の基礎を学んでいただければと思います。

第4章では文脈自由文法（や言語）について解説します。文脈自由文法やそれに関する理論は構文解析の基礎になっています。括弧の対応を表現する言語を`Dyck`言語と言いますが、`Dyck`言語は文脈自由言語を特徴づけるものです。この章を理解することで文脈自由文法の直観的な理解が得られます。現代の構文解析は文脈自由文法を基盤としていますから、文脈自由言語の概念を理解することは非常に重要です。

第5章では現在の構文解析で広く採用されているアルゴリズムのうち、主だったものを解説します。特にLL(1)やLR(1)といったアルゴリズムについてできるだけ平易にかつ詳しく説明します。また、PEGやPackrat Parsingという比較的新しい構文解析アルゴリズムについても詳しく説明します。

第6章では構文解析器生成系について解説します。Yaccのような古典的なものに留まらず、ALL(*)アルゴリズムを基盤にしたANTLRやPEGを基盤にしたパーサーコンビネータなど、最新の構文解析器生成系について説明します。さらに、第6章では簡単なパーサーコンビネータを自作します。パーサーコンビネータは元々は関数型プログラミング言語から出てきたテクニックですが昨今では色々な言語でパーサーコンビネータライブラリがあります。パーサーコンビネータを自作する体験を通じて「文の定義から構文解析器を生成する」とはどういうことか理解してもらえるのではないかと思います。

第7章では従来の言語処理系についての本が取り扱わなかった「現実の構文解析」の話をします。従来の書籍に書かれている構文解析の世界はとても「綺麗」なものです。しかし、RubyでもPythonでもあるいはJavaScriptでも良いですが、現実の構文解析は必ずしもそこまで綺麗にはいかないものです。この章を通して現実の言語における構文解析はとても泥臭いものであること、その泥臭さを通して「書きやすく読みやすい」文法が実現されていることを実感してもらえるのではないかと思います。

第8章は締めくくりとしてこれまでの章を振り返りつつ、今後、みなさんが構文解析を学ぶにあたって参考になりそうな文献や資料について紹介します。この本は構文解析のみを取り扱った珍しい本ですが、それでも構文解析の世界は広く、本書で取り扱わなかったテーマも多々あります。この章を読んで、構文解析の世界により深く興味を持っていただければ幸いです。

## 本書で扱うプログラミング言語とツール

本書では、構文解析を学ぶために、以下のプログラミング言語とツールを使用します。

**Java**: 本書の主要な実装言語としてJavaを選びました。Javaは静的型付けであり、抽象構文木のような複雑なデータ構造を表現するのにも不足はありません。本書ではJava 21を基準に解説します（2025年6月時点）。なお、次期LTSであるJava 25（2025年9月予定）でも記述の大筋は変わりません。

**パーサージェネレータ**: 第6章では以下のツールを扱います：
- ANTLR4：現代的で強力なパーサージェネレータ
- JavaCC：Java専用の伝統的なパーサージェネレータ
- Yacc/Lex：C言語用の古典的ツール（歴史的理解のため）

**開発環境**: 特定のIDEは必須ではありませんが、IntelliJ IDEA Community EditionやEclipseを推奨します。これらのIDEは、Javaの開発に適しており、構文解析器の実装やテストを効率的に行うことができます。Visual Studio Codeのようなエディタでも問題ありません。

すべてのサンプルコードはGitHubリポジトリから入手可能です。

## 学習の道筋

本書は様々な背景を持つ読者を想定しています。ここでは、目的に応じた読み進め方を提案します。

**初心者の方へ**

* まず第2章で構文解析の基本的な考え方を理解してください
* 次に第3章でJSONパーサーを実装し、実践的な経験を積みます
* その後、第6章でツールを使った構文解析器の生成を学びます
* 理論的な内容（第4章、第5章）は後回しにしても構いません

**理論もしっかり学びたい方へ**

* 第2章→第3章→第4章→第5章の順番で読み進めてください
* 第4章の文脈自由文法は構文解析の理論的基礎です
* 第5章のアルゴリズムは少し難しいですが、じっくり取り組んでください
* 第6章で理論の実装を、第7章で実践を学びます

**すぐに使える知識が欲しい方へ**

* 第2章→第3章→第6章→第7章の順で読むことをお勧めします
* 第7章では現実に遭遇する泥臭い構文解析の問題を扱います

**各章の難易度の目安**

* 第2章：★（入門）
* 第3章：★★（実践基礎）
* 第4章：★★★（理論基礎）
* 第5章：★★★★（理論応用）
* 第6章：★★（ツール活用）
* 第7章：★★（実践応用）
* 第8章：★（まとめ）

最初から最後まで読み通してもらえれば、最終的には構文解析の基礎から応用まで幅広く理解できるようになります。

さて、第1章を読み終えた皆さんは、構文解析というテーマに対してどのような印象を持たれたでしょうか。もしかしたら、「普段何気なく書いているプログラムの裏側では、こんな複雑なことが行われているのか」と驚かれたかもしれません。あるいは、「自分の手で言語のルールを定義し、それを解釈するプログラムを作るのは面白そうだ」と感じた方もいるかもしれません。あなたがこれまでに触れたことのある言語で、構文が原因で混乱した経験はありますか？もしあれば、それはなぜだったのか、この本を読み進める中でヒントが見つかるかもしれません。

次の第2章では、いよいよ具体的な構文解析の世界に足を踏み入れ、簡単な算術式を題材に、手を動かしながら構文解析の第一歩を体験していただきます。お楽しみに！

2025年6月、自室にて記す。

水島宏太

## コラム：現代の構文解析の課題

構文解析技術は長い歴史を持ちますが、現代においては新たな課題に直面しています。

**エラーリカバリー**: 従来の構文解析器は、文法エラーに遭遇すると即座に処理を停止していました。これは、最初の文法エラーが後続の文法エラーを引き起こす上に、後続の文法エラーが実態を表していないことが多かったための措置でした。しかし、IDEでは入力途中のコードを常に解析する必要があります。そのため、エラーがあっても可能な限り解析を続行し、意味のあるエラーメッセージを提供する「エラーリカバリー」技術が重要になっています。

**インクリメンタルパージング**: ファイル全体を毎回解析し直すのは非効率です。変更された部分だけを再解析する「インクリメンタルパージング」により、大規模なファイルでもリアルタイムな解析が可能になります。

**Language Server Protocol（LSP）**: Microsoftが提唱したLSPは、言語サーバーとエディタ間の通信プロトコルです。実質的にはIDEのための基盤プロトコルと言っても良いでしょう。構文解析結果を効率的に共有することで、一つの言語サーバーが複数のエディタに対応できるようになりました。

**AIとの融合**: GitHub CopilotやChatGPTのようなAIツールは、コードの構造を理解する必要があります。構文解析によって得られた抽象構文木は、AIがコードを**理解**するための重要な手がかりとなっています。

これらの課題は、構文解析が単なる「文字列から木構造への変換」以上の役割を担っていることを示しています。

[^1]: Alfred V. Aho, Monica S. Lam, Ravi Sethi, Jeffrey D. Ullman 著「コンパイラ 第2版: 原理・技法・ツール」（サイエンス社, 2009年）のこと。コンパイラ開発の標準的な教科書であり、表紙のデザインから「ドラゴンブック」の愛称で広く知られています。
