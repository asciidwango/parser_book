
# 第5章 構文解析アルゴリズム古今東西

第4章で学んだ文脈自由文法は、構文解析の理論的な基礎です。特にDyck言語（ディック言語）を例に、括弧の対応という根本的な問題を通して、再帰的な構造を文法でどう表現するかを学びました。この章では、いよいよその文法を実際に解析するための「アルゴリズム」について深く掘り下げていきます。

## 本章で学ぶこと

「構文解析アルゴリズム」と聞くと難しそうに感じるかもしれません。しかし、実は皆さんはすでに2つの構文解析アルゴリズムを実装しているのです。

第3章を思い出してください。最初に実装した`PegJsonParser`は、**PEG（Parsing Expression Grammar）**という手法の素朴な実装でした。次に実装した`SimpleJsonParser`は、実は**LL(1)**（「エルエルワン」と読みます）と呼ばれる手法に近い**再帰下降構文解析器**だったのです。

この章では、これらのアルゴリズムがどのような仕組みで動いているのか、そして他にどのようなアルゴリズムが存在するのかを体系的に学びます。具体的には：

1. **下向き構文解析（Top-down）**：文法の開始記号から始めて、入力文字列に向かって解析を進める方法

   - LL(1)、LL(k)、再帰下降構文解析
   
2. **上向き構文解析（Bottom-up）**：入力文字列から始めて、文法の開始記号に向かって解析を進める方法

   - LR(0)、SLR(1)、LR(1)、LALR(1)
   
3. **PEGとPackrat Parsing**：バックトラックを許す新しいアプローチ

それぞれのアルゴリズムには得意・不得意があり、実際のプログラミング言語の構文解析器では、言語の特性に応じて最適なアルゴリズムが選ばれています。

## 構文解析器生成系との関係

各アルゴリズムには、対応する**構文解析器生成系**（パーサジェネレータ）が存在します：

- **yacc/bison**：LALR(1)を採用（C言語向け）
- **JavaCC**：LL(1)を採用（Java向け）  
- **ANTLR**：ALL(*)という拡張されたLL系を採用（多言語対応）
- **各種PEGパーサジェネレータ**：PEGを採用

これらのツールについては第6章で詳しく説明しますが、本章でアルゴリズムを理解することで、各ツールがなぜそのアルゴリズムを選んだのかが見えてくるはずです。

## 下向き構文解析と上向き構文解析 - 2つの世界観

構文解析アルゴリズムの世界には、大きく分けて2つの「世界観」があります。それが**下向き（Top-down）**と**上向き（Bottom-up）**です。この2つは、同じ構文解析という仕事を、まったく逆のアプローチで実現します。

### なぜ2つのアプローチが必要なのか？

第4章で学んだDyck言語を例に考えてみましょう。文法は以下でした：

```
D → P
P → ( P ) P
P → ε
```

入力文字列 `(())` を解析する際、2つの考え方ができます：

1. **下向き（予測的）**：「Dから始まって、どうすれば`(())`が導出できるか？」
2. **上向き（還元的）**：「`(())`から始めて、どうすればDに辿り着けるか？」

これは、迷路を解くときに「入口から出口を探す」か「出口から入口を探す」かの違いに似ています。どちらも正解に辿り着きますが、効率や適用できる問題が異なるのです。

## 下向き構文解析の基本原理

下向き構文解析は、文法の開始記号から出発し、入力文字列に向かって「上から下へ」解析を進めます。

### Dyck言語で学ぶ予測型下向き構文解析

第4章で学んだDyck言語（括弧の対応が取れた文字列を表す言語）を例に、具体的に動作を追ってみましょう。説明のために、文法に入力の開始・終了を表す`$`（ドル記号）を追加します：

```
D -> $ P $
P -> ( P ) P
P -> ε
```

入力文字列 `(())` に対して、この文法が受理するかどうかを判定してみましょう。

### スタックを使った解析の追跡

予測型下向き構文解析では、**スタック**を使って解析の進行状況を管理します。スタックには、「今どの規則のどの位置を解析しているか」という情報を記録します。

ドット記号「・」（中黒）を使って、規則内の現在位置を表します。例えば：

- `D -> ・$ P $` ：まだ何も解析していない状態
- `D -> $・P $` ：`$`を解析済み、次は`P`を解析する
- `D -> $ P $・` ：すべて解析完了

このドット記号は、Javaでいえばデバッガーでステップ実行する時の「現在の実行位置」のようなものだと考えてください。

では、実際に解析を開始しましょう：

```
入力: $ ( ( ) ) $
スタック: [ D -> ・$ P $ ]
```

**ステップ1**：最初の記号 `$` を入力から読み込みます。スタックトップの規則が期待する記号と一致するので、ドットを進めます：

```
入力: ( ( ) ) $
スタック: [ D -> $・P $ ]
```

**ステップ2**：非終端記号 `P` を解析する必要があります。ここで「予測」が必要になります。

非終端記号とは、第2章で学んだように「まだ展開の余地がある記号」のことでした。Javaでいえばメソッド呼び出しのようなものです。

次の入力文字は `(` です。`P`の規則は2つあります：

- `P -> ( P ) P` ：`(`で始まる
- `P -> ε` ：空文字列（何もない）

先読み文字が`(`なので、`P -> ( P ) P`を選択します。この規則をスタックに追加します：

```
入力: ( ( ) ) $
スタック: [ D -> $・P $, P -> ・( P ) P ]
```

このように、「先読み文字を見て、次に適用すべき規則を予測する」のが予測型下向き構文解析の特徴です。

### 予測型下向き構文解析のアルゴリズム

予測型下向き構文解析の動作パターンをまとめると：

1. **先読み文字の取得**：現在の入力位置から1文字先を見る

2. **非終端記号の展開**：

   - スタックトップが非終端記号の場合、先読み文字に基づいて適用する規則を「予測」
   - 選択した規則をスタックに追加
   - 適切な規則がない場合はエラー

3. **終端記号のマッチング**：

   - スタックトップが終端記号の場合、入力文字と比較
   - 一致すれば入力を消費してドットを進める
   - 一致しなければエラー

4. **規則の完了**：

   - 規則の最後まで進んだら、スタックからその規則を除去
   - 一つ上の規則の解析を続行

5. **受理判定**：

   - 入力がすべて消費され、スタックが空になれば受理
   - それ以外は拒否

## 再帰下降構文解析 - 下向き構文解析のJava実装

スタックを使った下向き構文解析の動作を理解したところで、これをJavaで実装してみましょう。実は、多くの場合、スタックを明示的に使わずに**再帰呼び出し**を使って実装できます。これが「再帰下降構文解析」と呼ばれる理由です。

### 再帰下降構文解析の実装

```java
// 文法規則：
// D -> P
// P -> ( P ) P
// P -> ε（イプシロン：空文字列）
public class Dyck {
    private final String input;
    private int position;

    public Dyck(String input) {
        this.input = input;
        this.position = 0;
    }

    public boolean parse() {
        boolean result = D();
        return result && position == input.length();
    }

    private boolean D() {
        return P();
    }

    private boolean P() {
        // P -> ( P ) P
        if (position < input.length() && input.charAt(position) == '(') {
            position++; // '(' を読み進める
            if (!P()) return false;
            if (position < input.length() && input.charAt(position) == ')') {
                position++; // ')' を読み進める
                return P();
            } else {
                return false;
            }
        // P -> ε
        } else {
            // 空文字列にマッチ
            return true;
        }
    }
}
```

### コードの解説

この実装では、各非終端記号に対応するメソッドを作成しています：

1. **`D()`メソッド**：文法の開始記号`D`に対応
   - 規則 `D -> P` をそのまま実装：`P()`を呼び出すだけ

2. **`P()`メソッド**：非終端記号`P`に対応
   - 最初に `P -> ( P ) P` を試す：先読み文字が`(`か確認
   - 適用できない場合は `P -> ε` を適用：常に`true`を返す

3. **文字の消費**：`position`をインクリメントすることで実現

4. **バックトラックのない予測型**：一度選択した規則で失敗したら、即座に`false`を返す

### 文法規則とコードの対応関係

BNF規則とJavaコードの対応を見てみましょう：

```
文法規則： D -> P
Javaコード： private boolean D() { return P(); }

文法規則： P -> ( P ) P | ε  
Javaコード： private boolean P() {
    if (先読み文字 == '(') {
        // P -> ( P ) P を適用
    } else {
        // P -> ε を適用
    }
}
```

このように：

- 各非終端記号にメソッドが対応
- 非終端記号の参照はメソッド呼び出しに変換
- 選択はif文で実現
- 連接は順次実行で実現

と対応しています。

### 「再帰下降」という名前の由来

この実装方法が「再帰下降」と呼ばれる理由は：

1. **再帰**：メソッドが自分自身または他のメソッドを呼び出す
2. **下降**：文法の開始記号から「下」の規則へと解析が進む

実際に`parse("(())")`を実行すると、以下のような呼び出しの連鎖が発生します：

```
parse() -> D() -> P() -> P() -> P() -> ...
```

この呼び出しスタックが、先ほどスタックで説明した解析状態と対応しているのです。

## 上向き構文解析の基本原理

さて、下向き構文解析を理解したところで、次は**上向き構文解析**を見ていきましょう。こちらは下向きとは全く逆のアプローチを取ります。

### シフト還元構文解析の基本アイデア

上向き構文解析は、**シフト還元構文解析**とも呼ばれます。この名前は、2つの基本操作から来ています：

1. **シフト（Shift）**：入力から1文字読み込んでスタックに積む
2. **還元（Reduce）**：スタック上の記号列が某規則の右辺と一致したら、左辺に置き換える

下向き構文解析が「文法から入力へ」と進むのに対し、上向き構文解析は「入力から文法へ」と進みます。つまり、入力文字列を徐々に「縮めて」いって、最終的に開始記号に辿り着けるかを確認するのです。

### 例で学ぶシフト還元構文解析

同じDyck言語を例にしますが、上向き構文解析では空文字列規則（ε規則）が扱いづらいので、等価な別の文法を使います：

```
D -> $ P $
D -> $ ε $
P -> P X
P -> X
X -> ( X )
X -> ()
```

この文法の特徴は以下の通りです：

- `X`は内側の括弧ペアを表す
- `P`は括弧ペアの列を表す
- `D`は全体を表す

では、入力文字列 `(())` に対してシフト還元構文解析を行ってみましょう。

- **ステップ1**：開始記号`$`をシフト

```
スタック: [ $ ]
入力: ( ( ) ) $
```

- **ステップ2**：最初の`(`をシフト

```
スタック: [ $, ( ]
入力: ( ) ) $
```

- **ステップ3、4**：さらに`(`と`)`をシフト

```
スタック: [ $, (, (, ) ]
入力: ) $
```

- **ステップ5**: スタックの末尾`(, )`が規則`X -> ()`の右辺と一致しました。この2つの記号を`X`に**還元**します：

```
スタック: [ $, (, X ]
入力: ) $
```

- **ステップ6**：次の`)`をシフト

```
スタック: [ $, (, X, ) ]
入力: $
```

- **ステップ7**：スタックの末尾`(, X, )`が規則`X -> ( X )`の右辺と一致しました。還元します：

```
スタック: [ $, X ]
入力: $
```

このプロセスを続けることで、最終的に開始記号`D`に到達します。

### シフト還元構文解析のアルゴリズム

シフト還元構文解析の動作パターンをまとめると：

1. **シフト操作**：
   - 入力から1文字読み込んでスタックに積む
   - 常に左から右へ順番に読む

2. **還元操作**：
   - スタック上端の記号列が、ある規則の右辺と一致したら
   - その記号列を取り除いて、規則の左辺の非終端記号を積む

3. **アクションの選択**：
   - シフトと還元のどちらを行うかを決定する必要がある
   - この決定方法がLR(0)、SLR(1)、LR(1)などの違いになる

4. **受理判定**：
   - 入力をすべて読み、スタックが開始記号だけになれば受理
   - それ以外は拒否

### 下向きと上向きの違い

ここまでの例からわかるように：

- **下向き**：`D`から始めて`(())`を「生成」しようとする
- **上向き**：`(())`から始めて`D`に「還元」しようとする

上向き構文解析の還元操作は、第4章で学んだ「最右導出」の逆操作に相当します。つまり、導出の過程を逆再生しているのです。

## シフト還元構文解析のJava実装

シフト還元構文解析をJavaで実装してみましょう。下向き構文解析とは異なり、明示的にスタックを使い、規則をデータ構造として扱います。

### 必要なデータ構造

まず、記号（終端記号・非終端記号）を表すクラスと、文法規則を表すクラスが必要です：

```java
// 記号を表すインターフェース
interface Element {
    char value();
}

// 終端記号（実際の文字：'(', ')', '$'など）
record Terminal(char value) implements Element {}

// 非終端記号（文法記号：'D', 'P', 'X'など）
record NonTerminal(char value) implements Element {}
```

次に、文法規則を表す`Rule`クラスを定義します：

```java
import java.util.List;
import java.util.ArrayList;

public record Rule(char lhs, List<Element> rhs) {
    // 可変長引数コンストラクタ（便利のため）
    public Rule(char lhs, Element... rhs) {
        this(lhs, List.of(rhs));
    }
    
    // スタックの上端がこの規則の右辺と一致するか判定
    public boolean matches(List<Element> stack) {
        if (stack.size() < rhs.size()) return false;
        
        // スタックの上からrhs.size()個の要素を比較
        for (int i = 0; i < rhs.size(); i++) {
            Element elementInRule = rhs.get(i);
            Element elementInStack = stack.get(stack.size() - rhs.size() + i);
            if (!elementInRule.equals(elementInStack)) {
                return false;
            }
        }
        return true;
    }
}
```

### シフト還元構文解析器の実装

上記のデータ構造を使って、実際のシフト還元構文解析器を実装します：

```java
import java.util.List;
import java.util.ArrayList;

public class DyckShiftReduce {
    private final String input;
    private int position;
    private final List<Rule> rules;
    private final List<Element> stack = new ArrayList<>();

    public DyckShiftReduce(String input) {
        this.input = input;
        this.position = 0;
        
        // 文法規則の定義
        this.rules = List.of(
            // D -> $ P $
            new Rule('D', 
                new Terminal('$'), 
                new NonTerminal('P'), 
                new Terminal('$')
            ),
            // D -> $ $ (空文字列の場合)
            new Rule('D', 
                new Terminal('$'), 
                new Terminal('$')
            ),
            // P -> P X
            new Rule('P', 
                new NonTerminal('P'), 
                new NonTerminal('X')
            ),
            // P -> X
            new Rule('P', 
                new NonTerminal('X')
            ),
            // X -> ( X )
            new Rule('X', 
                new Terminal('('), 
                new NonTerminal('X'), 
                new Terminal(')')
            ),
            // X -> ()
            new Rule('X', 
                new Terminal('('), 
                new Terminal(')')
            )
        );
    }

    public boolean parse() {
        // 開始記号$をスタックに積む
        stack.add(new Terminal('$'));
        
        // メインループ：シフトと還元を繰り返す
        while (true) {
            // まず還元を試みる
            if (!tryReduce()) {
                // 還元できない場合、シフトを試みる
                if (position < input.length()) {
                    char c = input.charAt(position);
                    stack.add(new Terminal(c));
                    position++;
                } else {
                    // シフトもできないので終了
                    break;
                }
            }
        }
        
        // 終端記号$をスタックに積む
        stack.add(new Terminal('$'));
        
        // 最後に可能な限り還元を繰り返す
        while (tryReduce()) {
            // 還元ができなくなるまで続ける
        }
        
        // スタックが[D]のみになったら受理
        return stack.size() == 1 && 
               stack.get(0).equals(new NonTerminal('D'));
    }

    private boolean tryReduce() {
        for (Rule rule : rules) {
            if (rule.matches(stack)) {
                // マッチしたら右辺の長さ分スタックから削除
                for (int i = 0; i < rule.rhs().size(); i++) {
                    stack.remove(stack.size() - 1);
                }
                // 左辺の非終端記号をスタックに追加
                stack.add(new NonTerminal(rule.lhs()));
                return true; // 還元成功
            }
        }
        return false; // 還元できる規則がなかった
    }
}
```

### 実装のポイント

この実装の重要な点は：

1. **シフトより還元を優先**：まず`tryReduce()`で還元を試み、できない場合のみシフト
2. **単純な還元ルール**：すべての規則を順番にチェックし、最初にマッチしたものを使う
3. **明示的なスタック操作**：`List<Element>`をスタックとして使い、要素の追加・削除を明示的に行う

この実装は最も単純なシフト還元構文解析で、実用的なパーサではさらに洗練されたアルゴリズム（LR(0)、SLR(1)、LR(1)、LALR(1)）が使われます。

## 下向き構文解析と上向き構文解析の比較

ここまで下向き構文解析と上向き構文解析の具体例を見てきました。両者にはそれぞれ得意不得意があります。

### 下向き構文解析の利点と欠点

**利点：**
1. **直感的な実装**
   - 文法規則とメソッドが1対1に対応
   - 手書きの構文解析器が書きやすい
   - 実際、多くのプログラミング言語のコンパイラが手書き再帰下降を採用

2. **文脈依存の扱いやすさ**
   - メソッドの引数で情報を渡せる
   - 解析中に状態を管理しやすい
   - エラー回復やエラーメッセージの生成が容易

3. **デバッグのしやすさ**
   - 通常の関数呼び出しなのでデバッガで追える
   - 構文解析の過程が理解しやすい

**欠点：**
1. **左再帰の問題**

たとえば、以下のBNFは上向き型だと普通に解析できますが、工夫なしに下向き型で実装すると無限再帰に陥ってスタックオーバーフローします。

```text
A -> A "a" | ε // 左再帰を含む文法の例 (εは空文字列)
```

この文法は「`A`は、`A`の後に`a`が続くか、何もないか」という意味ですが、`A`を解析するためにまず`A`を解析する必要があるので無限ループになります。

このような問題を下向き型で解決する方法も存在します。例えば、直接左再帰 `A -> A α | β` （ここで `β` は `A` で始まらない）は、以下のように等価な右再帰の文法に書き換えることで除去できます。

```text
A  -> β A'
A' -> α A' | ε
```

この変換により、下向き構文解析で問題となる無限再帰を避けることができます。ただし、文法の書き換えは常に簡単とは限りません。

### 上向き構文解析の利点と欠点

**利点：**
1. **左再帰を自然に扱える**
2. **より広いクラスの文法を扱える**
3. **効率的な構文解析表による高速化が可能**

**欠点：**
1. **実装が複雑**
2. **文脈依存の処理が難しい**

たとえば、それまでの文脈に応じて構文解析のルールを切り替えたくなることがあります。最近の言語によく搭載されている文字列補間などはその最たる例です。

`"`の中は文字列リテラルとして特別扱いされますが、その中で`#{`が出てきたら（Rubyの場合）、通常の式を構文解析するときのルールに戻る必要があります。

このように、文脈に応じて適用するルールを切り替えるのは下向き型が得意です。もちろん、上向き型でも実現できないわけではありません。実際、Rubyの構文解析機はYaccの定義ファイルから生成されるようになっていますが、Yaccが採用しているのは代表的な上向き構文解析法である`LALR(1)`です。

## LL(1) - 代表的な下向き構文解析アルゴリズム

ここからは、具体的な構文解析アルゴリズムについて詳しく見ていきましょう。まずは下向き構文解析の代表格である**LL(1)**から始めます。

### LL(1)とは？

**LL(1)**という名前は以下の意味を持ちます：

- **最初のL**：**L**eft-to-right（左から右へ入力を読む）
- **2番目のL**：**L**eftmost derivation（最左導出を行う）
- **(1)**：1トークン先読み

つまり、「1トークン先を見て、次に適用すべき規則を一意に決定できる」という制約を持つ下向き構文解析法です。

この「LL」という名前の由来ですが、構文解析の研究が盛んだった1960年代に、様々な手法を分類するために考案された命名規則です。同様に、後で出てくる「LR」も「Left-to-right, Rightmost derivation」を表します。

### LL(1)の直感的な理解

身近な例で考えてみましょう。Javaのif文とwhile文の解析を例にします：

```java
if (age < 18) {
    System.out.println("18歳未満です");
}

while (count > 0) {
    count--;
}
```

プログラマがこのコードを見たとき、最初のトークンだけで文の種類を判断できます：
- `if`で始まる → if文だ！
- `while`で始まる → while文だ！

LL(1)は、まさにこの「最初の1トークンで判断」というアイデアをアルゴリズム化したものです。

しかし、すべての構文がこのように単純ではありません。例えば、算術式を考えてみましょう：

```
式 → 数値
式 → ( 式 )
式 → - 式
```

この場合、式は以下のいずれかで始まる可能性があります：
- 数値（例：`42`）
- 左括弧（例：`(3 + 5)`）
- マイナス記号（例：`-10`）

つまり、「式」という非終端記号は複数のトークンで始まる可能性があるのです。

### なぜFIRST集合とFOLLOW集合が必要か

LL(1)を実現するには、以下の2つの問題を解決する必要があります：

**問題1：複数のトークンで始まる構文**

上の算術式の例のように、一つの非終端記号が複数のトークンで始まる場合があります。これを体系的に扱うために**FIRST集合**（その非終端記号から始まる可能性のあるトークンの集合）が必要です。

**問題2：省略可能な要素**

Javaのif文には、else節があるものとないものがあります：

```java
// else節なし
if (condition) { ... }

// else節あり
if (condition) { ... } else { ... }
```

else節は「あってもなくてもいい」要素です。このような場合、else節の後に何が来るかを知る必要があります。これが**FOLLOW集合**（その非終端記号の後に来る可能性のあるトークンの集合）です。

### FIRST集合とFOLLOW集合

LL(1)構文解析を実現するには、これらの集合を計算して利用します：

#### FIRST集合

ある非終端記号から導出される文字列の「最初に現れうるトークンの集合」を**FIRST集合**と呼びます。

正式には、非終端記号`A`に対して：
```
FIRST(A) = { a | A ⇒* aβ であるような終端記号 a }
```

例えば、以下の算術式の文法を考えます。
```
Expr -> Term (('+' | '-') Term)*
Term -> Factor (('*' | '/') Factor)*
Factor -> '(' Expr ')' | Number | '-' Factor | '+' Factor
Number -> [0-9]+
```

この場合、それぞれの非終端記号のFIRST集合は次のようになります：

```
FIRST(Expr) = { '(', '-', '+', 数字 }
FIRST(Factor) = { '(', '-', '+', 数字 }
FIRST(Number) = { 数字 }
```

#### nullable - 空文字列を生成できるか

LL(1)構文解析で重要な概念として、**nullable**（ヌラブル）があります。これは、ある非終端記号が空文字列（ε）を生成できるかどうかを示すブール値です。

「nullable」という名前はJavaの`null`とは関係ありません。「空にできる」つまり「何も生成しないことができる」という意味です。

例えば、以下の文法を考えます：
```
A -> a B c
B -> b | ε
C -> d C | ε
```

この場合：
- `nullable(A) = false`（`A`は必ず`a`と`c`を含むため）
- `nullable(B) = true`（`B -> ε`という規則があるため）
- `nullable(C) = true`（`C -> ε`という規則があるため）

なぜnullableが重要かというと、ある非終端記号が空文字列を生成できる場合、その非終端記号の「次」に来るトークンも考慮する必要があるからです。

#### FOLLOW集合

非終端記号の後に現れうるトークンの集合を**FOLLOW集合**と呼びます。これは、nullable な非終端記号（空文字列規則を持つ非終端記号）を扱うために特に重要です。

例えば、if文の文法：
```
IfStatement -> 'if' '(' Expression ')' Statement ElsePart
ElsePart -> 'else' Statement | ε
```

`ElsePart`は空文字列を生成できるので、`nullable(ElsePart) = true`です。
`ElsePart`が`ε`を選ぶべきかどうかは、次のトークンが`else`か、それとも`FOLLOW(ElsePart)`に含まれるトークンかで判断します。

### FIRST集合、FOLLOW集合、nullableの計算方法

これらの集合を実際に計算する方法を見ていきましょう。

#### nullableの計算アルゴリズム

1. すべての非終端記号について`nullable = false`に初期化
2. `A -> ε`の形の規則があれば`nullable(A) = true`
3. `A -> X₁ X₂ ... Xₖ`について、すべての`Xᵢ`がnullableなら`nullable(A) = true`
4. 変化がなくなるまで繰り返す

**例：**
```
E → T E'
E' → + T E' | ε
T → F T'
T' → * F T' | ε
F → ( E ) | id
```

計算過程：
- 初期化：すべて`false`
- `E' → ε`があるので`nullable(E') = true`
- `T' → ε`があるので`nullable(T') = true`
- 他の非終端記号はε規則を持たず、右辺もnullableでないので`false`のまま

結果：
- `nullable(E) = false`、`nullable(E') = true`
- `nullable(T) = false`、`nullable(T') = true`
- `nullable(F) = false`

#### FIRST集合の計算アルゴリズム

各規則 `A → α` について：

1. `α = X₁ X₂ ... Xₙ` とする
2. `X₁`が終端記号なら、`FIRST(A)`に`X₁`を追加
3. `X₁`が非終端記号なら：
   - `FIRST(X₁) - {ε}`を`FIRST(A)`に追加
   - `X₁`がnullableなら`X₂`も確認（以下同様）
4. すべての`Xᵢ`がnullableなら、`ε`を`FIRST(A)`に追加

**例の文法での計算：**
```
F → ( E ) | id
```
- `FIRST(F) = { '(', id }`（両方の規則の最初の終端記号）

```
T → F T'
```
- `FIRST(T) = FIRST(F) = { '(', id }`（`F`は非終端記号なので`FIRST(F)`を使用）

```
E → T E'
```
- `FIRST(E) = FIRST(T) = { '(', id }`

```
E' → + T E' | ε
```
- `FIRST(E') = { '+', ε }`（最初の規則から`+`、2番目の規則から`ε`）

```
T' → * F T' | ε
```
- `FIRST(T') = { '*', ε }`

#### FOLLOW集合の計算アルゴリズム

1. すべての非終端記号の`FOLLOW`を空集合に初期化
2. 開始記号`S`に対して`FOLLOW(S) = {$}`（入力終端）
3. 規則`B → αAβ`に対して：
   - `FIRST(β) - {ε}`を`FOLLOW(A)`に追加
   - `β`がnullableなら`FOLLOW(B)`を`FOLLOW(A)`に追加
4. 規則`B → αA`（末尾に`A`）に対して：
   - `FOLLOW(B)`を`FOLLOW(A)`に追加
5. 変化がなくなるまで繰り返す

**例の文法での計算：**

初期状態：
- `FOLLOW(E) = {$}`（開始記号として）

規則`F → ( E )`から：
- `E`の後に`)`が来るので、`FOLLOW(E) = {$, ')'}`

規則`E → T E'`から：
- `T`の後に`E'`が来る。`FIRST(E') = {'+', ε}`
- `E'`がnullableなので、`FOLLOW(E)`も`FOLLOW(T)`に追加
- `FOLLOW(T) = {'+', $, ')'}`

規則`E → T E'`から：
- `E'`は末尾なので、`FOLLOW(E')`に`FOLLOW(E)`を追加
- `FOLLOW(E') = {$, ')'}`

同様に計算を続けると：
- `FOLLOW(E) = {$, ')'}`
- `FOLLOW(E') = {$, ')'}`
- `FOLLOW(T) = {'+', $, ')'}`
- `FOLLOW(T') = {'+', $, ')'}`
- `FOLLOW(F) = {'*', '+', $, ')'}`

### LL(1)構文解析表

FIRST集合とFOLLOW集合を使って、LL(1)構文解析表を作成します。これは「非終端記号」と「先読みトークン」の組み合わせから、適用すべき規則を決定する表です。

**例：簡単な文法の解析表**

文法：
```
E → T E'
E' → + T E' | ε
T → F T'
T' → * F T' | ε
F → ( E ) | id
```

|        | id  | +   | *   | (   | )   | $   |
|--------|-----|-----|-----|-----|-----|-----|
| E      | E->TE' |     |     | E->TE' |     |     |
| E'     |     | E'->+TE' |     |     | E'->ε | E'->ε |
| T      | T->FT' |     |     | T->FT' |     |     |
| T'     |     | T'->ε | T'->*FT' |     | T'->ε | T'->ε |
| F      | F->id |     |     | F->(E) |     |     |

もし同じセルに複数の規則が入る場合、その文法はLL(1)ではありません。

### LL(1)の問題点と限界

LL(1)はシンプルで実用的ですが、いくつかの限界があります。

**問題点1：共通前置辞問題**

例：
```
S -> a B
S -> a C
```

両方の規則が`a`で始まるため、1文字先読みでは判断できません。この問題は**左因子化**で解決できます：

```
S  -> a S'
S' -> B
S' -> C
```

**問題点2：左再帰の問題**

LL(1)の最大の欠点は、**左再帰**を扱えないことです。

```
E -> E + T
E -> T
```

この問題は**左再帰の除去**で解決できます：

```
E  -> T E'
E' -> + T E'
E' -> ε
```

しかし、この変換により文法の直感性が失われ、ASTの構築も複雑になります。

## LR構文解析 - 素朴なシフト還元の効率化

ここまで見てきた素朴なシフト還元構文解析には、大きな問題がありました：

1. **いつシフトして、いつ還元するか？** - 毎回スタック全体を調べる必要がある
2. **どの規則で還元するか？** - すべての規則を順番に試す必要がある

これらの判断を効率的に行うのが**LR構文解析**です。

### 素朴な方法の問題点

先ほどの`DyckShiftReduce`の実装を思い出してください：

```java
private boolean tryReduce() {
    for (Rule rule : rules) {  // すべての規則を試す！
        if (rule.matches(stack)) {  // スタック全体をチェック！
            // 還元処理
        }
    }
    return false;
}
```

入力が長くなると、この方法は非効率的です。LR構文解析は、この問題を**オートマトン**で解決します。

### LR構文解析の革新的アイデア

1965年、Donald Knuth（ドナルド・クヌース）は画期的な発見をしました：

> **シフト還元構文解析の「状態」は有限個にまとめられる！**

つまり：
- スタックの内容が違っても、「同じ判断をすべき状態」は同じ
- これらの状態間の遷移は**有限オートマトン**で表現できる

クヌースは、第1章でも出てきた「ドラゴンブック」の共著者としても知られるコンピュータ科学の巨人です。「オートマトン」は第4章で学んだ、状態を持つ機械のことでしたね。

### LR(0)項目 - 解析の進行状況を表す

LR構文解析では、規則の認識状況を「ドット（・）」で表します：

```
A → ・abc    （まだ何も認識していない）
A → a・bc    （aまで認識した）
A → ab・c    （abまで認識した）  
A → abc・    （全部認識した＝還元可能）
```

これを**LR(0)項目**と呼びます。「項目」という呼び名は難しく聮こえるかもしれませんが、単に「解析の途中状態を表すもの」だと思ってください。

素朴なシフト還元で「スタックの末尾が規則の右辺と一致するか」をチェックしていたのを、より体系的に表現したものです。

### 具体例で理解するLR(0)

素朴なシフト還元との違いを理解するため、具体例で見てみましょう。

文法：
```
E → T
T → id
```

入力 `id` を解析する場合：

**素朴なシフト還元では：**
1. `id`をシフト → スタック: `[id]`
2. すべての規則をチェック → `T → id`がマッチ
3. 還元 → スタック: `[T]`
4. すべての規則をチェック → `E → T`がマッチ
5. 還元 → スタック: `[E]`

**LR(0)では：**
1. 状態0：「`id`か`T`か`E`を待っている」
2. `id`を読む → 状態3：「`T → id・`」（還元準備完了）
3. 還元して`T`を生成 → 状態2：「`E → T・`」（還元準備完了）
4. 還元して`E`を生成 → 完了

違いは明確です：
- 素朴な方法：毎回すべての規則をチェック
- LR(0)：状態が「次に何をすべきか」を教えてくれる

### LR(0)オートマトンの構築手順

では、このオートマトンをどう作るのでしょうか？

**ステップ1：初期状態を作る**

拡張文法（終了記号`$`を追加）：
```
S' → E $
E → T
T → id
```

初期状態I0：「開始記号`S'`から解析を始める」
```
I0 = {
    S' → ・E $    （Eを期待）
    E → ・T       （Eを作るにはTが必要）
    T → ・id      （Tを作るにはidが必要）
}
```

**ステップ2：状態遷移を計算**

I0から`id`を読んだら？
```
I3 = { T → id・}  （Tの認識完了）
```

I0から`T`を認識したら？
```
I2 = { E → T・}   （Eの認識完了）
```

I0から`E`を認識したら？
```
I1 = { S' → E・$ }  （あとは$を待つだけ）
```

**完成したオートマトン**

```{=latex}
\begin{center}
\begin{tikzpicture}[
  >=stealth',
  node distance=3cm,
  state/.style={rectangle, draw, minimum width=20mm, minimum height=10mm},
  accept/.style={state, double}
]
  % 状態の定義
  \node[state] (s0) {状態0};
  \node[state] (s3) [right of=s0] {状態3};
  \node[state] (s2) [below of=s3] {状態2};
  \node[accept] (s1) [below of=s0] {状態1};
  
  % 遷移の定義
  \draw[->] (s0) -- node[above] {id} (s3);
  \draw[->] (s3) -- node[right] {T生成} node[left] {(T→idで還元)} (s2);
  \draw[->] (s0) -- node[left] {T} (s2);
  \draw[->] (s2) -- node[right] {E生成} node[left] {(E→Tで還元)} (s1);
  \draw[->] (s0) -- node[left] {E} (s1);
  \draw[->] (s1) -- node[below] {\$} ([xshift=2cm]s1.east) node[right] {受理};
  
  % 開始状態の矢印
  \draw[->] ([xshift=-1cm]s0.west) -- (s0);
\end{tikzpicture}
\end{center}
```

このオートマトンにより、素朴なシフト還元の「総当たり」が「状態遷移」に置き換わりました。

### LR(0)の限界：コンフリクト

LR(0)は効率的ですが、重要な限界があります。

**より現実的な文法での問題**

算術式の文法：
```
E → E + T
E → T
T → id
```

この文法でLR(0)オートマトンを構築すると、ある状態で以下の項目を含むことになります：

```
状態X = {
    E → T・       （還元準備完了）
    E → E・+ T    （+を期待）
}
```

この状態で問題が発生します：
- 入力が`+`なら → シフトして`+`を読むべき
- 入力が`$`（終端）なら → `E → T`で還元すべき

しかし、LR(0)は**次の入力を見ない**ので、どちらを選ぶか決められません。これを**シフト/還元コンフリクト**と呼びます。

### なぜコンフリクトが起きるのか

素朴なシフト還元では、実は暗黙的に「次の文字」を見ていました：

```java
// 素朴な実装では
if (tryReduce()) {
    // 還元
} else if (position < input.length()) {
    // まだ入力があるならシフト
}
```

しかし、LR(0)では「状態だけ」で判断しようとするため、情報が不足するのです。

## SLR(1)、LR(1)、LALR(1) - 先読みによる改良

LR(0)のコンフリクトを解決するため、**先読み**（次の入力を見る）を導入した手法が開発されました。

### SLR(1) - FOLLOW集合による改良

**SLR(1)**（Simple LR(1)）は、LL(1)で学んだFOLLOW集合の考え方を使います。

**基本アイデア：**
「ある非終端記号Aの後に来うる記号」が分かれば、還元すべきタイミングが分かる

先ほどのコンフリクトの例：
```
状態X = {
    E → T・       （還元準備完了）
    E → E・+ T    （+を期待）
}
```

SLR(1)の判断：
- `FOLLOW(E) = {+, $}`（Eの後には+か$が来る）
- 次の入力が`+`なら：
  - シフト（`E → E・+ T`のため）
  - 還元も可能（`+` ∈ FOLLOW(E)）だが、シフトを優先
- 次の入力が`$`なら：
  - 還元のみ（`$` ∈ FOLLOW(E)）

これで多くのコンフリクトが解消されます。

### LR(1) - より精密な先読み

SLR(1)でも解決できないコンフリクトがあります。**LR(1)**は、各項目に「その項目に到達した文脈での先読み記号」を付加します：

```
[E → T・, +]    （この還元の後には+が来る）
[E → T・, $]    （この還元の後には$が来る）
```

同じ`E → T・`でも、文脈によって異なる先読み記号を持つことで、より精密な判断が可能になります。

### LALR(1) - 実用的な妥協点

**LALR(1)**は、LR(1)の「同じコアを持つ状態」をマージします：

```
状態1: { [E → T・, +] }
状態2: { [E → T・, $] }
↓
マージ後: { [E → T・, +/$] }
```

これにより：
- 状態数：LR(0)と同じ（コンパクト）
- 解析能力：LR(1)に近い（実用上十分）

YaccやBisonがLALR(1)を採用しているのは、この「効率と能力のバランス」が理由です。

### まとめ：素朴な方法からの進化

1. **素朴なシフト還元**：毎回すべての規則をチェック
2. **LR(0)**：オートマトンで効率化、ただし先読みなし
3. **SLR(1)**：FOLLOW集合で簡単な先読み
4. **LR(1)**：文脈ごとの先読みで精密化
5. **LALR(1)**：実用的なバランス

この流れを理解することで、各手法の存在意義が明確になります。

## Parsing Expression Grammar(PEG) - 新しいアプローチ

2004年にBryan Fordが提案した**Parsing Expression Grammar（PEG）**は、全く違うアプローチを取ります。

### PEGの基本アイデア

PEGの最大の特徴は：

1. **順序付き選択**：`A / B`は「まずAを試し、失敗したらBを試す」
2. **無制限なバックトラック**：失敗したら元の位置に戻る
3. **字句解析が不要**：文字列レベルで直接解析

### 第3章で実装したPEG

思い出してください。第3章で最初に実装した`PegJsonParser`がまさにPEGの実装でした：

```java
public Ast.JsonArray parseArray() {
    int backup = cursor;
    try {
        // LBRACKET RBRACKET
        parseLBracket();
        parseRBracket();
        return new Ast.JsonArray(new ArrayList<>());
    } catch (ParseException e) {
        cursor = backup;  // バックトラック！
    }

    // LBRACKET value {COMMA value} RBRACKET
    parseLBracket();
    // ... 省略 ...
}
```

この「バックトラック」がPEGの核心です。

### PEGの形式的定義

PEGは以下の8つの構成要素から成り立ちます：

1. 空文字列： ε
2. 終端記号： t
3. 非終端記号： N
4. 連接： e1 e2（e1の後にe2）
5. 選択： e1 / e2（e1またはe2）
6. 0回以上の繰り返し： e*
7. 肯定述語： &e（eにマッチするが消費しない）
8. 否定述語： !e（eにマッチしないことを確認）

特に7番と8番は文脈自由文法にはない、PEG特有の機能です。

### PEGとCFGの違い

| 特徴 | CFG | PEG |
|------|-----|-----|
| 選択演算子 | `｜`（非決定的） | `/`（順序付き） |
| 曖昧性 | あり得る | 常に一意 |
| 字句解析 | 必須 | 不要 |
| 左再帰 | 問題なし（LR系） | 無限ループ |
| 表現力 | 文脈自由言語 | それ以上 |

## Packrat Parsing - PEGの線形時間化

PEGの最大の弱点は、バックトラックにより最悪の場合に指数関数時間がかかることです。**Packrat Parsing**は、メモ化（memoization）を使ってこの問題を解決します。

### メモ化とは？

メモ化（memoization）は、「同じ引数で関数を呼んだら、同じ結果が返る」ことを利用して、一度計算した結果をキャッシュする技法です。

「メモ化」という名前は「memoize」（記憶する）から来ています。「メモリ化」ではなく「メモ化」であることに注意してください。

### フィボナッチ数で学ぶメモ化

フィボナッチ数の素朴な実装：

```java
public static long fib(long n) {
    if(n == 0) return 0L;
    if(n == 1) return 1L;
    else return fib(n - 1) + fib(n - 2); 
}
```

この実装の問題点は、同じ値を何度も計算してしまうことです。メモ化を適用すると：

```java
private static Map<Long, Long> cache = new HashMap<>();

public static long fib(long n) {
    Long value = cache.get(n);
    if(value != null) return value;

    long result;
    if(n == 0) {
        result = 0L;
    } else if (n == 1) {
        result = 1L;
    } else {
        result = fib(n - 1) + fib(n - 2);
    }
    cache.put(n, result);
    return result;
}
```

メモ化の効果：
- 時間計算量：`O(2^n)` → `O(n)`
- 空間計算量：`O(1)` → `O(n)`

### PEGパーサのメモ化

PEGパーサにもメモ化を適用できます。全ての規則に対してメモ化を行ったものを**Packrat Parsing**と呼びます。

```java
public class PackratParser {
    private Map<Integer, Map<String, MemoEntry>> memo;
    
    static class MemoEntry {
        boolean success;
        int endPos;
    }
    
    private boolean memoized(String ruleName, Supplier<Boolean> parser) {
        // メモ化テーブルをチェック
        Map<String, MemoEntry> posCache = memo.get(pos);
        if (posCache != null) {
            MemoEntry entry = posCache.get(ruleName);
            if (entry != null) {
                // キャッシュヒット！
                pos = entry.endPos;
                return entry.success;
            }
        }
        
        // キャッシュミス：実際にパース
        int startPos = pos;
        boolean success = parser.get();
        int endPos = pos;
        
        // 結果をキャッシュに保存
        // ... 省略 ...
        
        return success;
    }
}
```

### Packrat Parsingの特徴

**利点：**
- 線形時間保証：`O(n)`（`n`は入力長）
- 左再帰対応：工夫により可能
- 実装が比較的単純

**欠点：**
- メモリ使用量：`O(n×m)`（`m`は文法規則数）
- キャッシュミスのオーバーヘッド
- 並列化が困難

## 構文解析アルゴリズムの計算量と表現力

各アルゴリズムの計算量をまとめると：

| アルゴリズム | 時間計算量 | 空間計算量 | 備考 |
|-------------|-----------|-----------|------|
| LL(1) | O(n) | O(\|N\| × \|T\|) | \|N\|:非終端記号数, \|T\|:終端記号数 |
| LL(k) | O(n) | O(\|N\| × \|T\|^k) | kが大きくなると表サイズが指数的に増大 |
| SLR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数はLR(0)と同じ |
| LR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数が多い |
| LALR(1) | O(n) | O(状態数 × (\|T\|+\|N\|)) | 状態数はLR(0)と同程度 |
| PEG | O(2^n) (最悪) | O(n) | バックトラック用スタック |
| Packrat | O(n) | O(n × \|P\|) | \|P\|: 規則数 |

この表の「O表記」は、アルゴリズムの計算量を表す記法で、`O(n)`は「入力の長さに比例した時間」、`O(n^2)`は「入力の長さの2乗に比例した時間」を意味します。

注目すべきは、PEGを除くすべての手法が線形時間で解析できることです。また、Packrat Parsingを使えばPEGも線形時間になります。

## まとめ

この章では、文脈自由文法を実際に解析するための様々なアルゴリズムを学びました。

### 学んだアルゴリズムの整理

**下向き構文解析（トップダウン）**
- 予測的構文解析：Dyck言語を例に、スタックを使った実装
- 再帰下降構文解析：メソッド呼び出しによる実装
- LL(1)構文解析：FIRST集合とFOLLOW集合による効率化

**上向き構文解析（ボトムアップ）**
- シフト還元構文解析：葉から根に向かって構文木を構築
- LR(0)、SLR(1)、LR(1)、LALR(1)：段階的に強力になる手法

**その他の手法**
- PEG：順序付き選択による決定的な構文解析
- Packrat Parsing：メモ化によるPEGの線形時間化

### なぜこれらの知識が重要か

1. **パーサジェネレータの選択**：各ツールの特性を理解して選択できる
   - 例：ANTLRはエラーリカバリーが優れているのでIDE向き
   - Yacc/Bisonは高速だがエラーメッセージが分かりにくい

2. **エラーメッセージの理解**：コンフリクトの意味がわかる
   - 「shift/reduce conflict」→ シフトと還元のどちらを選ぶか決まらない
   - 「reduce/reduce conflict」→ 複数の還元規則から選べない

3. **DSLの設計**：パースしやすい文法設計ができる
   - シンプルな設定ファイルならLL(1)で十分
   - 複雑な表現が必要ならPEGやLALR(1)を検討

4. **パフォーマンスの理解**：適切な最適化を選択できる
   - 大量のデータ処理なら線形時間が保証される手法を選ぶ
   - IDEのリアルタイム解析ならインクリメンタル対応を考慮

構文解析は一見難しく感じるかもしれませんが、基本的なアイデアは「文字列を構造化する」というシンプルなものです。この章で学んだ各手法の特徴を理解しておけば、実際の開発で構文解析が必要になった時に、適切な選択ができるはずです。

次章では、ここで学んだアルゴリズムを実装したパーサジェネレータ（構文解析器生成系）について具体的に見ていきます。