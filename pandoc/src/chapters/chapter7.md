<!-- Chapter 5: 第7章:現実の構文解析 -->

# 第7章 現実の構文解析

ここまでで、LL法やLR法、Packrat Parsingといった、これまでに知られているメジャーな構文解析アルゴリズムを一通り取り上げてきました。これらの構文解析アルゴリズムは概ね文脈自由言語あるいはそのサブセットを取り扱うことができ、一般的なプログラミング言語の構文解析を行うのに必要十分な能力を持っているように思えます。

しかし、構文解析を専門としている人や実用的な構文解析器を書いている人は直感的に理解していることなのですが、実のところ、既存の構文解析アルゴリズムだけではうまく取り扱えない類の構文があります。一言でいうと、それらの構文は文脈自由言語から逸脱しているために、文脈自由言語を取り扱う既存の手法だけではうまくいかないのです。

このような、既存の構文解析アルゴリズムだけでは扱えない要素は多数あります。たとえば、Cのtypedefはその典型ですし、RubyやPerlのヒアドキュメントと呼ばれる構文もそうです。他には、Scalaのプレースホルダ構文やC++のテンプレート、Pythonのインデント文法など、文脈自由言語を逸脱しているがゆえに人間が特別に配慮しなければいけない構文は多く見かけられます。

また、これまでの章では、主に構文解析を行う手法を取り扱っていましたが、現実問題としては抽象構文木をうまく作る方法やエラーメッセージを適切に出す方法も重要になってきます。

この章では、巷の書籍ではあまり扱われない、しかし現実の構文解析では対処しなくてはならない構文や問題について取り上げます。皆さんが何かしらの構文解析器を作るとき、やはり理想どおりにはいかないことが多いと思います。この章がそのような現実の構文解析で遭遇する読者の方々の助けになれば幸いです。

## 7.1 字句要素が構文要素を含む文法

最近の多くの言語は文字列補間(String Interpolation)と呼ばれる機能を持っています。

たとえば、Rubyでは以下の文字列を評価すると、`"x + y = x + y"`ではなく`"x + y = 3"`になります。

```ruby
x = 1; y = 2
"x + y = #{x + y}" # "x + y = 3"
```

つまり、`#{`と`}`で囲まれた範囲をRubyの式として評価した結果を文字列として埋め込んでくれるわけです。

Scalaでも同じことを次のように書くことができます。

```scala
val x = 1; val y = 2
s"x + y = ${x + y}" // "x + y = 3"
```

Swiftだと次のようになります。

```swift
let x = 1
let y = 2
"x + y = \(x + y)"
```


同様の機能はKotlin、Python(3.6以降)、JavaScript（TypeScriptも）など様々な言語に採用されています。比較的新しい言語や、既存言語の新機能として採用するのがすっかり普通になった機能と言えるでしょう。

文字列補間はとても便利な機能ですが、構文解析という観点からは少々やっかいな存在です。文字列リテラルは従来はトークンとして扱われており、正規言語の範囲に収まるように設計されていたため、正規表現で取り扱えたのです。これは字句解析と構文解析を分離し、かつ、字句解析を可能な限り単純化するという観点で言えばある意味当然とも言えますが、文字列補間は従来は字句であり正規表現で表現できたものを文脈自由文法を取り扱わなければいけない存在にしてしまいました。

たとえば、少々極端な例ですが、Rubyでは以下のように`#{}`の中にさらに文字列リテラルを書くことができ、その中には`#{}`を……といった具合に無限にネストできるのです。これまでの章を振り返ればわかるようにこれは明らかに正規言語を逸脱しており文脈自由言語の扱う範疇です。

```ruby
x = 1; y = 2
"expr1 (#{"expr2 (#{x + y})"})" # "expr1 (expr2 (3))"
```

しかし、従来の手法では文字列リテラルは字句として取り扱わなければいけないため、各言語処理系の実装者はad hocな形で構文解析器に手を加えています。たとえば、Rubyの構文解析器はbisonを使って書かれていますが、字句解析器に状態を持たせることでこの問題に対処しています。文字列リテラル内に`#{"が出現したら状態を式モードに切り替えて、その中で文字列リテラルがあらわれたら文字列リテラルモードに切り替えるといった具合です。

一方、PEGでは字句解析と構文解析が分離されていないため、特別な工夫をすることなく文字列補間を実装することができます。以下はRubyの文字列補間と同じようなものをPEGで記述する例です。

```text
string <- "\"" ("#{" expression "}" / .)* "\""
expression <- 式の定義
```

文字列補間を含む文字列リテラルは分解可能という意味で厳密な意味では字句と言えないわけですが、PEGは字句解析を分離しないおかげで文字列リテラルを殊更特別扱いする必要がないわけです。

PEGの利用例が近年増えてきているのは、言語に対してこのようにアドホックに構文を追加したいというニーズがあるためではないかと筆者は考えています。

<!-- 図7.X: 文字列補間の解析状態遷移図のプレースホルダ -->
<!-- 例: "abc#{1+2}def" の解析時
1. 通常文字列モード: "abc" を消費
2. 式モードへ遷移: '#{' を認識
3. 式モード: 1+2 を式として解析
4. 通常文字列モードへ復帰: '}' を認識
5. 通常文字列モード: "def" を消費
-->

## 7.2 インデント文法

Pythonではインデントによってプログラムの構造を表現します。たとえば、次のPythonプログラムを考えます。

```python
class Point:
  def __init__(self, x, y):
    self.x = x
    self.y = y
```

このPythonプログラムは次のような抽象構文木に変換されると考えられます。

![](img/chapter7/py-ast.svg){ width=70% }

インデントによってプログラムの構造を表現するというアイデアは秀逸ですが、一方で、インデントによる構造の表現は明らかに文脈自由言語の範囲を超えるものです。

Pythonでは字句解析のときにインデントを`<INDENT>`（インデントレベル増加）、インデントを「外す」のを`<DEDENT>`（インデントレベル減少）という特別なトークンに変換します。これにより、構文解析器自体はこれらのトークンをブロックの開始と終了のように扱うことができ、文脈自由文法の範囲で処理しやすくなります。

例えば、先の `Point` クラスの定義は、字句解析後には（簡略化すると）以下のようなトークン列として扱われるイメージです。

```
<CLASS> <NAME:Point> <COLON> <NEWLINE> <INDENT>
  <DEF> <NAME:__init__> <LPAREN> <NAME:self> <COMMA> <NAME:x> <COMMA> <NAME:y> <RPAREN> <COLON> <NEWLINE> <INDENT>
    <NAME:self> <DOT> <NAME:x> <ASSIGN> <NAME:x> <NEWLINE>
    <NAME:self> <DOT> <NAME:y> <ASSIGN> <NAME:y> <NEWLINE>
  <DEDENT>
<DEDENT>
```
（`<NAME:A>`は識別子A、`<COLON>`はコロン、`<NEWLINE>`は改行、`<ASSIGN>`は代入演算子を表すトークンとします。実際にはさらに詳細なトークン分割が行われます。）
このように、インデント/デデントトークンがブロック構造を示すため、構文解析器は括弧の対応付けに似た形で処理できます。

しかし、よくよく考えればわかるのですが、`<IDENT>`トークンと`<DEDENT>`トークンを切り出す処理が文脈自由ではありません。つまり、字句解析時に`<IDENT>`と`<DEDENT>`トークンを切り出すために特殊な処理をしていることになります。`<DEDENT>`トークンは`<IDENT>`トークンとスペースの数が同じでなければいけないため、切り出すためには正規表現でも文脈自由文法でも手に余ることは想像できるでしょう。

<!-- 図7.Y: インデント文法のトークン化とブロック構造のプレースホルダ -->
<!-- 例:
class Point:
  INDENT (レベル1)
  def __init__(self, x, y):
    INDENT (レベル2)
    self.x = x
    DEDENT (レベル1に戻る)
  DEDENT (レベル0に戻る)
インデントレベルのスタック: [0] -> [0, 2] -> [0, 2, 4] -> [0, 2] -> [0] のような変化
-->

## 7.3 ヒアドキュメント

ヒアドキュメントは複数行に渡る文字列を記述するための文法で、従来はbashなどのシェル言語で採用されていましたが、PerlやRubyもヒアドキュメントを採用しました。たとえば、RubyでHTMLの文字列をヒアドキュメントで以下のように書くことができます。

```ruby
html = <<HTML
<html>
  <head><title>Title</title></head>
  <body><p>Hello</p></body>
</html>
HTML
```

特筆すべきは、`<<HTML`と`HTML`のように対応している間だけが文字列として解釈されることです。これだけなら文脈自由言語の範囲内です。実際には問題はもっと複雑です。ヒアドキュメントは**ネストが可能**なのです。たとえば、以下のようなヒアドキュメントは正しいRubyプログラムです。

```ruby
here = <<E1 + <<E2
ここはE1です
E1
ここはE2です
E2
```

これは以下の内容の文字列として解釈されます。

```ruby
ここはE1です
ここはE2です
```

ヒアドキュメント内では文字列補間が使えるのでさらに複雑です。以下のようなヒアドキュメントもOKなのです。

```ruby
a = 100
b = 200
here = <<A + <<B
aは#{a}です
A
bは#{b}です
B
```

これは次の文字列として解釈されます。

```
aは100です
bは200です
```

読者の方々はおそらく「確かに凄いけど、普通はこのような書き方をすることはほぼないのでは」と思われたのではないでしょうか。実際問題そうなのですば、Rubyはこのような複雑怪奇なプログラムもうまく構文解析できなければいけないのも事実です。

Rubyのヒアドキュメントを適切に構文解析するには直感的にはHTMLやXMLにおけるタグ名の対応付けと同じ処理が必要になりますが、これは明らかに文脈自由言語の範囲を超えています。Rubyのヒアドキュメントがこのような振る舞いをすることを初めて知ったのは筆者が大学院生の頃ですが、あまりに予想外の振る舞いに目眩がする思いだったのを覚えています。

Rubyのヒアドキュメントが実際にどのように実装されているかはさておき、筆者はかつて中田育男先生と共同でISO Rubyの試験的な構文解析器をScalaで実装した際に、このヒアドキュメントの扱いに非常に苦労しました。

その際の実装の詳細は、中田先生の[ruby_scalaリポジトリ](https://github.com/inakata/ruby_scala/blob/3f54cc6f80678e30a211fb1374280246f08182ed/src/main/scala/com/github/inakata/ruby_scala/Ruby.scala#L1383)で確認できますが、ヒアドキュメントの開始デリミタを記憶し、対応する終了デリミタが現れるまでを特別に処理する、といった複雑なロジックが必要でした。

このときはScalaのパーザコンビネータを使ってヒアドキュメントを再現したのですが、引数を取ってコンビネータを返すメソッドを定義することで問題を解決しました。形式言語の文脈でいうのなら、PEGの規則が引数を持てるように拡張することでヒアドキュメントを解釈できるようになったと言うことができます。

PEGを拡張して規則が引数を持てるようにするという試みは複数ありますが、筆者もMacro PEGというPEGを拡張したものを提案しました。ヒアドキュメントという当たり前に使われている言語機能ですら、構文解析を正しく行うためには厄介な処理をする必要があるのです。

<!-- 図7.Z: ヒアドキュメントのデリミタ対応の概念図プレースホルダ -->
<!-- 例:
<<E1
  ...
  <<E2
    ...
  E2
  ...
E1
デリミタスタック: [] -> [E1] -> [E1, E2] -> [E1] -> []
-->

以下に、これまで見てきたような文脈自由言語の範囲を超える構文上の課題と、それに対する一般的な解決策をまとめます。

| 問題点                               | 解決策の例                                   | メリット                                                                 | デメリット                                                                 | 主な適用例                               |
| ------------------------------------ | -------------------------------------------- | ------------------------------------------------------------------------ | -------------------------------------------------------------------------- | ---------------------------------------- |
| **文字列補間**                       | 字句解析器の状態管理                         | 既存のLR系パーサーなどと比較的連携しやすい                               | 字句解析器が複雑化し、状態管理が煩雑になる                                 | Ruby, Perl                               |
|                                      | PEG / スキャナレスパーザ                     | 文法定義が直感的で、文字列リテラルと式を統一的に扱える                   | Packrat Parsingの場合、メモ化によるメモリ消費増。バックトラックの可能性も。    | Python (3.9+), Scala (パーザコンビネータ) |
| **インデント文法**                   | INDENT/DEDENTトークンによる前処理            | 構文解析器自体は通常のCFGとして扱える                                    | 字句解析器でのインデントレベル管理とトークン挿入ロジックが必須             | Python, Haskell (layout rule)            |
|                                      | PEG / スキャナレスパーザ                     | 文法定義にインデントレベルのチェックを直接組み込める可能性がある         | 実装の複雑さ、パフォーマンスへの影響                                       | (原理的には可能、F#など一部で採用例あり) |
| **ヒアドキュメント (ネスト対応)**      | 字句解析器の状態管理とデリミタスタック       |                                                                          | 字句解析器が非常に複雑化                                                   | Ruby, Perl                               |
|                                      | 引数付きPEG規則 / マクロPEG                  | より宣言的に複雑な対応関係を記述できる可能性がある                       | PEG自体の拡張が必要、対応ツールが限定的                                    | (研究段階、一部のパーザコンビネータ)     |
| **改行終端可能文法**                 | 字句解析器の状態管理 (例: 式モード/文モード) | 特定の文脈で改行の扱いを切り替えられる                                   | 状態遷移が複雑になりがち                                                   | Ruby, Scala (一部の挙動)                 |
|                                      | PEG / スキャナレスパーザ                     | 改行の扱いを構文規則レベルでより柔軟かつ宣言的に定義可能                 |                                                                            | Python, Klassic (本書の例)                 |
| **Cのtypedefのような文脈依存性**     | シンボルテーブルと構文解析器の連携           | 構文解析中に型情報を参照し、識別子の解釈を動的に変更できる                 | 構文解析器と意味解析部が密結合し、実装の独立性やモジュール性が低下する     | C, C++                                   |
|                                      | (限定的なケースでは)パラメータ化された文法規則 |                                                                          | 汎用性は低い                                                               |                                          |

## 7.4 改行終端可能文法

C、C++、Java、C#などの言語では、解釈・実行の基本単位は**文**(Statement)と呼ばれるものになります。また、文はセミコロンなどの終端子と呼ばれるもので終わるか、区切り文字で区切られるのが一般的です。一方、セミコロンが文の区切りになるのがPascalなどの言語です。厳密には違いますが、関数型プログラミング言語Standard MLのセミコロンも似たような扱いです。

Javaでは次のように書くことで、A、B、Cを順に出力することができます。

```java
System.out.println("A");
System.out.println("B");
System.out.println("C");
```

このように文が終端子（Terminator)で終わる文法には、文の途中に改行が挟まっても単なるスペースと同様に取り扱えるという利点があります。先程のプログラムを次のように書き換えても意味は代わりません。

```java
System.out.println(
  "A");
System.out.println(
  "B");
System.out.println(
  "C");
```

大抵の場合、文は一行で終わるのですから、毎回セミコロンをつけなければいけないのも面倒くさいものです。そういったニーズを反映してか、Scala、Kotlin、Swift、Goなどの比較的新しい言語では（Scalaの初期バージョン
が2003ですから、そこまで新しいのかという話もありますが）、文はセミコロンで終わることもできるが、改行でも終わることができます。より古い言語でもPython、Ruby、JavaScriptも改行で文が終わることができます。

たとえば、先程のJavaプログラムに相当するScalaプログラムは次のようになります。

```scala
println("A")
println("B")
println("C")
```

見た目にもすっきりしますし、改行を併用するコーディングスタイルが大半であることを考えても、無駄なタイピングが減るしでいいことずくめです。Scalaではそれでいて、次のように文の途中で改行が入っても問題なく解釈・実行することができます。

```scala
println(
  "A")
println(
  "B")
println(
  "C")
```

Scalaでも一行の文字数が増えれば分割したくなりますから、このような機能があるのは自然でしょう。

ここで一つの疑問が湧きます。「文は改行で終わる」という規則なら改行が来たときに「文の終わり」とみなせばよいですし、「文はセミコロンで終わる」という規則なら、セミコロンが来たときに「文の終わり」とみなせば問題ありません。しかしながら、このような文法を実現するためには「セミコロンが来れば文が終わるが、改行で文が終わることもある」というややこしい規則に基づいて構文解析をしなければいけません。

このような文法を実現するのは案外ややこしいものです。Javaの`System.out.println("A");`という文は正確には「式文」と呼ばれますが、この式文は次のように定義されます。

```text
expression_statement ::= expression <SEMICOLON>
```

`<SEMICOLON>`はセミコロンを表すトークンです。では、Scala式の文法を「改行でもセミコロンでも終わることができる」と考えて次のように記述しても大丈夫でしょうか。

```text
expression_statement ::= expression <SEMICOLON>
                       | expression <LINE_TERMINATOR>
```


`<LINE_TERMINATOR>`は改行を表すトークンです。プラットフォームによって改行コードは異なるので、このように定義しておくと楽でしょう。このような規則でうまく先程の例全てをうまく取り扱えるかといえば、端的に言って無理です。

```scala
println(
  "A")
```

C系の言語では行コメントなどの例外を除き、字句解析時に改行もスペースも同じ扱いで処理しているので、このような「式の途中で改行が来る」ケースも特に工夫する必要がありませんでした。しかし、Scalaなどの言語における「改行」は式の途中では無視されるが文末では終端子にもなり得るという複雑な存在です。

言い換えると「文脈」を考慮して改行を取り扱う必要がでてきたのです。このような文法はどのようにすれば取り扱えるでしょうか。なかなか難しい問題ですが、大きく分けて二つの戦略があります。

一つ目は字句解析器に文脈情報を持たせる方法です。たとえば、「式」モードでは改行は無視されるが、「文」モードだと無視されないという風にした上で、式が終わったら「文」モードに切り替えを行い、式が開始したら「式」モードに切り替えを行います。この方式を採用している典型的な言語がRubyで、Cで書かれた字句解析器には実に多数の文脈情報を持たせています。

```c
// https://github.com/ruby/ruby/blob/v3_2_0/parse.y#L161-L181
/* examine combinations */
enum lex_state_e {
#define DEF_EXPR(n) EXPR_##n = (1 << EXPR_##n##_bit)
    DEF_EXPR(BEG),
    DEF_EXPR(END),
    DEF_EXPR(ENDARG),
    DEF_EXPR(ENDFN),
    DEF_EXPR(ARG),
    DEF_EXPR(CMDARG),
    DEF_EXPR(MID),
    DEF_EXPR(FNAME),
    DEF_EXPR(DOT),
    DEF_EXPR(CLASS),
    DEF_EXPR(LABEL),
    DEF_EXPR(LABELED),
    DEF_EXPR(FITEM),
    EXPR_VALUE = EXPR_BEG,
    EXPR_BEG_ANY  =  (EXPR_BEG | EXPR_MID | EXPR_CLASS),
    EXPR_ARG_ANY  =  (EXPR_ARG | EXPR_CMDARG),
    EXPR_END_ANY  =  (EXPR_END | EXPR_ENDARG | EXPR_ENDFN),
    EXPR_NONE = 0
};
```

「改行で文が終わる」以外にもRubyはかなり複雑な構文解析を行っているため、このように多数の状態を字句解析器に持たせる必要があります。Rubyの文法は私が知る限り**もっとも複雑なものの一つ**なのでややこれは極端ですが、字句解析器に状態を持たせるアプローチは他の言語も採用していることが多いようです。

別のアプローチとして既出のPEGを使うという方法があります。PEGでは字句解析という概念自体がありませんから、式の途中に改行が入るというのも構文解析レベルで処理できます。Pythonでは3.9からPEGベースのパーサーが導入され、3.10以降も継続して使用されています。これにより、Pythonのパーサーは改行の扱いなど、より柔軟な構文規則を以前よりも直接的に記述しやすくなりました。

例として拙作のプログラミング言語Klassicでは次のようにして式の合間に改行を挟むことができるようにしています。

```scala
//add ::= term {"+" term | "-" term}
lazy val add: Parser[AST] = rule{
  chainl(term)(
    (%% << CL(PLUS)) ^^ { location => (left: AST, right: AST) => BinaryExpression(location, Operator.ADD, left, right) } |
    (%% << CL(MINUS)) ^^ { location => (left: AST, right: AST) => BinaryExpression(location, Operator.SUBTRACT, left, right) }
  )
}
```

関数`CL()`は次のように定義されます。

```scala
 def CL[T](parser: Parser[T]): Parser[T] = parser << SPACING
```

Klassicの構文解析器は自作のパーザコンビネータライブラリで構築されているので少々ややこしく見えますが、要約すると、`CL()`は引数に与えたものの後に任意個のスペース（改行）が来るという意味で、キーワードである`PLUS`や`MINUS`の後にこのような規則を差し込むことで「式の途中での改行は無視」が実現できています。

現在ある言語で採用されているかはわかりませんが、GLR法のようにスキャナレス構文解析と呼ばれる他の手法を使う方法もあります。スキャナレスということは字句解析が無いということですが、字句解析器を別に必要としない構文解析法の総称を指します。PEGも字句解析器を必要としませんから、PEGもスキャナレス構文解析の一種と言えます。

ともあれ、私達が普通に使っている「改行で文が終わる」ようにできる処理一つとっても厄介な問題だということです。

## 7.5 Cのtypedef

C言語の`typedef`文は既存の型に別名をつける機能です。C言語をバリバリ書いているプログラマの型ならお馴染みの機能でしょう。Cのtypdefは

- 移植性を高める
- 関数ポインタを使ったよみづらい宣言を読みやすくする

といった目的で使われますが、この`typedef`文が意外に曲者だったりします。以下は`i`をint型の別名として定義するものですが、同時にローカル変数`i`を`i`型として定義しています。

```c
typedef int i;
int main(void) {
        i i = 100; // OK
        int x = (i)'a'; // ERROR
        return 0;
}
```

現実にこのようなコードの書き方をするかはともかく、`i i = 100;`は明らかにOKな表現として解析してあげなければいけません。一方で、`int x = (i)'a';`は構文解析エラーになります。`i i = 100;`という宣言がなければこの文も通るのですが、合わせて書けば構文解析エラーです。それ以前の文脈である識別子がtypedefされたかどうかで構文解析の結果が変わるのですからとてもややこしいです。

C言語ではこのようなややこしい構文を解析するために、typdefした識別子を連想配列の形で持っておいて、構文解析時にそれを使うという手法を採用しています。

## 7.6 Scalaでの「文頭に演算子が来る場合の処理」

7.4 で改行で文を終端する文法について説明しましたが、Scalaはさらにややこしい入力を処理できなければいけません。たとえば、以下のような文を解釈できる必要があります。

```scala
val x = 1
      + 2
println(x) // 3
```

ここで、xを3とちゃんと解釈するには`val x = 1`が改行で終わったから「文が終わった」と解釈せず、次のトークンである`+`まで見てから文が終わるか判定する必要があります。これまで試した限り、同じことができるのはJavaScriptくらいで、Ruby、Python、Kotlin、Go、Swiftなどの言語ではエラーになるか、`x = 1`で文が終わったと解釈され、`+ 2`は別の文として解釈されるケースばかりでした。

この処理について、Scala言語仕様内の[1.2 Newline Characters](https://scala-lang.org/files/archive/spec/2.13/01-lexical-syntax.html)に関連する記述があります。

> Scala is a line-oriented language where statements may be terminated by semi-colons or newlines. A newline in a Scala source text is treated as the special token “nl” if the three following criteria are satisfied:
>   1. The token immediately preceding the newline can terminate a statement.
>   2. The token immediately following the newline can begin a statement.
>   3. The token appears in a region where newlines are enabled.
> The tokens that can terminate a statement are: literals, identifiers and the following delimiters and reserved words:

これを意訳すると、通常の場合はScalaの文はセミコロンまたは改行で終わることができるが、次の三つの条件**全て**を満たしたときのみ、特別なトークン`nl`として扱われることになる、ということになります。

1. 改行の直前のトークンが「文を終わらせられる」ものである場合
2. 改行の直後のトークンが「文を始められる」ものである場合
3. 改行が「利用可能」になっている箇所にあらわれたものである場合

たとえば、以下のScalaプログラムについていうと、最初の改行は`nl`トークンになりませんが、何故かというと条件1が満たされても条件2が満たされないからです。

```scala
val x = 1
      + 2
```

ちなみに、調査を開始する時点ではScalaの文法の基本文法を継承したKotlinでも同じようになっていると思っていたのですが、一行目で文が終わると解釈されてしまいました。

```kotlin
val x = 1
      + 2 // + 2は単独の式として解釈されてしまう
println(x) // 1
```

## 7.7 プレースホルダー構文

Scalaにはプレースホルダー構文、正確にはPlaceholder Syntax for Anonymous Functionと呼ばれる構文があります。これは最近の言語ではすっかり普通に使えるようになったいわゆる**ラムダ式**を簡易表記するための構文です。

たとえば、Scalaで`[1, 2, 3, 4]`というリストの各要素をインクリメントする処理はラムダ式（Scalaでは無名関数とも呼ばれます）を使って次のように書くことができます。

```scala
List(1, 2, 3, 4).map(x => x + 1)
```

ラムダ式を普段から使っておられる読者には大体雰囲気で伝わると思うのですが、`map`は多くの言語で採用されている高階関数です。`map`は引数で渡された無名関数をリストの各要素に適用して、その結果できた新しいリストを返します。たとえば、上のプログラムだと実行結果は次のようになります。


```scala
List(2, 3, 4, 5)
```

しかし、`map()`に渡す無名関数を毎回`x => x + 1`のように書かないといけないのも冗長です。というわけで、Scalaでは次のように無名関数を簡易表記することができます。

```scala
List(1, 2, 3, 4).map(_ + 1)
```

これは構文解析のときに、先程の

```scala
List(1, 2, 3, 4).map(x => x + 1)
```

に展開されます。出てくる`_`のことをプレースホルダ（placeholder）と呼びます。例によってこの構文は非常に扱いが厄介です。何故かというと、`_`がどのような無名関数を表すかを構文解析時に決定するのはかなり困難なのです。すぐに思いつくのは、`_`はそれを囲む「最小の式」を無名関数に変換すると定義するという方法です。しかし、これはプレースホルダが二つ以上出てくると破綻します。

たとえば、別の高階関数`foldLeft()`を使った例を見てみます。

```scala
List(1, 2, 3, 4).foldLeft(0)(_ + _)
```

リスト`[1, 2, 3, 4]`の合計値である`10`を計算してくれます。このプレースホルダ構文は次のように変換されます。

```scala
List(1, 2, 3, 4).foldLeft(0)((x, y) => x + y)
```

このケースでは、`(_ + _)`が`((x, y) => x + y)`という無名関数に変換されたわけですが、プレースホルダが複数出現するとややこしい問題になります。


また、そもそもプレースホルダが単一であっても解釈が難しい問題もあります。たとえば、次の式は考えてみます。

```scala
List(1, 2, 3, 4).map(_ * 2 + 3)
```

これは以下のScalaプログラムに変換されます。

```scala
List(1, 2, 3, 4).map(x => x * 2 + 3)
````

もし、`_`を含む「最小の式」を無名関数にするという方式だと`(_ * 2)`が`(x => x * 2)`という無名関数に変換されても良さそうですがそうはなっていません。また、ユーザーのニーズを考えてもそうなっては欲しくありません。

Scalaではこのプレースホルダ構文をどう扱っているかというと非常に複雑で一言では説明しきれない部分があるのですが、あえておおざっぱに要約すると、次のようになります。

1. `_` をアンダースコアセクション（underscore section）と呼ぶ
2. 無名関数になる範囲の式`e`は構文カテゴリ（syntactic category）`Expr`に属しており、アンダースコアセクション`u`について次の条件を満たす必要がある：
  2-1. `e`は真に（property）`u`を含んでいる
  2-2. `e`の中に構文カテゴリ`Expr`に属する式は存在しない

といっても、これだけだとわかりませんよね。たとえば、

```
map(_ * 2 + 3)
```

では`_ * 2 + 3`までが「無名関数化」される範囲ですが、これをいったん括弧つきで表記すると`(_ * 2) + 3`となります。Scalaの構文解析上のルールでは、演算子を使った式は単独では構文カテゴリ`Expr`に属しません。メソッドの引数になっている`(_ * 2 + 3)`まで来て初めて、この式は構文カテゴリ`Expr`になります。

端的に言って、この時点で既に目眩がするような内容です。というのは、構文カテゴリという情報自体が構文解析の途中でなければ取り出せない情報であり、つまり、Scalaでは構文解析の*途中*にうまくプレースホルダを処理する必要があるのです。このプレースホルダ構文をきっちり解説するのは本書の内容を超えますが、やはりこの問題も文脈自由言語の範囲で扱うことができません。

Scala処理系内部でプレースホルダ構文がどのように実装されているかも読んだことがありますが、とてもややこしくいものでした。C言語のtypedefは構文解析の途中で連想配列に名前を登録すればいいだけまだマシですが、さらに厄介だというのが正直な印象です。

なお、プレースホルダ構文について「きちんとした定義」を参照されたい方は、[Scala Language Specification 6.23.2: Placeholder Syntax for Anonymous Function](https://www.scala-lang.org/files/archive/spec/2.13/06-expressions.html#placeholder-syntax-for-anonymous-functions)を読んでいただければと思います。

## 7.8 エラーリカバリ

構文解析の途中でエラーが起きることは（当然ながら）普通にあります。構文解析中のエラーリカバリについては多くの研究があるものの、コンパイラの教科書で構文解析アルゴリズでのエラーリカバリについて言及されることは稀です。推測ですが、構文解析において２つ目以降のエラーは大抵最初のエラーに誘発されて起こるということや、どうしても経験則に頼った記述になりがちなため、教科書で言及されることは少ないのでしょう。また、大抵の言語処理系で構文解析中のエラーリカバリについては大したことをしていなかったという歴史的事情もあるかもしれません。

しかし、現在は別の観点から構文解析中のエラーリカバリが重要性を増してきています。それは、テキストエディタの拡張としてIDEのような「構文解析エラーになるが、それっぽくなんとか構文解析をしなければいけない」というニーズがあるからです。ユーザーがコードを書いている最中は、一時的に文法的に正しくない状態になることが頻繁にあります。IDEがそのような状況でも構文ハイライト、コード補完、リアルタイムのエラー表示などの機能を提供し続けるためには、エラーが発生しても即座に解析を中断するのではなく、可能な限り解析を継続し、後続のエラーも検出できるような仕組み、すなわちエラーリカバリ機構が不可欠です。

エラーリカバリにはいくつかの代表的な手法があります。

- **パニックモード (Panic Mode):** 最も単純な手法の一つです。エラーを検出したら、セミコロン（`;`）や閉じ波括弧（`}`）のような、文やブロックの区切りとなる「同期トークン」が見つかるまで、入力トークンを読み飛ばします。同期トークンが見つかったら、そこから解析を再開します。

   C言語風のコード `x = a + * b; y = c;` で、`*` が予期しないトークンとしてエラーになった場合、パニックモードでは `*` と `b` を読み飛ばし、次の同期トークンである `;` を見つけて解析を再開します。これにより、`y = c;` の解析は行われますが、`* b` に関するエラーの詳細は失われる可能性があります。

- **フレーズレベルリカバリ (Phrase-Level Recovery):** エラー箇所の周辺で、局所的な修正を試みる手法です。例えば、不足しているセミコロンを補ったり、予期しないトークンを削除したり、期待されるトークンに置き換えたりします。

  `x = a + b y = c;` というコードで、`b` と `y` の間にセミコロンが欠落している場合、パーサは `y` が予期しないトークンであると判断します。フレーズレベルリカバリでは、「文の終わりにはセミコロンが期待される」という知識に基づき、`b` の後にセミコロンを挿入して `x = a + b; y = c;` として解析を試みるかもしれません。例えば、Javaのメソッド呼び出しで `myObject.method(arg1 arg2)` のようにカンマが抜けている場合、`arg1` と `arg2` の間にカンマを補って `myObject.method(arg1, arg2)` として解釈を試みる、といった具合です。あるいは、JSON の配列 `[1, , 2]` で余分なカンマがある場合、それを削除して `[1, 2]` として解析を続けるかもしれません。パニックモードよりは洗練されていますが、どのような修正を行うかの判断が難しく、実装が複雑になりがちです。

- **エラー生成規則 (Error Productions):** 文法にあらかじめよくあるエラーパターンに対応する生成規則を追加しておく手法です。例えば、「`if (condition) statement`」という正しい規則に加えて、「`if condition) statement`」（開き括弧が欠落）のようなエラー用の規則を定義しておきます。これにより、特定のエラーを「受理」し、解析を継続できます。

  Yaccのようなツールでは、`error` トークンを使ってエラー規則を定義できます。

```text
statement: IF '(' expr ')' statement
         | IF error ')' statement { yyerror("Missing opening parenthesis in if statement"); }
         | /* ... other rules ... */
         ;
```

この例では、`if` の後に開き括弧 `(` がない場合に `error` トークンがマッチし、エラーメッセージを出力しつつ、`)` 以降の解析を継続しようとします。多くのエラーパターンを網羅しようとすると文法が複雑になりますが、特定のエラーに対しては効果的です。

- **グローバルコレクション (Global Correction):** 理論的には最も強力な手法で、入力文字列全体に対して、最小限の修正（挿入、削除、置換）で文法的に正しい文字列に変換する方法を探します。

  `if x > 0) { ... }` という入力に対し、グローバルコレクションは開き括弧 `(` を挿入するのが最小の修正であると判断するかもしれません。しかし、入力全体を考慮して最適な修正を見つけるのは計算量的に非常に困難であり、実用的なコンパイラやIDEでこの手法が全面的に採用されることは稀です。

IDEのような環境では、これらの手法を組み合わせたり、部分的な構文木（エラー箇所を含むかもしれないが、解析できた部分）を構築したり、インクリメンタルな解析（変更箇所だけを再解析する）を行ったりすることで、ユーザーが編集中でも可能な限り正確な情報を提供しようと試みています。例えば、ユーザーが `class MyClass { public void myMethod() { ... }` と入力し、最後の閉じ括弧 `}` を入力し忘れている場合でも、IDEは `myMethod` の本体部分についてはある程度解析を試み、メソッド内の変数に対するコード補完や型チェックを行おうとします。これは、エラーリカバリ機構が、エラー箇所を特定しつつも、それ以外の部分については解析を継続し、部分的な構文情報を抽出しているためです。エラーリカバリは、単にエラーを見つけるだけでなく、その後の解析をどう継続し、ユーザーにどのようなフィードバックを与えるかという、より実践的で奥深い問題領域なのです。

## 7.9 まとめ

7章では現実の構文解析で遭遇する問題について、いくつかの例を挙げて説明しました。筆者が大学院博士後期課程に進学した頃「構文解析は終わった問題」と言われたのを覚えていますが、実際にはその後もANTLRの`LL(*)`アルゴリズムのような革新が起きていますし、細かいところでは今回の例のように従来の構文解析法単体では取り扱えない部分をアドホックに各プログラミング言語が補っている部分があります。

このような問題が起きるのは結局のところ、当初の想定と違って「プログラミング言語は文脈自由言語として表せ」なかったという事です。より厳密には当然、文脈自由言語の範囲に納めることもできますが、便利な表記を許していくとどうしても文脈自由言語から「はみ出て」しまうということです。このような「現実のプログラミング言語の文脈依存性」については専門の研究者以外には案外知られていなかったりしますが、ともあれこのような問題があることを知っておくのは、既存言語の表記法を取り入れた新しい言語を設計するときにも有益でしょう。
